{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def gen_data(mu, delta, n, d: int = 2):\n",
    "    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))\n",
    "    mu = np.full((n, d), mu, dtype=np.float64)\n",
    "\n",
    "    if len(delta) == 1 and delta[0] == 0:\n",
    "        return mu + noise, np.zeros(n)\n",
    "    \n",
    "    # 10% of the data are abnormal\n",
    "    m = len(delta)\n",
    "    abnormal_idx = np.random.choice(n, int(n/10), replace=False)\n",
    "\n",
    "    ptr = 0\n",
    "    for i in range(m):\n",
    "        for j in range(len(abnormal_idx)//m):\n",
    "            mu[abnormal_idx[ptr], :] += delta[i]\n",
    "            ptr += 1\n",
    "    \n",
    "    X = mu + noise \n",
    "    Y = np.zeros(n)\n",
    "    Y[abnormal_idx] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Feature extractor network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Domain critic network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class WDGRL():\n",
    "    def __init__(self, input_dim: int=2, generator_hidden_dims: List[int]=[32, 16, 8, 4, 2], critic_hidden_dims: List[int]=[32, 16, 8, 4, 2],\n",
    "                 gamma: float = 0.1, _lr_generator: float = 1e-2, _lr_critic: float = 1e-2, \n",
    "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.generator = Generator(input_dim, generator_hidden_dims).to(self.device)\n",
    "        self.critic = Critic(generator_hidden_dims[-1], critic_hidden_dims).to(self.device)\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=_lr_generator)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=_lr_critic)\n",
    "    \n",
    "    def compute_gradient_penalty(self, source_data: torch.Tensor, target_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute gradient penalty.\"\"\"\n",
    "        if source_data.size(0) > target_data.size(0):\n",
    "            ms = source_data.size(0)\n",
    "            mt = target_data.size(0)\n",
    "            gradient_penalty = 0\n",
    "            for _ in range(0, ms, mt):\n",
    "                source_chunk = source_data[_:_+mt]\n",
    "                target_chunk = target_data\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            if ms % mt != 0:\n",
    "                source_chunk = source_data[ms-mt:]\n",
    "                perm = torch.randperm(mt)\n",
    "                idx = perm[:ms % mt]\n",
    "                target_chunk = target_data[idx]\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            return gradient_penalty / ((ms // mt) + (ms % mt != 0)) \n",
    "        \n",
    "        # For balanced batch\n",
    "        alpha = torch.rand(source_data.size(0), 1).to(self.device)\n",
    "        interpolates = (alpha * source_data + ((1 - alpha) * target_data)).requires_grad_(True)\n",
    "        \n",
    "        # Domain critic outputs\n",
    "        dc_output = self.critic(interpolates)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=dc_output,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        # Compute gradient penalty\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    def train(self, source_loader: DataLoader, target_loader: DataLoader, num_epochs: int = 100, dc_iter: int = 100) -> List[float]:\n",
    "        self.generator.train()\n",
    "        self.critic.train()\n",
    "        losses = []\n",
    "        source_critic_scores = []\n",
    "        target_critic_scores = []\n",
    "        for epoch in trange(num_epochs, desc='Epoch'):\n",
    "            loss = 0\n",
    "            for (source_data, _), (target_data, _) in zip(source_loader, target_loader):\n",
    "                source_data, target_data = source_data.to(self.device), target_data.to(self.device)\n",
    "\n",
    "                # Train domain critic\n",
    "                for _ in range(dc_iter):\n",
    "                    self.critic_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        source_features = self.generator(source_data)\n",
    "                        target_features = self.generator(target_data)\n",
    "                    \n",
    "                    # Compute empirical Wasserstein distance\n",
    "                    dc_source = self.critic(source_features)\n",
    "                    dc_target = self.critic(target_features)\n",
    "                    wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.compute_gradient_penalty(source_features, target_features)\n",
    "\n",
    "                    # Domain critic loss\n",
    "                    dc_loss = - wasserstein_distance + self.gamma * gradient_penalty\n",
    "                    dc_loss.backward()\n",
    "                    self.critic_optimizer.step()\n",
    "\n",
    "                # Train feature extractor\n",
    "                self.generator_optimizer.zero_grad()\n",
    "                source_features = self.generator(source_data)\n",
    "                target_features = self.generator(target_data)\n",
    "                dc_source = self.critic(source_features)\n",
    "                dc_target = self.critic(target_features)\n",
    "                wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "                wasserstein_distance.backward()\n",
    "                self.generator_optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    loss += wasserstein_distance.item()\n",
    "                    \n",
    "            source_critic_scores.append(self.criticize(source_loader.dataset.tensors[0].to(self.device)))\n",
    "            target_critic_scores.append(self.criticize(target_loader.dataset.tensors[0].to(self.device)))\n",
    "            losses.append(loss/len(source_loader))\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | Loss: {wasserstein_distance.item()}')\n",
    "        return losses, source_critic_scores, target_critic_scores\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_feature(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.generator.eval()\n",
    "        return self.generator(x)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def criticize(self, x: torch.Tensor) -> float:\n",
    "        self.generator.eval()\n",
    "        self.critic.eval()\n",
    "        return self.critic(self.generator(x)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the WDGRL model (same architecture as before)\n",
    "model = WDGRL(input_dim=1,generator_hidden_dims=[10, 10, 10], critic_hidden_dims=[10])\n",
    "\n",
    "# Load the saved checkpoint\n",
    "checkpoint = torch.load(\"wdgrl.pth\", map_location=model.device, weights_only=True)\n",
    "\n",
    "# Restore the model weights\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Create synthetic dataset and dataloaders for domain adaptation.\"\"\"\n",
    "# Create datasets\n",
    "ns, nt, d = 100, 10, 1\n",
    "mu_s, mu_t = 0, 20\n",
    "delta_s, delta_t = [3], [3]\n",
    "xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "plt.scatter(xs[:, 0], np.zeros_like(xs[:, 0]), c=ys, cmap='viridis', s=2)\n",
    "plt.scatter(xt[:, 0], np.zeros_like(xt[:, 0]), c=yt, cmap='cool', s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.FloatTensor(xs)\n",
    "ys = torch.LongTensor(ys)\n",
    "xt = torch.FloatTensor(xt)\n",
    "yt = torch.LongTensor(yt)\n",
    "xs_hat = model.extract_feature(xs)\n",
    "xt_hat = model.extract_feature(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_sum(X):\n",
    "    return np.argmax(np.sum(X, axis=1))\n",
    "x_hat = torch.cat([xs_hat, xt_hat], dim=0).cpu().numpy()\n",
    "print(x_hat)\n",
    "O = max_sum(x_hat)\n",
    "O = [O-ns]\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_hat = torch.zeros_like(yt)\n",
    "yt_hat[O[0]] = 1\n",
    "print(yt)\n",
    "yt_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpmath import mp\n",
    "\n",
    "mp.dps = 500\n",
    "def truncated_cdf(etajTy, mu, sigma, left, right):\n",
    "    numerator = mp.ncdf((etajTy - mu) / sigma) - mp.ncdf((left - mu) / sigma)\n",
    "    denominator = mp.ncdf((right - mu) / sigma) - mp.ncdf((left - mu) / sigma)\n",
    "    if denominator <= 1e-16:\n",
    "        true_cdf = 1\n",
    "    else:\n",
    "        true_cdf = numerator / denominator \n",
    "    return true_cdf\n",
    "def intersect(itv1, itv2):\n",
    "    # print(itv1, itv2)\n",
    "    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]\n",
    "    if itv[0] > itv[1]:\n",
    "        return None    \n",
    "    return itv\n",
    "\n",
    "def solve_linear_inequality(u, v): #u + vz < 0\n",
    "    if (v > -1e-16 and v < 1e-16):\n",
    "        v = 0\n",
    "        if (u < 0):\n",
    "            return [-np.Inf, np.Inf]\n",
    "        else:\n",
    "            print('error')\n",
    "            return None\n",
    "    if (v < 0):\n",
    "        return [-u/v, np.Inf]\n",
    "    return [np.NINF, -u/v]\n",
    "\n",
    "def get_interval(Xtj, a, b):\n",
    "    layers = []\n",
    "\n",
    "    for name, param in model.generator.named_children():\n",
    "        temp = dict(param._modules)\n",
    "        \n",
    "        for layer_name in temp.values():\n",
    "            if ('Linear' in str(layer_name)):\n",
    "                layers.append('Linear')\n",
    "            elif ('ReLU' in str(layer_name)):\n",
    "                layers.append('ReLU')\n",
    "\n",
    "    ptr = 0\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    u = a\n",
    "    v = b\n",
    "    temp = Xtj\n",
    "    weight = None\n",
    "    bias = None\n",
    "    for name, param in model.generator.named_parameters():\n",
    "        if (layers[ptr] == 'Linear'):\n",
    "            if ('weight' in name):\n",
    "                weight = param.data.cpu().detach().numpy()\n",
    "            elif ('bias' in name):\n",
    "                bias = param.data.cpu().detach().numpy().reshape(-1, 1)\n",
    "                ptr += 1\n",
    "                temp = weight.dot(temp) + bias\n",
    "                u = weight.dot(u) + bias\n",
    "                v = weight.dot(v)\n",
    "\n",
    "        if (ptr < len(layers) and layers[ptr] == 'ReLU'):\n",
    "            ptr += 1\n",
    "            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))\n",
    "            sub_itv = [np.NINF, np.inf]\n",
    "            for i in range(temp.shape[0]):\n",
    "                if temp[i] > 0:\n",
    "                    Relu_matrix[i][i] = 1\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i][0], -v[i][0]))\n",
    "                else:\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i][0], v[i][0]))\n",
    "            itv = intersect(itv, sub_itv)\n",
    "            temp = Relu_matrix.dot(temp)\n",
    "            u = Relu_matrix.dot(u)\n",
    "            v = Relu_matrix.dot(v)\n",
    "\n",
    "    return itv, u, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tpr():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = [3], [3]\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < ns):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - ns]   \n",
    "    if yt[O[0]] == 0:\n",
    "        return None\n",
    "    Oc = list(np.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "    \n",
    "\n",
    "    etajTX = etaj.T.dot(X)\n",
    "    print(f'Anomaly index: {O[0] + ns}')\n",
    "    print(f'etajTX: {etajTX}')\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    \n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    \n",
    "\n",
    "    itv = [np.NINF, np.inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        itv = intersect(itv, get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "\n",
    "    sub_itv = [np.NINF, np.inf]\n",
    "    _, uo, vo = get_interval(X[O[0]+100].reshape(-1, 1), a[O[0]+100].reshape(-1, 1), b[O[0]+100].reshape(-1, 1))\n",
    "    I = np.ones((x_hat.shape[1],1))\n",
    "    for i in range(X.shape[0]):\n",
    "        if (i != O[0]+100):\n",
    "            _, ui, vi = get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "            u = uo - ui\n",
    "            v = vo - vi \n",
    "            u = I.T.dot(u)[0][0]\n",
    "            v = I.T.dot(v)[0][0]\n",
    "            sub__itv = solve_linear_inequality(-u, -v)\n",
    "            sub_itv = intersect(sub_itv, sub__itv)\n",
    "    itv = intersect(itv, sub_itv)\n",
    "\n",
    "    cdf = truncated_cdf(etajTX[0][0], etajTmu[0][0], np.sqrt(etajTsigmaetaj[0][0]), itv[0], itv[1])\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    print(f'p-value: {p_value}')\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #0:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.15433354]]\n",
      "p-value: 0.5698870236032749\n",
      "TPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #2:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.74170536]]\n",
      "p-value: 0.641705565019232\n",
      "TPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #3:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.43255213]]\n",
      "p-value: 0.9325104931615499\n",
      "TPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #4:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.36020554]]\n",
      "p-value: 0.04165180364796207\n",
      "TPR: 0.25\n",
      "-------------------------------------------------\n",
      "iteration #5:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.87376277]]\n",
      "p-value: 0.23499090721650084\n",
      "TPR: 0.2\n",
      "-------------------------------------------------\n",
      "iteration #6:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.10269843]]\n",
      "p-value: 0.01688698970044548\n",
      "TPR: 0.3333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #7:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.54375076]]\n",
      "p-value: 0.08006265139778194\n",
      "TPR: 0.2857142857142857\n",
      "-------------------------------------------------\n",
      "iteration #8:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.36839358]]\n",
      "p-value: 0.0077660862595505305\n",
      "TPR: 0.375\n",
      "-------------------------------------------------\n",
      "iteration #9:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.17292658]]\n",
      "p-value: 0.874564192566081\n",
      "TPR: 0.3333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #10:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.4200609]]\n",
      "p-value: 0.8447412941088922\n",
      "TPR: 0.3\n",
      "-------------------------------------------------\n",
      "iteration #11:\n",
      "Anomaly index: 107\n",
      "etajTX: [[2.88015514]]\n",
      "p-value: 0.03189075447799279\n",
      "TPR: 0.36363636363636365\n",
      "-------------------------------------------------\n",
      "iteration #12:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.13361168]]\n",
      "p-value: 0.659939122369351\n",
      "TPR: 0.3333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #13:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.62220679]]\n",
      "p-value: 0.1749160198260117\n",
      "TPR: 0.3076923076923077\n",
      "-------------------------------------------------\n",
      "iteration #14:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.29152256]]\n",
      "p-value: 0.006605984419496131\n",
      "TPR: 0.35714285714285715\n",
      "-------------------------------------------------\n",
      "iteration #15:\n",
      "Anomaly index: 109\n",
      "etajTX: [[3.67117924]]\n",
      "p-value: 0.002350048261300644\n",
      "TPR: 0.4\n",
      "-------------------------------------------------\n",
      "iteration #16:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.92750952]]\n",
      "p-value: 0.06601562825313309\n",
      "TPR: 0.375\n",
      "-------------------------------------------------\n",
      "iteration #17:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.92596647]]\n",
      "p-value: 0.008888391700800564\n",
      "TPR: 0.4117647058823529\n",
      "-------------------------------------------------\n",
      "iteration #18:\n",
      "Anomaly index: 103\n",
      "etajTX: [[4.24409421]]\n",
      "p-value: 0.0004586573606494838\n",
      "TPR: 0.4444444444444444\n",
      "-------------------------------------------------\n",
      "iteration #19:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.89814546]]\n",
      "p-value: 0.0036968055311368837\n",
      "TPR: 0.47368421052631576\n",
      "-------------------------------------------------\n",
      "iteration #20:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.84218958]]\n",
      "p-value: 0.8609852744077297\n",
      "TPR: 0.45\n",
      "-------------------------------------------------\n",
      "iteration #21:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.38500044]]\n",
      "p-value: 0.6813130299341266\n",
      "TPR: 0.42857142857142855\n",
      "-------------------------------------------------\n",
      "iteration #22:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.89567545]]\n",
      "p-value: 0.08378035200214577\n",
      "TPR: 0.4090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #23:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.12578413]]\n",
      "p-value: 0.0485235880923548\n",
      "TPR: 0.43478260869565216\n",
      "-------------------------------------------------\n",
      "iteration #24:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.47850566]]\n",
      "p-value: 0.13796403703782503\n",
      "TPR: 0.4166666666666667\n",
      "-------------------------------------------------\n",
      "iteration #25:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.86444558]]\n",
      "p-value: 0.20296494425728417\n",
      "TPR: 0.4\n",
      "-------------------------------------------------\n",
      "iteration #26:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.92290963]]\n",
      "p-value: 0.005450471348072692\n",
      "TPR: 0.4230769230769231\n",
      "-------------------------------------------------\n",
      "iteration #27:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.69062233]]\n",
      "p-value: 0.04468406065265596\n",
      "TPR: 0.4444444444444444\n",
      "-------------------------------------------------\n",
      "iteration #28:\n",
      "Anomaly index: 108\n",
      "etajTX: [[4.02818722]]\n",
      "p-value: 0.012780154624551782\n",
      "TPR: 0.4642857142857143\n",
      "-------------------------------------------------\n",
      "iteration #29:\n",
      "Anomaly index: 107\n",
      "etajTX: [[2.9141424]]\n",
      "p-value: 0.049119177161672065\n",
      "TPR: 0.4827586206896552\n",
      "-------------------------------------------------\n",
      "iteration #30:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.8686284]]\n",
      "p-value: 0.0025351676803182363\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #31:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.96744559]]\n",
      "p-value: 0.0031344661104683045\n",
      "TPR: 0.5161290322580645\n",
      "-------------------------------------------------\n",
      "iteration #32:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.51310984]]\n",
      "p-value: 0.1574058368807509\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #33:\n",
      "Anomaly index: 102\n",
      "etajTX: [[3.71065691]]\n",
      "p-value: 0.0029066986791609502\n",
      "TPR: 0.5151515151515151\n",
      "-------------------------------------------------\n",
      "iteration #34:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.76740562]]\n",
      "p-value: 0.06958481858851034\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #35:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.11616495]]\n",
      "p-value: 0.003324467819192713\n",
      "TPR: 0.5142857142857142\n",
      "-------------------------------------------------\n",
      "iteration #36:\n",
      "Anomaly index: 103\n",
      "etajTX: [[4.60836919]]\n",
      "p-value: 0.00274549438065802\n",
      "TPR: 0.5277777777777778\n",
      "-------------------------------------------------\n",
      "iteration #37:\n",
      "Anomaly index: 109\n",
      "etajTX: [[3.62962299]]\n",
      "p-value: 0.0038701166811683286\n",
      "TPR: 0.5405405405405406\n",
      "-------------------------------------------------\n",
      "iteration #38:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.94000053]]\n",
      "p-value: 0.10288364301575678\n",
      "TPR: 0.5263157894736842\n",
      "-------------------------------------------------\n",
      "iteration #39:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.94534281]]\n",
      "p-value: 0.8801359965001202\n",
      "TPR: 0.5128205128205128\n",
      "-------------------------------------------------\n",
      "iteration #40:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.59890111]]\n",
      "p-value: 0.9476143306857943\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #41:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.65639432]]\n",
      "p-value: 0.10187304961988794\n",
      "TPR: 0.4878048780487805\n",
      "-------------------------------------------------\n",
      "iteration #42:\n",
      "Anomaly index: 106\n",
      "etajTX: [[4.87263128]]\n",
      "p-value: 6.501887831149445e-05\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #43:\n",
      "Anomaly index: 108\n",
      "etajTX: [[4.04855792]]\n",
      "p-value: 0.001934730982052426\n",
      "TPR: 0.5116279069767442\n",
      "-------------------------------------------------\n",
      "iteration #44:\n",
      "Anomaly index: 107\n",
      "etajTX: [[2.98651801]]\n",
      "p-value: 0.13269197887271905\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #45:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.12723626]]\n",
      "p-value: 0.23208237705970478\n",
      "TPR: 0.4888888888888889\n",
      "-------------------------------------------------\n",
      "iteration #46:\n",
      "Anomaly index: 100\n",
      "etajTX: [[4.19136471]]\n",
      "p-value: 0.00042673355365029347\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #47:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.0207456]]\n",
      "p-value: 0.22196554324012993\n",
      "TPR: 0.48936170212765956\n",
      "-------------------------------------------------\n",
      "iteration #48:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.35964987]]\n",
      "p-value: 0.29967347178838943\n",
      "TPR: 0.4791666666666667\n",
      "-------------------------------------------------\n",
      "iteration #49:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.68141217]]\n",
      "p-value: 0.002280881268531782\n",
      "TPR: 0.4897959183673469\n",
      "-------------------------------------------------\n",
      "iteration #50:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.78521114]]\n",
      "p-value: 0.25287031589234266\n",
      "TPR: 0.48\n",
      "-------------------------------------------------\n",
      "iteration #51:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.23805216]]\n",
      "p-value: 0.4361493747488838\n",
      "TPR: 0.47058823529411764\n",
      "-------------------------------------------------\n",
      "iteration #52:\n",
      "Anomaly index: 106\n",
      "etajTX: [[4.0001422]]\n",
      "p-value: 0.0013732030154234088\n",
      "TPR: 0.4807692307692308\n",
      "-------------------------------------------------\n",
      "iteration #53:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.25701396]]\n",
      "p-value: 0.03453871506856298\n",
      "TPR: 0.49056603773584906\n",
      "-------------------------------------------------\n",
      "iteration #54:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.23365529]]\n",
      "p-value: 0.503499578887578\n",
      "TPR: 0.48148148148148145\n",
      "-------------------------------------------------\n",
      "iteration #55:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.78221448]]\n",
      "p-value: 0.06436785168807724\n",
      "TPR: 0.4727272727272727\n",
      "-------------------------------------------------\n",
      "iteration #56:\n",
      "Anomaly index: 109\n",
      "etajTX: [[3.67464828]]\n",
      "p-value: 0.002881917619196195\n",
      "TPR: 0.48214285714285715\n",
      "-------------------------------------------------\n",
      "iteration #57:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.59765561]]\n",
      "p-value: 0.030107743102259558\n",
      "TPR: 0.49122807017543857\n",
      "-------------------------------------------------\n",
      "iteration #58:\n",
      "Anomaly index: 105\n",
      "etajTX: [[3.26541307]]\n",
      "p-value: 0.02997328717173156\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #59:\n",
      "Anomaly index: 105\n",
      "etajTX: [[3.58285544]]\n",
      "p-value: 0.004315161786084283\n",
      "TPR: 0.5084745762711864\n",
      "-------------------------------------------------\n",
      "iteration #60:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.88494958]]\n",
      "p-value: 0.8196498224441856\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #61:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.94942898]]\n",
      "p-value: 0.46294675202287827\n",
      "TPR: 0.4918032786885246\n",
      "-------------------------------------------------\n",
      "iteration #62:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.06905958]]\n",
      "p-value: 0.08897415444751582\n",
      "TPR: 0.4838709677419355\n",
      "-------------------------------------------------\n",
      "iteration #63:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.34260114]]\n",
      "p-value: 0.01017580779309605\n",
      "TPR: 0.49206349206349204\n",
      "-------------------------------------------------\n",
      "iteration #64:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.03184446]]\n",
      "p-value: 0.023775816353409397\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #65:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.03973007]]\n",
      "p-value: 0.012631304532815791\n",
      "TPR: 0.5076923076923077\n",
      "-------------------------------------------------\n",
      "iteration #66:\n",
      "Anomaly index: 108\n",
      "etajTX: [[4.78229247]]\n",
      "p-value: 0.00017495021962382252\n",
      "TPR: 0.5151515151515151\n",
      "-------------------------------------------------\n",
      "iteration #67:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.17297724]]\n",
      "p-value: 0.457522378699971\n",
      "TPR: 0.5074626865671642\n",
      "-------------------------------------------------\n",
      "iteration #68:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.17654228]]\n",
      "p-value: 0.26356161625852215\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #69:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.81740125]]\n",
      "p-value: 0.05684314791347991\n",
      "TPR: 0.4927536231884058\n",
      "-------------------------------------------------\n",
      "iteration #70:\n",
      "Anomaly index: 109\n",
      "etajTX: [[3.70830684]]\n",
      "p-value: 0.004345009526681429\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #71:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.92664337]]\n",
      "p-value: 0.04271960729445888\n",
      "TPR: 0.5070422535211268\n",
      "-------------------------------------------------\n",
      "iteration #72:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.56523238]]\n",
      "p-value: 0.0044348748308199945\n",
      "TPR: 0.5138888888888888\n",
      "-------------------------------------------------\n",
      "iteration #73:\n",
      "Anomaly index: 104\n",
      "etajTX: [[4.08374935]]\n",
      "p-value: 0.006315602864385646\n",
      "TPR: 0.5205479452054794\n",
      "-------------------------------------------------\n",
      "iteration #74:\n",
      "Anomaly index: 102\n",
      "etajTX: [[4.57501051]]\n",
      "p-value: 7.95437837757013e-05\n",
      "TPR: 0.527027027027027\n",
      "-------------------------------------------------\n",
      "iteration #75:\n",
      "Anomaly index: 103\n",
      "etajTX: [[4.21445507]]\n",
      "p-value: 0.006424875588214517\n",
      "TPR: 0.5333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #76:\n",
      "Anomaly index: 106\n",
      "etajTX: [[4.66933123]]\n",
      "p-value: 0.00021688735929254252\n",
      "TPR: 0.5394736842105263\n",
      "-------------------------------------------------\n",
      "iteration #77:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.43596204]]\n",
      "p-value: 0.22195900849950895\n",
      "TPR: 0.5324675324675324\n",
      "-------------------------------------------------\n",
      "iteration #78:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.73014175]]\n",
      "p-value: 0.00011213671855922881\n",
      "TPR: 0.5384615384615384\n",
      "-------------------------------------------------\n",
      "iteration #79:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.72585699]]\n",
      "p-value: 0.07646058550314379\n",
      "TPR: 0.5316455696202531\n",
      "-------------------------------------------------\n",
      "iteration #80:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.88779937]]\n",
      "p-value: 0.003300177986833614\n",
      "TPR: 0.5375\n",
      "-------------------------------------------------\n",
      "iteration #81:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.72443983]]\n",
      "p-value: 0.17367087867087663\n",
      "TPR: 0.5308641975308642\n",
      "-------------------------------------------------\n",
      "iteration #82:\n",
      "Anomaly index: 103\n",
      "etajTX: [[4.00677299]]\n",
      "p-value: 0.007271208573483244\n",
      "TPR: 0.5365853658536586\n",
      "-------------------------------------------------\n",
      "iteration #83:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.56748009]]\n",
      "p-value: 0.0404553538667054\n",
      "TPR: 0.5421686746987951\n",
      "-------------------------------------------------\n",
      "iteration #84:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.78099759]]\n",
      "p-value: 0.16295536627816765\n",
      "TPR: 0.5357142857142857\n",
      "-------------------------------------------------\n",
      "iteration #85:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.44811291]]\n",
      "p-value: 0.015316552694749137\n",
      "TPR: 0.5411764705882353\n",
      "-------------------------------------------------\n",
      "iteration #86:\n",
      "Anomaly index: 105\n",
      "etajTX: [[4.60773489]]\n",
      "p-value: 8.395784437596919e-05\n",
      "TPR: 0.5465116279069767\n",
      "-------------------------------------------------\n",
      "iteration #87:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.24445089]]\n",
      "p-value: 0.03440014374787706\n",
      "TPR: 0.5517241379310345\n",
      "-------------------------------------------------\n",
      "iteration #88:\n",
      "Anomaly index: 109\n",
      "etajTX: [[3.0524381]]\n",
      "p-value: 0.16765377059412492\n",
      "TPR: 0.5454545454545454\n",
      "-------------------------------------------------\n",
      "iteration #89:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.1722463]]\n",
      "p-value: 0.92640767551667\n",
      "TPR: 0.5393258426966292\n",
      "-------------------------------------------------\n",
      "iteration #90:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.0904327]]\n",
      "p-value: 0.01830780501736923\n",
      "TPR: 0.5444444444444444\n",
      "-------------------------------------------------\n",
      "iteration #91:\n",
      "Anomaly index: 105\n",
      "etajTX: [[3.40676859]]\n",
      "p-value: 0.027060952204566505\n",
      "TPR: 0.5494505494505495\n",
      "-------------------------------------------------\n",
      "iteration #92:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.85235214]]\n",
      "p-value: 0.008261986077336707\n",
      "TPR: 0.5543478260869565\n",
      "-------------------------------------------------\n",
      "iteration #93:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.93700282]]\n",
      "p-value: 0.4836880238861673\n",
      "TPR: 0.5483870967741935\n",
      "-------------------------------------------------\n",
      "iteration #94:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.06685575]]\n",
      "p-value: 0.22796629088840822\n",
      "TPR: 0.5425531914893617\n",
      "-------------------------------------------------\n",
      "iteration #95:\n",
      "Anomaly index: 109\n",
      "etajTX: [[3.37882169]]\n",
      "p-value: 0.05461337478112737\n",
      "TPR: 0.5368421052631579\n",
      "-------------------------------------------------\n",
      "iteration #96:\n",
      "Anomaly index: 107\n",
      "etajTX: [[2.56203567]]\n",
      "p-value: 0.14277499857164183\n",
      "TPR: 0.53125\n",
      "-------------------------------------------------\n",
      "iteration #97:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.14329041]]\n",
      "p-value: 0.4110796557933388\n",
      "TPR: 0.5257731958762887\n",
      "-------------------------------------------------\n",
      "iteration #98:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.04839092]]\n",
      "p-value: 0.040737793647535506\n",
      "TPR: 0.5306122448979592\n",
      "-------------------------------------------------\n",
      "iteration #99:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.72852601]]\n",
      "p-value: 0.31473782238868286\n",
      "TPR: 0.5252525252525253\n",
      "-------------------------------------------------\n",
      "iteration #100:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.55661731]]\n",
      "p-value: 0.13545612998839\n",
      "TPR: 0.52\n",
      "-------------------------------------------------\n",
      "iteration #101:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.65337563]]\n",
      "p-value: 0.003353684155674507\n",
      "TPR: 0.5247524752475248\n",
      "-------------------------------------------------\n",
      "iteration #102:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.19222344]]\n",
      "p-value: 0.022856752360065256\n",
      "TPR: 0.5294117647058824\n",
      "-------------------------------------------------\n",
      "iteration #103:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.13596853]]\n",
      "p-value: 0.30200439891802416\n",
      "TPR: 0.5242718446601942\n",
      "-------------------------------------------------\n",
      "iteration #104:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.27550782]]\n",
      "p-value: 0.2144284178422791\n",
      "TPR: 0.5192307692307693\n",
      "-------------------------------------------------\n",
      "iteration #105:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.04173194]]\n",
      "p-value: 0.059445096178682925\n",
      "TPR: 0.5142857142857142\n",
      "-------------------------------------------------\n",
      "iteration #106:\n",
      "Anomaly index: 102\n",
      "etajTX: [[4.02671602]]\n",
      "p-value: 0.005549666969468665\n",
      "TPR: 0.5188679245283019\n",
      "-------------------------------------------------\n",
      "iteration #107:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.67300966]]\n",
      "p-value: 0.6986958205063838\n",
      "TPR: 0.514018691588785\n",
      "-------------------------------------------------\n",
      "iteration #108:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.9125078]]\n",
      "p-value: 0.0912443556085615\n",
      "TPR: 0.5092592592592593\n",
      "-------------------------------------------------\n",
      "iteration #109:\n",
      "Anomaly index: 109\n",
      "etajTX: [[3.40999434]]\n",
      "p-value: 0.009951994591639007\n",
      "TPR: 0.5137614678899083\n",
      "-------------------------------------------------\n",
      "iteration #110:\n",
      "Anomaly index: 100\n",
      "etajTX: [[4.35538801]]\n",
      "p-value: 0.00044002040115335533\n",
      "TPR: 0.5181818181818182\n",
      "-------------------------------------------------\n",
      "iteration #111:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.34238561]]\n",
      "p-value: 0.001359711906787625\n",
      "TPR: 0.5225225225225225\n",
      "-------------------------------------------------\n",
      "iteration #112:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.94108454]]\n",
      "p-value: 0.000949587361076304\n",
      "TPR: 0.5267857142857143\n",
      "-------------------------------------------------\n",
      "iteration #113:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.22653092]]\n",
      "p-value: 0.9001105244302502\n",
      "TPR: 0.5221238938053098\n",
      "-------------------------------------------------\n",
      "iteration #114:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.31636153]]\n",
      "p-value: 0.011783383007941132\n",
      "TPR: 0.5263157894736842\n",
      "-------------------------------------------------\n",
      "iteration #115:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.74912135]]\n",
      "p-value: 0.0029993520919105662\n",
      "TPR: 0.5304347826086957\n",
      "-------------------------------------------------\n",
      "iteration #116:\n",
      "Anomaly index: 100\n",
      "etajTX: [[5.00534693]]\n",
      "p-value: 3.4625529650028874e-05\n",
      "TPR: 0.5344827586206896\n",
      "-------------------------------------------------\n",
      "iteration #117:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.3135696]]\n",
      "p-value: 0.021383302741238376\n",
      "TPR: 0.5384615384615384\n",
      "-------------------------------------------------\n",
      "iteration #118:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.90626611]]\n",
      "p-value: 0.29445846244375207\n",
      "TPR: 0.5338983050847458\n",
      "-------------------------------------------------\n",
      "iteration #119:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.6589489]]\n",
      "p-value: 0.23641392402236963\n",
      "TPR: 0.5294117647058824\n",
      "-------------------------------------------------\n",
      "iteration #120:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.28459146]]\n",
      "p-value: 0.02175908449003906\n",
      "TPR: 0.5333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #121:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.4297053]]\n",
      "p-value: 0.6829053715596671\n",
      "TPR: 0.5289256198347108\n",
      "-------------------------------------------------\n",
      "iteration #122:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "max_iteration = 120\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "print(f'iteration #{0}:')\n",
    "\n",
    "\n",
    "while len(list_p_value) <= max_iteration:\n",
    "    p_value = run_tpr()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "    print(f'TPR: {count / len(list_p_value)}')\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'iteration #{len(list_p_value)+1}:')\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fpr():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = [4], [0]\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < 100):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - 100]   \n",
    "\n",
    "    Oc = list(np.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "\n",
    "    etajTX = etaj.T.dot(X)\n",
    "    print(f'Anomaly index: {O[0] + ns}')\n",
    "    print(f'etajTX: {etajTX}')\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    \n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    \n",
    "\n",
    "    itv = [np.NINF, np.inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        itv = intersect(itv, get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "\n",
    "    sub_itv = [np.NINF, np.inf]\n",
    "    _, uo, vo = get_interval(X[O[0]+100].reshape(-1, 1), a[O[0]+100].reshape(-1, 1), b[O[0]+100].reshape(-1, 1))\n",
    "    I = np.ones((x_hat.shape[1],1))\n",
    "    for i in range(X.shape[0]):\n",
    "        if (i != O[0]+100):\n",
    "            _, ui, vi = get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "            u = uo - ui\n",
    "            v = vo - vi \n",
    "            u = I.T.dot(u)[0][0]\n",
    "            v = I.T.dot(v)[0][0]\n",
    "            sub__itv = solve_linear_inequality(-u, -v)\n",
    "            sub_itv = intersect(sub_itv, sub__itv)\n",
    "    itv = intersect(itv, sub_itv)\n",
    "\n",
    "    cdf = truncated_cdf(etajTX[0][0], etajTmu[0][0], np.sqrt(etajTsigmaetaj[0][0]), itv[0], itv[1])\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    print(f'p-value: {p_value}')\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #0:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-2.83187224]]\n",
      "p-value: 0.6571974985679299\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #2:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-1.89908043]]\n",
      "p-value: 0.6313867115836984\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #3:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.52589023]]\n",
      "p-value: 0.859513544719767\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #4:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-1.48968299]]\n",
      "p-value: 0.621104946674676\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #5:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.8630974]]\n",
      "p-value: 0.21946897666607765\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #6:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-2.44204455]]\n",
      "p-value: 0.5382640829542408\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #7:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.49353241]]\n",
      "p-value: 0.6410632548976397\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #8:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-1.78626428]]\n",
      "p-value: 0.10589176744015182\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #9:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.7045607]]\n",
      "p-value: 0.5746484767947184\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #10:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-3.21906428]]\n",
      "p-value: 0.050939619948250574\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #11:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.13389792]]\n",
      "p-value: 0.35604431716104895\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #12:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-3.29744025]]\n",
      "p-value: 0.49627576044684885\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #13:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-3.21601866]]\n",
      "p-value: 0.3277009395697876\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #14:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.14901806]]\n",
      "p-value: 0.31067244310831643\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #15:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.1568558]]\n",
      "p-value: 0.6557848026891574\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #16:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-2.3438837]]\n",
      "p-value: 0.27467284730959723\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #17:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-1.44544005]]\n",
      "p-value: 0.8398675773208858\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #18:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.34675854]]\n",
      "p-value: 0.06728722761192746\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #19:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-2.1129814]]\n",
      "p-value: 0.5815483256038846\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #20:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.53726282]]\n",
      "p-value: 0.9512007049637661\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #21:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-2.31176007]]\n",
      "p-value: 0.7064058732250634\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #22:\n",
      "Anomaly index: 105\n",
      "etajTX: [[-2.79006045]]\n",
      "p-value: 0.1425585296908996\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #23:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-2.36015362]]\n",
      "p-value: 0.5049951952689605\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #24:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-1.97037803]]\n",
      "p-value: 0.75145901143876\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #25:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.5211839]]\n",
      "p-value: 0.3233732359433234\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #26:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.60495828]]\n",
      "p-value: 0.9739252392637135\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #27:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.30357804]]\n",
      "p-value: 0.1575362783216151\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #28:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.6780711]]\n",
      "p-value: 0.20823538733272062\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #29:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.24279017]]\n",
      "p-value: 0.3928138765840722\n",
      "FPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #30:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.40322683]]\n",
      "p-value: 0.026415604042028695\n",
      "FPR: 0.03333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #31:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-1.75576697]]\n",
      "p-value: 0.4877251470209669\n",
      "FPR: 0.03225806451612903\n",
      "-------------------------------------------------\n",
      "iteration #32:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-1.97810625]]\n",
      "p-value: 0.4995866951255748\n",
      "FPR: 0.03125\n",
      "-------------------------------------------------\n",
      "iteration #33:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.24693691]]\n",
      "p-value: 0.3898160784095288\n",
      "FPR: 0.030303030303030304\n",
      "-------------------------------------------------\n",
      "iteration #34:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-1.71289553]]\n",
      "p-value: 0.5576474473206731\n",
      "FPR: 0.029411764705882353\n",
      "-------------------------------------------------\n",
      "iteration #35:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.24765447]]\n",
      "p-value: 0.08489020394293015\n",
      "FPR: 0.02857142857142857\n",
      "-------------------------------------------------\n",
      "iteration #36:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-1.5091251]]\n",
      "p-value: 0.4961882459471072\n",
      "FPR: 0.027777777777777776\n",
      "-------------------------------------------------\n",
      "iteration #37:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.04702432]]\n",
      "p-value: 0.5520291449704194\n",
      "FPR: 0.02702702702702703\n",
      "-------------------------------------------------\n",
      "iteration #38:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.57408508]]\n",
      "p-value: 0.011896500295653614\n",
      "FPR: 0.05263157894736842\n",
      "-------------------------------------------------\n",
      "iteration #39:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.28237355]]\n",
      "p-value: 0.924124958183875\n",
      "FPR: 0.05128205128205128\n",
      "-------------------------------------------------\n",
      "iteration #40:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.55939579]]\n",
      "p-value: 0.5316348560119468\n",
      "FPR: 0.05\n",
      "-------------------------------------------------\n",
      "iteration #41:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-2.32387684]]\n",
      "p-value: 0.22486181027394006\n",
      "FPR: 0.04878048780487805\n",
      "-------------------------------------------------\n",
      "iteration #42:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-2.84361645]]\n",
      "p-value: 0.32033486061287486\n",
      "FPR: 0.047619047619047616\n",
      "-------------------------------------------------\n",
      "iteration #43:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-1.94738492]]\n",
      "p-value: 0.5187408405762144\n",
      "FPR: 0.046511627906976744\n",
      "-------------------------------------------------\n",
      "iteration #44:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.59327601]]\n",
      "p-value: 0.23542829753922404\n",
      "FPR: 0.045454545454545456\n",
      "-------------------------------------------------\n",
      "iteration #45:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-3.44146733]]\n",
      "p-value: 0.009655336860821475\n",
      "FPR: 0.06666666666666667\n",
      "-------------------------------------------------\n",
      "iteration #46:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-2.83474218]]\n",
      "p-value: 0.8956147917426209\n",
      "FPR: 0.06521739130434782\n",
      "-------------------------------------------------\n",
      "iteration #47:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-1.62041347]]\n",
      "p-value: 0.9340821909521209\n",
      "FPR: 0.06382978723404255\n",
      "-------------------------------------------------\n",
      "iteration #48:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.37577253]]\n",
      "p-value: 0.7173787848898189\n",
      "FPR: 0.0625\n",
      "-------------------------------------------------\n",
      "iteration #49:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.16044151]]\n",
      "p-value: 0.3401134390586021\n",
      "FPR: 0.061224489795918366\n",
      "-------------------------------------------------\n",
      "iteration #50:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-1.81388899]]\n",
      "p-value: 0.3343696101666583\n",
      "FPR: 0.06\n",
      "-------------------------------------------------\n",
      "iteration #51:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.36771522]]\n",
      "p-value: 0.47424230724361843\n",
      "FPR: 0.058823529411764705\n",
      "-------------------------------------------------\n",
      "iteration #52:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-1.61144178]]\n",
      "p-value: 0.6538615305602481\n",
      "FPR: 0.057692307692307696\n",
      "-------------------------------------------------\n",
      "iteration #53:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-1.73647003]]\n",
      "p-value: 0.75192080594907\n",
      "FPR: 0.05660377358490566\n",
      "-------------------------------------------------\n",
      "iteration #54:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-1.65512171]]\n",
      "p-value: 0.9259135976582576\n",
      "FPR: 0.05555555555555555\n",
      "-------------------------------------------------\n",
      "iteration #55:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-3.16810625]]\n",
      "p-value: 0.023175978543169006\n",
      "FPR: 0.07272727272727272\n",
      "-------------------------------------------------\n",
      "iteration #56:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-1.98273551]]\n",
      "p-value: 0.04135304279344655\n",
      "FPR: 0.08928571428571429\n",
      "-------------------------------------------------\n",
      "iteration #57:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.40737296]]\n",
      "p-value: 0.49681420467236564\n",
      "FPR: 0.08771929824561403\n",
      "-------------------------------------------------\n",
      "iteration #58:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-1.88605789]]\n",
      "p-value: 0.6138399480824929\n",
      "FPR: 0.08620689655172414\n",
      "-------------------------------------------------\n",
      "iteration #59:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.14196823]]\n",
      "p-value: 0.6948546049737861\n",
      "FPR: 0.0847457627118644\n",
      "-------------------------------------------------\n",
      "iteration #60:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-1.91776522]]\n",
      "p-value: 0.15741143581549902\n",
      "FPR: 0.08333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #61:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-1.51233181]]\n",
      "p-value: 0.47581777315821966\n",
      "FPR: 0.08196721311475409\n",
      "-------------------------------------------------\n",
      "iteration #62:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.00819274]]\n",
      "p-value: 0.28185693274404194\n",
      "FPR: 0.08064516129032258\n",
      "-------------------------------------------------\n",
      "iteration #63:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-1.78227475]]\n",
      "p-value: 0.46358475258363285\n",
      "FPR: 0.07936507936507936\n",
      "-------------------------------------------------\n",
      "iteration #64:\n",
      "Anomaly index: 105\n",
      "etajTX: [[-2.59968521]]\n",
      "p-value: 0.6757196628364398\n",
      "FPR: 0.078125\n",
      "-------------------------------------------------\n",
      "iteration #65:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.33797045]]\n",
      "p-value: 0.017409897092503183\n",
      "FPR: 0.09230769230769231\n",
      "-------------------------------------------------\n",
      "iteration #66:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-1.36108017]]\n",
      "p-value: 0.6841374363170271\n",
      "FPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #67:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-1.61662433]]\n",
      "p-value: 0.5456715678263507\n",
      "FPR: 0.08955223880597014\n",
      "-------------------------------------------------\n",
      "iteration #68:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.3932304]]\n",
      "p-value: 0.636794487262019\n",
      "FPR: 0.08823529411764706\n",
      "-------------------------------------------------\n",
      "iteration #69:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.22012609]]\n",
      "p-value: 0.03552018395114962\n",
      "FPR: 0.10144927536231885\n",
      "-------------------------------------------------\n",
      "iteration #70:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.41832316]]\n",
      "p-value: 0.21605121107693723\n",
      "FPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #71:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.15287836]]\n",
      "p-value: 0.6449413633043874\n",
      "FPR: 0.09859154929577464\n",
      "-------------------------------------------------\n",
      "iteration #72:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-3.44385939]]\n",
      "p-value: 0.014634179539338689\n",
      "FPR: 0.1111111111111111\n",
      "-------------------------------------------------\n",
      "iteration #73:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-2.97037848]]\n",
      "p-value: 0.21097170643257124\n",
      "FPR: 0.1095890410958904\n",
      "-------------------------------------------------\n",
      "iteration #74:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.37353038]]\n",
      "p-value: 0.5134436643016772\n",
      "FPR: 0.10810810810810811\n",
      "-------------------------------------------------\n",
      "iteration #75:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-1.58734556]]\n",
      "p-value: 0.8917244313625757\n",
      "FPR: 0.10666666666666667\n",
      "-------------------------------------------------\n",
      "iteration #76:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-2.80401965]]\n",
      "p-value: 0.38269603897386967\n",
      "FPR: 0.10526315789473684\n",
      "-------------------------------------------------\n",
      "iteration #77:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-2.46671088]]\n",
      "p-value: 0.16755614194965604\n",
      "FPR: 0.1038961038961039\n",
      "-------------------------------------------------\n",
      "iteration #78:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.05761105]]\n",
      "p-value: 0.06090434736702219\n",
      "FPR: 0.10256410256410256\n",
      "-------------------------------------------------\n",
      "iteration #79:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.87641217]]\n",
      "p-value: 0.27514387000510543\n",
      "FPR: 0.10126582278481013\n",
      "-------------------------------------------------\n",
      "iteration #80:\n",
      "Anomaly index: 105\n",
      "etajTX: [[-2.80724718]]\n",
      "p-value: 0.24016208152522195\n",
      "FPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #81:\n",
      "Anomaly index: 105\n",
      "etajTX: [[-2.7225128]]\n",
      "p-value: 0.45553673850097093\n",
      "FPR: 0.09876543209876543\n",
      "-------------------------------------------------\n",
      "iteration #82:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-3.02804105]]\n",
      "p-value: 0.031573867902112106\n",
      "FPR: 0.10975609756097561\n",
      "-------------------------------------------------\n",
      "iteration #83:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.12054631]]\n",
      "p-value: 0.9929831370431713\n",
      "FPR: 0.10843373493975904\n",
      "-------------------------------------------------\n",
      "iteration #84:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-2.27721931]]\n",
      "p-value: 0.9716934312571884\n",
      "FPR: 0.10714285714285714\n",
      "-------------------------------------------------\n",
      "iteration #85:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-1.91274586]]\n",
      "p-value: 0.5716899514312259\n",
      "FPR: 0.10588235294117647\n",
      "-------------------------------------------------\n",
      "iteration #86:\n",
      "Anomaly index: 105\n",
      "etajTX: [[-2.3677259]]\n",
      "p-value: 0.09701714000332302\n",
      "FPR: 0.10465116279069768\n",
      "-------------------------------------------------\n",
      "iteration #87:\n",
      "Anomaly index: 105\n",
      "etajTX: [[-2.71245708]]\n",
      "p-value: 0.3467794069219479\n",
      "FPR: 0.10344827586206896\n",
      "-------------------------------------------------\n",
      "iteration #88:\n",
      "Anomaly index: 105\n",
      "etajTX: [[-2.85165673]]\n",
      "p-value: 0.21694060877061447\n",
      "FPR: 0.10227272727272728\n",
      "-------------------------------------------------\n",
      "iteration #89:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.04751839]]\n",
      "p-value: 0.2494421125990113\n",
      "FPR: 0.10112359550561797\n",
      "-------------------------------------------------\n",
      "iteration #90:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.16850727]]\n",
      "p-value: 0.6552164436411715\n",
      "FPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #91:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-1.84398402]]\n",
      "p-value: 0.5860022632269091\n",
      "FPR: 0.0989010989010989\n",
      "-------------------------------------------------\n",
      "iteration #92:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-1.57241142]]\n",
      "p-value: 0.9190604088979563\n",
      "FPR: 0.09782608695652174\n",
      "-------------------------------------------------\n",
      "iteration #93:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-2.67190223]]\n",
      "p-value: 0.2093525040274766\n",
      "FPR: 0.0967741935483871\n",
      "-------------------------------------------------\n",
      "iteration #94:\n",
      "Anomaly index: 100\n",
      "etajTX: [[-1.68082449]]\n",
      "p-value: 0.3573463482310834\n",
      "FPR: 0.09574468085106383\n",
      "-------------------------------------------------\n",
      "iteration #95:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.29791494]]\n",
      "p-value: 0.9156660742207307\n",
      "FPR: 0.09473684210526316\n",
      "-------------------------------------------------\n",
      "iteration #96:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-1.96783844]]\n",
      "p-value: 0.6103028011830318\n",
      "FPR: 0.09375\n",
      "-------------------------------------------------\n",
      "iteration #97:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.11238749]]\n",
      "p-value: 0.7038065138987541\n",
      "FPR: 0.09278350515463918\n",
      "-------------------------------------------------\n",
      "iteration #98:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.71275936]]\n",
      "p-value: 0.8258445583570805\n",
      "FPR: 0.09183673469387756\n",
      "-------------------------------------------------\n",
      "iteration #99:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.23580117]]\n",
      "p-value: 0.12561625175131463\n",
      "FPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #100:\n",
      "Anomaly index: 106\n",
      "etajTX: [[-2.52938752]]\n",
      "p-value: 0.8531354230500939\n",
      "FPR: 0.09\n",
      "-------------------------------------------------\n",
      "iteration #101:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.32080817]]\n",
      "p-value: 0.06803554074661357\n",
      "FPR: 0.0891089108910891\n",
      "-------------------------------------------------\n",
      "iteration #102:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.53903714]]\n",
      "p-value: 0.6337030322714554\n",
      "FPR: 0.08823529411764706\n",
      "-------------------------------------------------\n",
      "iteration #103:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.07171711]]\n",
      "p-value: 0.17679025211785043\n",
      "FPR: 0.08737864077669903\n",
      "-------------------------------------------------\n",
      "iteration #104:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-3.27778084]]\n",
      "p-value: 0.9780058040715578\n",
      "FPR: 0.08653846153846154\n",
      "-------------------------------------------------\n",
      "iteration #105:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.05139712]]\n",
      "p-value: 0.9761894252947806\n",
      "FPR: 0.08571428571428572\n",
      "-------------------------------------------------\n",
      "iteration #106:\n",
      "Anomaly index: 104\n",
      "etajTX: [[-2.18485496]]\n",
      "p-value: 0.49930007718656694\n",
      "FPR: 0.08490566037735849\n",
      "-------------------------------------------------\n",
      "iteration #107:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-2.29087974]]\n",
      "p-value: 0.6219373748545426\n",
      "FPR: 0.08411214953271028\n",
      "-------------------------------------------------\n",
      "iteration #108:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.01092413]]\n",
      "p-value: 0.7208872696030154\n",
      "FPR: 0.08333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #109:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-1.53685337]]\n",
      "p-value: 0.14727605098574395\n",
      "FPR: 0.08256880733944955\n",
      "-------------------------------------------------\n",
      "iteration #110:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.1353864]]\n",
      "p-value: 0.283711193872353\n",
      "FPR: 0.08181818181818182\n",
      "-------------------------------------------------\n",
      "iteration #111:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.30516087]]\n",
      "p-value: 0.7267417727841357\n",
      "FPR: 0.08108108108108109\n",
      "-------------------------------------------------\n",
      "iteration #112:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-2.33852299]]\n",
      "p-value: 0.392638261073442\n",
      "FPR: 0.08035714285714286\n",
      "-------------------------------------------------\n",
      "iteration #113:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.0206003]]\n",
      "p-value: 0.6658377355363713\n",
      "FPR: 0.07964601769911504\n",
      "-------------------------------------------------\n",
      "iteration #114:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-1.60122911]]\n",
      "p-value: 0.2068326692631006\n",
      "FPR: 0.07894736842105263\n",
      "-------------------------------------------------\n",
      "iteration #115:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-1.51350554]]\n",
      "p-value: 0.6267547210344567\n",
      "FPR: 0.0782608695652174\n",
      "-------------------------------------------------\n",
      "iteration #116:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-3.09018291]]\n",
      "p-value: 0.31945116060622536\n",
      "FPR: 0.07758620689655173\n",
      "-------------------------------------------------\n",
      "iteration #117:\n",
      "Anomaly index: 108\n",
      "etajTX: [[-2.4257182]]\n",
      "p-value: 0.9168357555806006\n",
      "FPR: 0.07692307692307693\n",
      "-------------------------------------------------\n",
      "iteration #118:\n",
      "Anomaly index: 103\n",
      "etajTX: [[-2.09274746]]\n",
      "p-value: 0.23387068926797258\n",
      "FPR: 0.07627118644067797\n",
      "-------------------------------------------------\n",
      "iteration #119:\n",
      "Anomaly index: 101\n",
      "etajTX: [[-3.14186968]]\n",
      "p-value: 0.11993950845837598\n",
      "FPR: 0.07563025210084033\n",
      "-------------------------------------------------\n",
      "iteration #120:\n",
      "Anomaly index: 107\n",
      "etajTX: [[-2.50252417]]\n",
      "p-value: 0.8239861337503473\n",
      "FPR: 0.075\n",
      "-------------------------------------------------\n",
      "iteration #121:\n",
      "Anomaly index: 109\n",
      "etajTX: [[-2.39291537]]\n",
      "p-value: 0.8763219918070445\n",
      "FPR: 0.0743801652892562\n",
      "-------------------------------------------------\n",
      "iteration #122:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "max_iteration = 120\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "print(f'iteration #{0}:')\n",
    "\n",
    "\n",
    "while len(list_p_value) <= max_iteration:\n",
    "    p_value = run_fpr()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "    print(f'FPR: {count / len(list_p_value)}')\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'iteration #{len(list_p_value)+1}:')\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
