{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gen_data(mu, delta, n, d: int = 2):\n",
    "    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))\n",
    "    mu = np.full((n, d), mu, dtype=np.float64)\n",
    "\n",
    "    if len(delta) == 1 and delta[0] == 0:\n",
    "        return mu + noise, np.zeros(n)\n",
    "    \n",
    "    # 10% of the data are abnormal\n",
    "    m = len(delta)\n",
    "    abnormal_idx = np.random.choice(n, int(n/10), replace=False)\n",
    "\n",
    "    ptr = 0\n",
    "    for i in range(m):\n",
    "        for j in range(len(abnormal_idx)//m):\n",
    "            mu[abnormal_idx[ptr], :] += delta[i]\n",
    "            ptr += 1\n",
    "    \n",
    "    X = mu + noise \n",
    "    Y = np.zeros(n)\n",
    "    Y[abnormal_idx] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Feature extractor network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Domain critic network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class WDGRL():\n",
    "    def __init__(self, input_dim: int=2, generator_hidden_dims: List[int]=[32, 16, 8, 4, 2], critic_hidden_dims: List[int]=[32, 16, 8, 4, 2],\n",
    "                 gamma: float = 0.1, _lr_generator: float = 1e-2, _lr_critic: float = 1e-2, \n",
    "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.generator = Generator(input_dim, generator_hidden_dims).to(self.device)\n",
    "        self.critic = Critic(generator_hidden_dims[-1], critic_hidden_dims).to(self.device)\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=_lr_generator)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=_lr_critic)\n",
    "    \n",
    "    def compute_gradient_penalty(self, source_data: torch.Tensor, target_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute gradient penalty.\"\"\"\n",
    "        if source_data.size(0) > target_data.size(0):\n",
    "            ms = source_data.size(0)\n",
    "            mt = target_data.size(0)\n",
    "            gradient_penalty = 0\n",
    "            for _ in range(0, ms, mt):\n",
    "                source_chunk = source_data[_:_+mt]\n",
    "                target_chunk = target_data\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            if ms % mt != 0:\n",
    "                source_chunk = source_data[ms-mt:]\n",
    "                perm = torch.randperm(mt)\n",
    "                idx = perm[:ms % mt]\n",
    "                target_chunk = target_data[idx]\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            return gradient_penalty / ((ms // mt) + (ms % mt != 0)) \n",
    "        \n",
    "        # For balanced batch\n",
    "        alpha = torch.rand(source_data.size(0), 1).to(self.device)\n",
    "        interpolates = (alpha * source_data + ((1 - alpha) * target_data)).requires_grad_(True)\n",
    "        \n",
    "        # Domain critic outputs\n",
    "        dc_output = self.critic(interpolates)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=dc_output,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        # Compute gradient penalty\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    def train(self, source_loader: DataLoader, target_loader: DataLoader, num_epochs: int = 100, dc_iter: int = 100) -> List[float]:\n",
    "        self.generator.train()\n",
    "        self.critic.train()\n",
    "        losses = []\n",
    "        source_critic_scores = []\n",
    "        target_critic_scores = []\n",
    "        for epoch in trange(num_epochs, desc='Epoch'):\n",
    "            loss = 0\n",
    "            for (source_data, _), (target_data, _) in zip(source_loader, target_loader):\n",
    "                source_data, target_data = source_data.to(self.device), target_data.to(self.device)\n",
    "\n",
    "                # Train domain critic\n",
    "                for _ in range(dc_iter):\n",
    "                    self.critic_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        source_features = self.generator(source_data)\n",
    "                        target_features = self.generator(target_data)\n",
    "                    \n",
    "                    # Compute empirical Wasserstein distance\n",
    "                    dc_source = self.critic(source_features)\n",
    "                    dc_target = self.critic(target_features)\n",
    "                    wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.compute_gradient_penalty(source_features, target_features)\n",
    "\n",
    "                    # Domain critic loss\n",
    "                    dc_loss = - wasserstein_distance + self.gamma * gradient_penalty\n",
    "                    dc_loss.backward()\n",
    "                    self.critic_optimizer.step()\n",
    "\n",
    "                # Train feature extractor\n",
    "                self.generator_optimizer.zero_grad()\n",
    "                source_features = self.generator(source_data)\n",
    "                target_features = self.generator(target_data)\n",
    "                dc_source = self.critic(source_features)\n",
    "                dc_target = self.critic(target_features)\n",
    "                wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "                wasserstein_distance.backward()\n",
    "                self.generator_optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    loss += wasserstein_distance.item()\n",
    "                    \n",
    "            source_critic_scores.append(self.criticize(source_loader.dataset.tensors[0].to(self.device)))\n",
    "            target_critic_scores.append(self.criticize(target_loader.dataset.tensors[0].to(self.device)))\n",
    "            losses.append(loss/len(source_loader))\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | Loss: {wasserstein_distance.item()}')\n",
    "        return losses, source_critic_scores, target_critic_scores\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_feature(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.generator.eval()\n",
    "        return self.generator(x)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def criticize(self, x: torch.Tensor) -> float:\n",
    "        self.generator.eval()\n",
    "        self.critic.eval()\n",
    "        return self.critic(self.generator(x)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the WDGRL model (same architecture as before)\n",
    "model = WDGRL(input_dim=1,generator_hidden_dims=[10, 10, 10], critic_hidden_dims=[10])\n",
    "\n",
    "# Load the saved checkpoint\n",
    "checkpoint = torch.load(\"wdgrl.pth\", map_location=model.device, weights_only=True)\n",
    "\n",
    "# Restore the model weights\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Create synthetic dataset and dataloaders for domain adaptation.\"\"\"\n",
    "# Create datasets\n",
    "ns, nt, d = 100, 10, 1\n",
    "mu_s, mu_t = 0, 20\n",
    "delta_s, delta_t = [4], [4]\n",
    "xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "plt.scatter(xs[:, 0], np.zeros_like(xs[:, 0]), c=ys, cmap='viridis', s=2)\n",
    "plt.scatter(xt[:, 0], np.zeros_like(xt[:, 0]), c=yt, cmap='cool', s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.FloatTensor(xs)\n",
    "ys = torch.LongTensor(ys)\n",
    "xt = torch.FloatTensor(xt)\n",
    "yt = torch.LongTensor(yt)\n",
    "xs_hat = model.extract_feature(xs.cuda())\n",
    "xt_hat = model.extract_feature(xt.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_sum(X):\n",
    "    return np.argmax(np.sum(X, axis=1))\n",
    "x_hat = torch.cat([xs_hat, xt_hat], dim=0).cpu().numpy()\n",
    "print(x_hat)\n",
    "O = max_sum(x_hat)\n",
    "O = [O-ns]\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_hat = torch.zeros_like(yt)\n",
    "yt_hat[O[0]] = 1\n",
    "print(yt)\n",
    "yt_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(yt, yt_hat)\n",
    "precision = precision_score(yt, yt_hat)\n",
    "recall = recall_score(yt, yt_hat)\n",
    "f1 = f1_score(yt, yt_hat)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(yt, yt_hat))\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(yt, yt_hat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpmath import mp\n",
    "\n",
    "mp.dps = 500\n",
    "def intersect(itv1, itv2):\n",
    "    # print(itv1, itv2)\n",
    "    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]\n",
    "    if itv[0] > itv[1]:\n",
    "        return None    \n",
    "    return itv\n",
    "\n",
    "def solve_linear_inequality(u, v): #u + vz < 0\n",
    "    u = float(u)\n",
    "    v = float(v)\n",
    "    if (v > -1e-16 and v < 1e-16):\n",
    "        if (u < 0):\n",
    "            return [-np.Inf, np.Inf]\n",
    "        else:\n",
    "            print('error')\n",
    "            return None\n",
    "    if (v < 0):\n",
    "        return [-u/v, np.Inf]\n",
    "    return [np.NINF, -u/v]\n",
    "\n",
    "def get_dnn_interval(Xtj, a, b):\n",
    "    layers = []\n",
    "\n",
    "    for name, param in model.generator.named_children():\n",
    "        temp = dict(param._modules)\n",
    "        \n",
    "        for layer_name in temp.values():\n",
    "            if ('Linear' in str(layer_name)):\n",
    "                layers.append('Linear')\n",
    "            elif ('ReLU' in str(layer_name)):\n",
    "                layers.append('ReLU')\n",
    "\n",
    "    ptr = 0\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    u = a\n",
    "    v = b\n",
    "    temp = Xtj\n",
    "    weight = None\n",
    "    bias = None\n",
    "    for name, param in model.generator.named_parameters():\n",
    "        if (layers[ptr] == 'Linear'):\n",
    "            if ('weight' in name):\n",
    "                weight = param.data.cpu().detach().numpy()\n",
    "            elif ('bias' in name):\n",
    "                bias = param.data.cpu().detach().numpy().reshape(-1, 1)\n",
    "                ptr += 1\n",
    "                temp = weight.dot(temp) + bias\n",
    "                u = weight.dot(u) + bias\n",
    "                v = weight.dot(v)\n",
    "\n",
    "        if (ptr < len(layers) and layers[ptr] == 'ReLU'):\n",
    "            ptr += 1\n",
    "            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))\n",
    "            sub_itv = [np.NINF, np.inf]\n",
    "            for i in range(temp.shape[0]):\n",
    "                if temp[i] > 0:\n",
    "                    Relu_matrix[i][i] = 1\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i], -v[i]))\n",
    "                else:\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i], v[i]))\n",
    "            itv = intersect(itv, sub_itv)\n",
    "            temp = Relu_matrix.dot(temp)\n",
    "            u = Relu_matrix.dot(u)\n",
    "            v = Relu_matrix.dot(v)\n",
    "\n",
    "    return itv, u, v\n",
    "\n",
    "def get_ad_interval(X, X_hat, O, a, b):\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        itv = intersect(itv, get_dnn_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "    _, uo, vo = get_dnn_interval(X[O].reshape(-1, 1), a[O].reshape(-1, 1), b[O].reshape(-1, 1))\n",
    "    I = np.ones((X_hat.shape[1],1))\n",
    "    sub_itv = [np.NINF, np.inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        if (i != O):\n",
    "            _, ui, vi = get_dnn_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "            u = uo - ui\n",
    "            v = vo - vi \n",
    "            u = I.T.dot(u)\n",
    "            v = I.T.dot(v)\n",
    "            sub_itv = intersect(sub_itv, solve_linear_inequality(-u, -v))\n",
    "    itv = intersect(itv, sub_itv)\n",
    "    return itv\n",
    "\n",
    "def compute_yz(X, etaj, zk, n):\n",
    "    sq_norm = (np.linalg.norm(etaj))**2\n",
    "\n",
    "    e1 = np.identity(n) - (np.dot(etaj, etaj.T))/sq_norm\n",
    "    a = np.dot(e1, X)\n",
    "\n",
    "    b = etaj/sq_norm\n",
    "\n",
    "    Xz = a + b*zk\n",
    "\n",
    "    return Xz, a, b\n",
    "\n",
    "def parametric_wdgrl(Xz, a, b, n, zk):\n",
    "    Xz = torch.FloatTensor(Xz)\n",
    "    Xz_hat = model.extract_feature(Xz.cuda())\n",
    "    Oz = [max_sum(Xz_hat.cpu().numpy())]\n",
    "    itv = get_ad_interval(Xz, Xz_hat, Oz[0], a, b)\n",
    "    return itv[1] - min(zk, itv[1]), Oz\n",
    "\n",
    "\n",
    "def run_parametric_wdgrl(X, etaj, n, threshold):\n",
    "    zk = -threshold\n",
    "\n",
    "    list_zk = [zk]\n",
    "    list_Oz = []\n",
    "\n",
    "    while zk < threshold:\n",
    "        Xz, a, b = compute_yz(X, etaj, zk, n)\n",
    "        skz, Oz = parametric_wdgrl(Xz, a, b, n, zk)\n",
    "\n",
    "        zk = zk + skz + 1e-3 \n",
    "        zk = min(zk, threshold)\n",
    "        if zk < threshold:\n",
    "            list_zk.append(zk)\n",
    "        else:\n",
    "            list_zk.append(threshold)\n",
    "        list_Oz.append(Oz)\n",
    "        # print(f'intervals: {zk-skz-1e-3} - {zk -1e-3}')\n",
    "        # print(f'Anomaly index: {Oz}')\n",
    "    return list_zk, list_Oz\n",
    "        \n",
    "def cdf(mu, sigma, list_zk, list_Oz, etajTX, O):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for each_interval in range(len(list_zk) - 1):\n",
    "        al = list_zk[each_interval]\n",
    "        ar = list_zk[each_interval + 1] - 1e-3\n",
    "\n",
    "        if (np.array_equal(O, list_Oz[each_interval]) == False):\n",
    "            continue\n",
    "\n",
    "        denominator = denominator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)\n",
    "        if etajTX >= ar:\n",
    "            numerator = numerator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)\n",
    "        elif (etajTX >= al) and (etajTX< ar):\n",
    "            numerator = numerator + mp.ncdf((etajTX - mu)/sigma) - mp.ncdf((al - mu)/sigma)\n",
    "\n",
    "    if denominator != 0:\n",
    "        return float(numerator/denominator)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fpr():\n",
    "    # np.random.seed(42)\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = [4], [0]\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "\n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "\n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < 100):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - 100]   \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    X = np.vstack((xs, xt))\n",
    "    X = torch.FloatTensor(X)\n",
    "    j = np.random.choice(O)\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "\n",
    "    etajTx = etaj.T.dot(X)\n",
    "    \n",
    "    print(f'Anomaly index: {O[0] + 100}')\n",
    "    print(f'etajTX: {etajTx}')\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    threshold = 20\n",
    "    list_zk, list_Oz = run_parametric_wdgrl(X, etaj, ns+nt, threshold)\n",
    "    CDF = cdf(etajTmu[0][0], etajTsigmaetaj[0][0], list_zk, list_Oz, etajTx[0][0], [O[0] + 100])\n",
    "    p_value = 2 * min(CDF, 1 - CDF)\n",
    "    print(f'p-value: {p_value}')\n",
    "    return p_value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #0:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.42122948]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9804\\3172295839.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  u = float(u)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9804\\3172295839.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  v = float(v)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_p_value) \u001b[38;5;241m<\u001b[39m max_iteration:\n\u001b[1;32m---> 10\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 57\u001b[0m, in \u001b[0;36mrun_fpr\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m a \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39midentity(ns\u001b[38;5;241m+\u001b[39mnt) \u001b[38;5;241m-\u001b[39m b\u001b[38;5;241m.\u001b[39mdot(etaj\u001b[38;5;241m.\u001b[39mT))\u001b[38;5;241m.\u001b[39mdot(X)\n\u001b[0;32m     56\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 57\u001b[0m list_zk, list_Oz \u001b[38;5;241m=\u001b[39m \u001b[43mrun_parametric_wdgrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metaj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m CDF \u001b[38;5;241m=\u001b[39m cdf(etajTmu[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], etajTsigmaetaj[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], list_zk, list_Oz, etajTx[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], [O[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m     59\u001b[0m p_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmin\u001b[39m(CDF, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m CDF)\n",
      "Cell \u001b[1;32mIn[20], line 117\u001b[0m, in \u001b[0;36mrun_parametric_wdgrl\u001b[1;34m(X, etaj, n, threshold)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m zk \u001b[38;5;241m<\u001b[39m threshold:\n\u001b[0;32m    116\u001b[0m     Xz, a, b \u001b[38;5;241m=\u001b[39m compute_yz(X, etaj, zk, n)\n\u001b[1;32m--> 117\u001b[0m     skz, Oz \u001b[38;5;241m=\u001b[39m \u001b[43mparametric_wdgrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     zk \u001b[38;5;241m=\u001b[39m zk \u001b[38;5;241m+\u001b[39m skz \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-3\u001b[39m \n\u001b[0;32m    120\u001b[0m     zk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(zk, threshold)\n",
      "Cell \u001b[1;32mIn[20], line 105\u001b[0m, in \u001b[0;36mparametric_wdgrl\u001b[1;34m(Xz, a, b, n, zk)\u001b[0m\n\u001b[0;32m    103\u001b[0m Xz_hat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mextract_feature(Xz\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[0;32m    104\u001b[0m Oz \u001b[38;5;241m=\u001b[39m [max_sum(Xz_hat\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())]\n\u001b[1;32m--> 105\u001b[0m itv \u001b[38;5;241m=\u001b[39m \u001b[43mget_ad_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXz_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m itv[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(zk, itv[\u001b[38;5;241m1\u001b[39m]), Oz\n",
      "Cell \u001b[1;32mIn[20], line 74\u001b[0m, in \u001b[0;36mget_ad_interval\u001b[1;34m(X, X_hat, O, a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m itv \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mNINF, np\u001b[38;5;241m.\u001b[39mInf]\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 74\u001b[0m     itv \u001b[38;5;241m=\u001b[39m intersect(itv, \u001b[43mget_dnn_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     75\u001b[0m _, uo, vo \u001b[38;5;241m=\u001b[39m get_dnn_interval(X[O]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), a[O]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), b[O]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     76\u001b[0m I \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((X_hat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[20], line 46\u001b[0m, in \u001b[0;36mget_dnn_interval\u001b[1;34m(Xtj, a, b)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (layers[ptr] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name):\n\u001b[1;32m---> 46\u001b[0m         weight \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name):\n\u001b[0;32m     48\u001b[0m         bias \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "max_iteration = 1000\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "print(f'iteration #{0}:')\n",
    "\n",
    "\n",
    "while len(list_p_value) < max_iteration:\n",
    "    p_value = run_fpr()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "    print(f'FPR: {count / len(list_p_value)}')\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'iteration #{len(list_p_value)+1}:')\n",
    "print(f'KS-test p-value: {stats.kstest(list_p_value, 'uniform')[1]}')\n",
    "\n",
    "\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tpr():\n",
    "    # np.random.seed(42)\n",
    "    # Create datasets\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = [3], [3]\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "\n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "\n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < ns):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - ns]   \n",
    "    if yt[O[0]] == 0:\n",
    "        return None\n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    X = np.vstack((xs, xt))\n",
    "    X = torch.FloatTensor(X)\n",
    "    j = np.random.choice(O)\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "\n",
    "    etajTx = etaj.T.dot(X)\n",
    "    \n",
    "    print(f'Anomaly index: {O[0] + ns}')\n",
    "    print(f'etajTX: {etajTx}')\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    threshold = 20\n",
    "    list_zk, list_Oz = run_parametric_wdgrl(X, etaj, ns+nt, threshold)\n",
    "    CDF = cdf(etajTmu[0][0], etajTsigmaetaj[0][0], list_zk, list_Oz, etajTx[0][0], [O[0] + ns])\n",
    "    p_value = 2 * min(CDF, 1 - CDF)\n",
    "    print(f'p-value: {p_value}')\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #0:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.31414223]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13412\\3172295839.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  u = float(u)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13412\\3172295839.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  v = float(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.4325399852391698\n",
      "TPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #2:\n",
      "Anomaly index: 108\n",
      "etajTX: [[3.97123125]]\n",
      "p-value: 0.00426666494434369\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #3:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.89622392]]\n",
      "p-value: 0.09875406011509846\n",
      "TPR: 0.3333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #4:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.81914308]]\n",
      "p-value: 0.07011949552939334\n",
      "TPR: 0.25\n",
      "-------------------------------------------------\n",
      "iteration #5:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.57777066]]\n",
      "p-value: 0.8774195976320966\n",
      "TPR: 0.2\n",
      "-------------------------------------------------\n",
      "iteration #6:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.03924624]]\n",
      "p-value: 0.0024237808650626746\n",
      "TPR: 0.3333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #7:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.47802035]]\n",
      "p-value: 0.0022718832686752233\n",
      "TPR: 0.42857142857142855\n",
      "-------------------------------------------------\n",
      "iteration #8:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.57825597]]\n",
      "p-value: 0.10294513737053212\n",
      "TPR: 0.375\n",
      "-------------------------------------------------\n",
      "iteration #9:\n",
      "Anomaly index: 103\n",
      "etajTX: [[4.18798256]]\n",
      "p-value: 0.001048133591015521\n",
      "TPR: 0.4444444444444444\n",
      "-------------------------------------------------\n",
      "iteration #10:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.88462808]]\n",
      "p-value: 0.06907495675032371\n",
      "TPR: 0.4\n",
      "-------------------------------------------------\n",
      "iteration #11:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.80754322]]\n",
      "p-value: 0.3597869528133084\n",
      "TPR: 0.36363636363636365\n",
      "-------------------------------------------------\n",
      "iteration #12:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.5065333]]\n",
      "p-value: 0.0451087857117245\n",
      "TPR: 0.4166666666666667\n",
      "-------------------------------------------------\n",
      "iteration #13:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.26147525]]\n",
      "p-value: 0.04161281186544752\n",
      "TPR: 0.46153846153846156\n",
      "-------------------------------------------------\n",
      "iteration #14:\n",
      "Anomaly index: 108\n",
      "etajTX: [[4.06432618]]\n",
      "p-value: 0.002457509964259419\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #15:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.47683695]]\n",
      "p-value: 0.0008886020941112349\n",
      "TPR: 0.5333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #16:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.23223495]]\n",
      "p-value: 0.043763935835777756\n",
      "TPR: 0.5625\n",
      "-------------------------------------------------\n",
      "iteration #17:\n",
      "Anomaly index: 104\n",
      "etajTX: [[1.90080833]]\n",
      "p-value: 0.5564982340834945\n",
      "TPR: 0.5294117647058824\n",
      "-------------------------------------------------\n",
      "iteration #18:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.9631034]]\n",
      "p-value: 0.20773328271755087\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #19:\n",
      "Anomaly index: 105\n",
      "etajTX: [[3.2789758]]\n",
      "p-value: 0.055449304336457894\n",
      "TPR: 0.47368421052631576\n",
      "-------------------------------------------------\n",
      "iteration #20:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.15638245]]\n",
      "p-value: 0.25730574349424384\n",
      "TPR: 0.45\n",
      "-------------------------------------------------\n",
      "iteration #21:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.94050047]]\n",
      "p-value: 0.0016842548770796828\n",
      "TPR: 0.47619047619047616\n",
      "-------------------------------------------------\n",
      "iteration #22:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.47589832]]\n",
      "p-value: 0.03794877689969778\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #23:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.09405581]]\n",
      "p-value: 0.030829909441321135\n",
      "TPR: 0.5217391304347826\n",
      "-------------------------------------------------\n",
      "iteration #24:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.83979056]]\n",
      "p-value: 0.1208803446539155\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #25:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.96890767]]\n",
      "p-value: 0.005633203830011313\n",
      "TPR: 0.52\n",
      "-------------------------------------------------\n",
      "iteration #26:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.44896126]]\n",
      "p-value: 0.16738524967900692\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #27:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.52024227]]\n",
      "p-value: 0.6974418142732646\n",
      "TPR: 0.48148148148148145\n",
      "-------------------------------------------------\n",
      "iteration #28:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.74669986]]\n",
      "p-value: 0.47715818186801684\n",
      "TPR: 0.4642857142857143\n",
      "-------------------------------------------------\n",
      "iteration #29:\n",
      "Anomaly index: 105\n",
      "etajTX: [[4.29827881]]\n",
      "p-value: 0.0012840250401608966\n",
      "TPR: 0.4827586206896552\n",
      "-------------------------------------------------\n",
      "iteration #30:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.40943718]]\n",
      "p-value: 0.23041977937507507\n",
      "TPR: 0.4666666666666667\n",
      "-------------------------------------------------\n",
      "iteration #31:\n",
      "Anomaly index: 106\n",
      "etajTX: [[4.13685248]]\n",
      "p-value: 0.0011810865006438576\n",
      "TPR: 0.4838709677419355\n",
      "-------------------------------------------------\n",
      "iteration #32:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.49340587]]\n",
      "p-value: 0.22020644968780556\n",
      "TPR: 0.46875\n",
      "-------------------------------------------------\n",
      "iteration #33:\n",
      "Anomaly index: 102\n",
      "etajTX: [[3.28364478]]\n",
      "p-value: 0.07109661537183687\n",
      "TPR: 0.45454545454545453\n",
      "-------------------------------------------------\n",
      "iteration #34:\n",
      "Anomaly index: 108\n",
      "etajTX: [[3.72722435]]\n",
      "p-value: 0.008130744374532872\n",
      "TPR: 0.47058823529411764\n",
      "-------------------------------------------------\n",
      "iteration #35:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.54914792]]\n",
      "p-value: 0.002465258019278327\n",
      "TPR: 0.4857142857142857\n",
      "-------------------------------------------------\n",
      "iteration #36:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.56705814]]\n",
      "p-value: 0.40537123151950816\n",
      "TPR: 0.4722222222222222\n",
      "-------------------------------------------------\n",
      "iteration #37:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.08849759]]\n",
      "p-value: 0.4655745997230742\n",
      "TPR: 0.4594594594594595\n",
      "-------------------------------------------------\n",
      "iteration #38:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.15591897]]\n",
      "p-value: 0.24183080665485934\n",
      "TPR: 0.4473684210526316\n",
      "-------------------------------------------------\n",
      "iteration #39:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.88282034]]\n",
      "p-value: 0.003662376335563433\n",
      "TPR: 0.46153846153846156\n",
      "-------------------------------------------------\n",
      "iteration #40:\n",
      "Anomaly index: 102\n",
      "etajTX: [[5.04161114]]\n",
      "p-value: 4.4499700809330633e-05\n",
      "TPR: 0.475\n",
      "-------------------------------------------------\n",
      "iteration #41:\n",
      "Anomaly index: 102\n",
      "etajTX: [[4.67671903]]\n",
      "p-value: 0.00035897268809104155\n",
      "TPR: 0.4878048780487805\n",
      "-------------------------------------------------\n",
      "iteration #42:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.67962223]]\n",
      "p-value: 0.0876292032911219\n",
      "TPR: 0.47619047619047616\n",
      "-------------------------------------------------\n",
      "iteration #43:\n",
      "Anomaly index: 109\n",
      "etajTX: [[4.95621936]]\n",
      "p-value: 0.00042998229418778067\n",
      "TPR: 0.4883720930232558\n",
      "-------------------------------------------------\n",
      "iteration #44:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.41902987]]\n",
      "p-value: 0.6071350882430953\n",
      "TPR: 0.4772727272727273\n",
      "-------------------------------------------------\n",
      "iteration #45:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.46719339]]\n",
      "p-value: 0.012837173021656767\n",
      "TPR: 0.4888888888888889\n",
      "-------------------------------------------------\n",
      "iteration #46:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.79429754]]\n",
      "p-value: 0.534411634461553\n",
      "TPR: 0.4782608695652174\n",
      "-------------------------------------------------\n",
      "iteration #47:\n",
      "Anomaly index: 105\n",
      "etajTX: [[4.32327271]]\n",
      "p-value: 0.0008332230354721748\n",
      "TPR: 0.48936170212765956\n",
      "-------------------------------------------------\n",
      "iteration #48:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.67870458]]\n",
      "p-value: 0.005272285030557766\n",
      "TPR: 0.5\n",
      "-------------------------------------------------\n",
      "iteration #49:\n",
      "Anomaly index: 105\n",
      "etajTX: [[5.55366241]]\n",
      "p-value: 2.388744505776863e-05\n",
      "TPR: 0.5102040816326531\n",
      "-------------------------------------------------\n",
      "iteration #50:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.63478894]]\n",
      "p-value: 0.0001502648475752988\n",
      "TPR: 0.52\n",
      "-------------------------------------------------\n",
      "iteration #51:\n",
      "Anomaly index: 109\n",
      "etajTX: [[4.51281865]]\n",
      "p-value: 0.0002461450790536279\n",
      "TPR: 0.5294117647058824\n",
      "-------------------------------------------------\n",
      "iteration #52:\n",
      "Anomaly index: 102\n",
      "etajTX: [[3.12361675]]\n",
      "p-value: 0.04186202360205726\n",
      "TPR: 0.5384615384615384\n",
      "-------------------------------------------------\n",
      "iteration #53:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.6827543]]\n",
      "p-value: 0.006074595872720856\n",
      "TPR: 0.5471698113207547\n",
      "-------------------------------------------------\n",
      "iteration #54:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.1345448]]\n",
      "p-value: 0.004719915646498318\n",
      "TPR: 0.5555555555555556\n",
      "-------------------------------------------------\n",
      "iteration #55:\n",
      "Anomaly index: 108\n",
      "etajTX: [[3.72156482]]\n",
      "p-value: 0.006490923503986501\n",
      "TPR: 0.5636363636363636\n",
      "-------------------------------------------------\n",
      "iteration #56:\n",
      "Anomaly index: 106\n",
      "etajTX: [[4.06741799]]\n",
      "p-value: 0.002256677289822928\n",
      "TPR: 0.5714285714285714\n",
      "-------------------------------------------------\n",
      "iteration #57:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.06003041]]\n",
      "p-value: 0.04763040693911824\n",
      "TPR: 0.5789473684210527\n",
      "-------------------------------------------------\n",
      "iteration #58:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.46527481]]\n",
      "p-value: 0.1649435301163658\n",
      "TPR: 0.5689655172413793\n",
      "-------------------------------------------------\n",
      "iteration #59:\n",
      "Anomaly index: 105\n",
      "etajTX: [[4.08390808]]\n",
      "p-value: 0.001307358813184667\n",
      "TPR: 0.576271186440678\n",
      "-------------------------------------------------\n",
      "iteration #60:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.13132668]]\n",
      "p-value: 0.028468845612602545\n",
      "TPR: 0.5833333333333334\n",
      "-------------------------------------------------\n",
      "iteration #61:\n",
      "Anomaly index: 105\n",
      "etajTX: [[3.42638461]]\n",
      "p-value: 0.015185102674923234\n",
      "TPR: 0.5901639344262295\n",
      "-------------------------------------------------\n",
      "iteration #62:\n",
      "Anomaly index: 108\n",
      "etajTX: [[3.77780978]]\n",
      "p-value: 0.004836513874421078\n",
      "TPR: 0.5967741935483871\n",
      "-------------------------------------------------\n",
      "iteration #63:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.23128637]]\n",
      "p-value: 0.6588306370335469\n",
      "TPR: 0.5873015873015873\n",
      "-------------------------------------------------\n",
      "iteration #64:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.86978743]]\n",
      "p-value: 0.01326311882425446\n",
      "TPR: 0.59375\n",
      "-------------------------------------------------\n",
      "iteration #65:\n",
      "Anomaly index: 102\n",
      "etajTX: [[3.16609022]]\n",
      "p-value: 0.06333733268945063\n",
      "TPR: 0.5846153846153846\n",
      "-------------------------------------------------\n",
      "iteration #66:\n",
      "Anomaly index: 102\n",
      "etajTX: [[4.0695449]]\n",
      "p-value: 0.0012069434831709636\n",
      "TPR: 0.5909090909090909\n",
      "-------------------------------------------------\n",
      "iteration #67:\n",
      "Anomaly index: 103\n",
      "etajTX: [[5.98134295]]\n",
      "p-value: 8.27525912905358e-07\n",
      "TPR: 0.5970149253731343\n",
      "-------------------------------------------------\n",
      "iteration #68:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.86166212]]\n",
      "p-value: 0.3297205807597301\n",
      "TPR: 0.5882352941176471\n",
      "-------------------------------------------------\n",
      "iteration #69:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.88264635]]\n",
      "p-value: 0.04920473026329075\n",
      "TPR: 0.5942028985507246\n",
      "-------------------------------------------------\n",
      "iteration #70:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.04967011]]\n",
      "p-value: 0.004104165840351337\n",
      "TPR: 0.6\n",
      "-------------------------------------------------\n",
      "iteration #71:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.11747106]]\n",
      "p-value: 0.03217098261763085\n",
      "TPR: 0.6056338028169014\n",
      "-------------------------------------------------\n",
      "iteration #72:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.99138472]]\n",
      "p-value: 0.544421797194671\n",
      "TPR: 0.5972222222222222\n",
      "-------------------------------------------------\n",
      "iteration #73:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.77929815]]\n",
      "p-value: 0.012950345011071729\n",
      "TPR: 0.6027397260273972\n",
      "-------------------------------------------------\n",
      "iteration #74:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.48933432]]\n",
      "p-value: 0.15118390804909354\n",
      "TPR: 0.5945945945945946\n",
      "-------------------------------------------------\n",
      "iteration #75:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.44283358]]\n",
      "p-value: 0.0003917381668752107\n",
      "TPR: 0.6\n",
      "-------------------------------------------------\n",
      "iteration #76:\n",
      "Anomaly index: 105\n",
      "etajTX: [[5.21084849]]\n",
      "p-value: 2.056601415412196e-05\n",
      "TPR: 0.6052631578947368\n",
      "-------------------------------------------------\n",
      "iteration #77:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.95647579]]\n",
      "p-value: 0.005156248683459763\n",
      "TPR: 0.6103896103896104\n",
      "-------------------------------------------------\n",
      "iteration #78:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.79715135]]\n",
      "p-value: 0.07832489252167152\n",
      "TPR: 0.6025641025641025\n",
      "-------------------------------------------------\n",
      "iteration #79:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.15425046]]\n",
      "p-value: 0.6617932945140423\n",
      "TPR: 0.5949367088607594\n",
      "-------------------------------------------------\n",
      "iteration #80:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.96880998]]\n",
      "p-value: 0.5128648622789362\n",
      "TPR: 0.5875\n",
      "-------------------------------------------------\n",
      "iteration #81:\n",
      "Anomaly index: 107\n",
      "etajTX: [[5.312468]]\n",
      "p-value: 4.205870847728832e-05\n",
      "TPR: 0.5925925925925926\n",
      "-------------------------------------------------\n",
      "iteration #82:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.71400367]]\n",
      "p-value: 0.018722106759092583\n",
      "TPR: 0.5975609756097561\n",
      "-------------------------------------------------\n",
      "iteration #83:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.16822645]]\n",
      "p-value: 0.9582707854803462\n",
      "TPR: 0.5903614457831325\n",
      "-------------------------------------------------\n",
      "iteration #84:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.63039822]]\n",
      "p-value: 0.21655974032594694\n",
      "TPR: 0.5833333333333334\n",
      "-------------------------------------------------\n",
      "iteration #85:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.3338534]]\n",
      "p-value: 0.19098324984810944\n",
      "TPR: 0.5764705882352941\n",
      "-------------------------------------------------\n",
      "iteration #86:\n",
      "Anomaly index: 103\n",
      "etajTX: [[4.24044461]]\n",
      "p-value: 0.002646673820806411\n",
      "TPR: 0.5813953488372093\n",
      "-------------------------------------------------\n",
      "iteration #87:\n",
      "Anomaly index: 102\n",
      "etajTX: [[3.07322968]]\n",
      "p-value: 0.0302637595204438\n",
      "TPR: 0.5862068965517241\n",
      "-------------------------------------------------\n",
      "iteration #88:\n",
      "Anomaly index: 107\n",
      "etajTX: [[3.85548486]]\n",
      "p-value: 0.004562005209316711\n",
      "TPR: 0.5909090909090909\n",
      "-------------------------------------------------\n",
      "iteration #89:\n",
      "Anomaly index: 102\n",
      "etajTX: [[4.7409189]]\n",
      "p-value: 8.272289953814571e-05\n",
      "TPR: 0.5955056179775281\n",
      "-------------------------------------------------\n",
      "iteration #90:\n",
      "Anomaly index: 102\n",
      "etajTX: [[5.27444839]]\n",
      "p-value: 6.99723482513459e-05\n",
      "TPR: 0.6\n",
      "-------------------------------------------------\n",
      "iteration #91:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.71425692]]\n",
      "p-value: 0.3093134851820405\n",
      "TPR: 0.5934065934065934\n",
      "-------------------------------------------------\n",
      "iteration #92:\n",
      "Anomaly index: 103\n",
      "etajTX: [[3.85886362]]\n",
      "p-value: 0.0031333159613731176\n",
      "TPR: 0.5978260869565217\n",
      "-------------------------------------------------\n",
      "iteration #93:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.87526766]]\n",
      "p-value: 0.004238684711981744\n",
      "TPR: 0.6021505376344086\n",
      "-------------------------------------------------\n",
      "iteration #94:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.73439238]]\n",
      "p-value: 0.0006319929655389522\n",
      "TPR: 0.6063829787234043\n",
      "-------------------------------------------------\n",
      "iteration #95:\n",
      "Anomaly index: 108\n",
      "etajTX: [[3.48077753]]\n",
      "p-value: 0.019693972747121036\n",
      "TPR: 0.6105263157894737\n",
      "-------------------------------------------------\n",
      "iteration #96:\n",
      "Anomaly index: 104\n",
      "etajTX: [[3.69142426]]\n",
      "p-value: 0.0086154136126666\n",
      "TPR: 0.6145833333333334\n",
      "-------------------------------------------------\n",
      "iteration #97:\n",
      "Anomaly index: 105\n",
      "etajTX: [[4.0725335]]\n",
      "p-value: 0.004036556985665962\n",
      "TPR: 0.6185567010309279\n",
      "-------------------------------------------------\n",
      "iteration #98:\n",
      "Anomaly index: 105\n",
      "etajTX: [[3.3071999]]\n",
      "p-value: 0.014563597618052038\n",
      "TPR: 0.6224489795918368\n",
      "-------------------------------------------------\n",
      "iteration #99:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.34377734]]\n",
      "p-value: 0.0007000041834877013\n",
      "TPR: 0.6262626262626263\n",
      "-------------------------------------------------\n",
      "iteration #100:\n",
      "Anomaly index: 104\n",
      "etajTX: [[4.90987354]]\n",
      "p-value: 0.0023993617274944423\n",
      "TPR: 0.63\n",
      "-------------------------------------------------\n",
      "iteration #101:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.58651691]]\n",
      "p-value: 0.002618172543527253\n",
      "TPR: 0.6336633663366337\n",
      "-------------------------------------------------\n",
      "iteration #102:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.00135846]]\n",
      "p-value: 0.004722692379071303\n",
      "TPR: 0.6372549019607843\n",
      "-------------------------------------------------\n",
      "iteration #103:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.11359702]]\n",
      "p-value: 0.24183019552051777\n",
      "TPR: 0.6310679611650486\n",
      "-------------------------------------------------\n",
      "iteration #104:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.66503821]]\n",
      "p-value: 0.32970216189310797\n",
      "TPR: 0.625\n",
      "-------------------------------------------------\n",
      "iteration #105:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.52477158]]\n",
      "p-value: 0.20450878452950283\n",
      "TPR: 0.6190476190476191\n",
      "-------------------------------------------------\n",
      "iteration #106:\n",
      "Anomaly index: 102\n",
      "etajTX: [[4.2782686]]\n",
      "p-value: 0.002517567650321295\n",
      "TPR: 0.6226415094339622\n",
      "-------------------------------------------------\n",
      "iteration #107:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.47298728]]\n",
      "p-value: 0.1722673397306269\n",
      "TPR: 0.616822429906542\n",
      "-------------------------------------------------\n",
      "iteration #108:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.84662183]]\n",
      "p-value: 0.05137202176376343\n",
      "TPR: 0.6111111111111112\n",
      "-------------------------------------------------\n",
      "iteration #109:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.4458669]]\n",
      "p-value: 0.27191384553224074\n",
      "TPR: 0.6055045871559633\n",
      "-------------------------------------------------\n",
      "iteration #110:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.5196476]]\n",
      "p-value: 0.120597978922385\n",
      "TPR: 0.6\n",
      "-------------------------------------------------\n",
      "iteration #111:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.51309374]]\n",
      "p-value: 0.3418186450688099\n",
      "TPR: 0.5945945945945946\n",
      "-------------------------------------------------\n",
      "iteration #112:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.25297356]]\n",
      "p-value: 0.8273706892019259\n",
      "TPR: 0.5892857142857143\n",
      "-------------------------------------------------\n",
      "iteration #113:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.99417369]]\n",
      "p-value: 0.07480491873498396\n",
      "TPR: 0.584070796460177\n",
      "-------------------------------------------------\n",
      "iteration #114:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.79459021]]\n",
      "p-value: 0.4497661276156286\n",
      "TPR: 0.5789473684210527\n",
      "-------------------------------------------------\n",
      "iteration #115:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.64488983]]\n",
      "p-value: 0.12740239377786655\n",
      "TPR: 0.5739130434782609\n",
      "-------------------------------------------------\n",
      "iteration #116:\n",
      "Anomaly index: 101\n",
      "etajTX: [[4.33856286]]\n",
      "p-value: 0.001696919280885112\n",
      "TPR: 0.5775862068965517\n",
      "-------------------------------------------------\n",
      "iteration #117:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.38452615]]\n",
      "p-value: 0.36411903124724615\n",
      "TPR: 0.5726495726495726\n",
      "-------------------------------------------------\n",
      "iteration #118:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.80244022]]\n",
      "p-value: 0.08682906786002809\n",
      "TPR: 0.5677966101694916\n",
      "-------------------------------------------------\n",
      "iteration #119:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.74819989]]\n",
      "p-value: 0.8521062551560723\n",
      "TPR: 0.5630252100840336\n",
      "-------------------------------------------------\n",
      "iteration #120:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.53612582]]\n",
      "p-value: 0.7692934744803495\n",
      "TPR: 0.5583333333333333\n",
      "-------------------------------------------------\n",
      "iteration #121:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.79936875]]\n",
      "p-value: 0.6491640483041099\n",
      "TPR: 0.5537190082644629\n",
      "-------------------------------------------------\n",
      "iteration #122:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAGeCAYAAABPfaH9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiZklEQVR4nO3de3BU9f3/8VdIyIZKdmNQdpOacPEWRPESNKxgrZg2gxRliHeqqFS0RiykXkgV8UoiWqBYLtViwFFKxREqoliNFQcNKBE6VjSIoImFXcfW7CKWTSCf7x+/cX8uBPVsNuST5fmYOTPm7Nmzbz4y5unJ2WyKMcYIAADAEt06ewAAAIBvI04AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAVknr7AH219raqh07digzM1MpKSmdPQ4AAPgBjDHatWuXcnNz1a1bO699GAf27t1r7rrrLtO3b1+TkZFh+vfvb+677z7T2toaPaa1tdVMnTrV+Hw+k5GRYc4//3yzZcuWH/wajY2NRhIbGxsbGxtbF9waGxudpEWbHF05eeihhzR//nwtXrxYAwcO1IYNG3TttdfK4/HolltukSTNmDFDc+bM0eLFi9WvXz9NnTpVJSUl2rx5szIyMr73NTIzMyVJjY2NcrvdTsYDAACdJBwOKy8vL/p9vD1SjPnhH/z3i1/8Ql6vVwsXLozuKy0tVY8ePfTUU0/JGKPc3Fz99re/1a233ipJCoVC8nq9WrRokS6//PLvfY1wOCyPx6NQKEScAADQRSTy+7ejHwqdffbZqqmp0ZYtWyRJ//znP7V27VqNGDFCkrR9+3YFAgEVFxdHn+PxeFRUVKTa2to2zxmJRBQOh2M2AABw+HL0Y50pU6YoHA6roKBAqamp2rdvnx588EGNHTtWkhQIBCRJXq835nlerzf62P4qKyt17733xjM7AABIQo6unDzzzDN6+umntWTJEr377rtavHixHnnkES1evDjuASoqKhQKhaJbY2Nj3OcCAABdn6MrJ7fddpumTJkSvXfklFNO0aeffqrKykqNGzdOPp9PkhQMBpWTkxN9XjAY1GmnndbmOV0ul1wuV5zjAwCAZOPoysnXX399wHuXU1NT1draKknq16+ffD6fampqoo+Hw2GtX79efr8/AeMCAIBk5+jKyahRo/Tggw8qPz9fAwcO1MaNGzVz5kxdd911kqSUlBRNmjRJDzzwgI4//vjoW4lzc3M1evTojpgfAAAkGUdx8uijj2rq1Km66aab9Pnnnys3N1c33HCD7r777ugxt99+u3bv3q0JEyaoqalJw4YN0+rVq3/Q7zgBAABw9HtODgV+zwkAAF1Pp/2eEwAAgI5GnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqzj6PSfJoO+UVZ09gmOfVI3s7BEAADhkuHICAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALCKozjp27evUlJSDtjKysokSXv27FFZWZl69eqlnj17qrS0VMFgsEMGBwAAyclRnLzzzjvauXNndHvllVckSZdccokkafLkyVq5cqWWLVumNWvWaMeOHRozZkzipwYAAEkrzcnBRx99dMzXVVVVOvbYY3XuuecqFApp4cKFWrJkiYYPHy5Jqq6u1oABA7Ru3ToNGTKkzXNGIhFFIpHo1+Fw2OmfAQAAJJG47zlpbm7WU089peuuu04pKSmqq6tTS0uLiouLo8cUFBQoPz9ftbW1Bz1PZWWlPB5PdMvLy4t3JAAAkATijpMVK1aoqalJ11xzjSQpEAgoPT1dWVlZMcd5vV4FAoGDnqeiokKhUCi6NTY2xjsSAABIAo5+rPNtCxcu1IgRI5Sbm9uuAVwul1wuV7vOAQAAkkdccfLpp5/q1Vdf1XPPPRfd5/P51NzcrKamppirJ8FgUD6fr92DAgCAw0NcP9aprq5W7969NXLkyOi+wsJCde/eXTU1NdF99fX1amhokN/vb/+kAADgsOD4yklra6uqq6s1btw4paX9/6d7PB6NHz9e5eXlys7Oltvt1sSJE+X3+w/6Th0AAID9OY6TV199VQ0NDbruuusOeGzWrFnq1q2bSktLFYlEVFJSonnz5iVkUAAAcHhIMcaYzh7i28LhsDwej0KhkNxud8LP33fKqoSfs6N9UjXy+w8CAKATJfL7N5+tAwAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKs4jpN///vf+uUvf6levXqpR48eOuWUU7Rhw4bo48YY3X333crJyVGPHj1UXFysjz76KKFDAwCA5OUoTr788ksNHTpU3bt310svvaTNmzfr97//vY488sjoMTNmzNCcOXO0YMECrV+/XkcccYRKSkq0Z8+ehA8PAACST5qTgx966CHl5eWpuro6uq9fv37RfzbGaPbs2brrrrt00UUXSZKefPJJeb1erVixQpdffnmCxgYAAMnK0ZWT559/XoMHD9Yll1yi3r176/TTT9fjjz8efXz79u0KBAIqLi6O7vN4PCoqKlJtbW2b54xEIgqHwzEbAAA4fDmKk23btmn+/Pk6/vjj9fLLL+vXv/61brnlFi1evFiSFAgEJElerzfmeV6vN/rY/iorK+XxeKJbXl5ePH8OAACQJBzFSWtrq8444wxNnz5dp59+uiZMmKDrr79eCxYsiHuAiooKhUKh6NbY2Bj3uQAAQNfnKE5ycnJ00kknxewbMGCAGhoaJEk+n0+SFAwGY44JBoPRx/bncrnkdrtjNgAAcPhyFCdDhw5VfX19zL4tW7aoT58+kv7fzbE+n081NTXRx8PhsNavXy+/35+AcQEAQLJz9G6dyZMn6+yzz9b06dN16aWX6u2339Zjjz2mxx57TJKUkpKiSZMm6YEHHtDxxx+vfv36aerUqcrNzdXo0aM7Yn4AAJBkHMXJmWeeqeXLl6uiokL33Xef+vXrp9mzZ2vs2LHRY26//Xbt3r1bEyZMUFNTk4YNG6bVq1crIyMj4cMDAIDkk2KMMZ09xLeFw2F5PB6FQqEOuf+k75RVCT9nR/ukamRnjwAAwHdK5PdvPlsHAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVRzFyT333KOUlJSYraCgIPr4nj17VFZWpl69eqlnz54qLS1VMBhM+NAAACB5Ob5yMnDgQO3cuTO6rV27NvrY5MmTtXLlSi1btkxr1qzRjh07NGbMmIQODAAAklua4yekpcnn8x2wPxQKaeHChVqyZImGDx8uSaqurtaAAQO0bt06DRkypP3TAgCApOf4yslHH32k3Nxc9e/fX2PHjlVDQ4Mkqa6uTi0tLSouLo4eW1BQoPz8fNXW1h70fJFIROFwOGYDAACHL0dxUlRUpEWLFmn16tWaP3++tm/frnPOOUe7du1SIBBQenq6srKyYp7j9XoVCAQOes7Kykp5PJ7olpeXF9cfBAAAJAdHP9YZMWJE9J8HDRqkoqIi9enTR88884x69OgR1wAVFRUqLy+Pfh0OhwkUAAAOY+16K3FWVpZOOOEEbd26VT6fT83NzWpqaoo5JhgMtnmPyjdcLpfcbnfMBgAADl/tipOvvvpKH3/8sXJyclRYWKju3burpqYm+nh9fb0aGhrk9/vbPSgAADg8OPqxzq233qpRo0apT58+2rFjh6ZNm6bU1FRdccUV8ng8Gj9+vMrLy5WdnS23262JEyfK7/fzTh0AAPCDOYqTzz77TFdccYX+85//6Oijj9awYcO0bt06HX300ZKkWbNmqVu3biotLVUkElFJSYnmzZvXIYMDAIDklGKMMZ09xLeFw2F5PB6FQqEOuf+k75RVCT9nR/ukamRnjwAAwHdK5PdvPlsHAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVdoVJ1VVVUpJSdGkSZOi+/bs2aOysjL16tVLPXv2VGlpqYLBYHvnBAAAh4m44+Sdd97Rn/70Jw0aNChm/+TJk7Vy5UotW7ZMa9as0Y4dOzRmzJh2DwoAAA4PccXJV199pbFjx+rxxx/XkUceGd0fCoW0cOFCzZw5U8OHD1dhYaGqq6v11ltvad26dW2eKxKJKBwOx2wAAODwFVeclJWVaeTIkSouLo7ZX1dXp5aWlpj9BQUFys/PV21tbZvnqqyslMfjiW55eXnxjAQAAJKE4zhZunSp3n33XVVWVh7wWCAQUHp6urKysmL2e71eBQKBNs9XUVGhUCgU3RobG52OBAAAkkiak4MbGxv1m9/8Rq+88ooyMjISMoDL5ZLL5UrIuQAAQNfn6MpJXV2dPv/8c51xxhlKS0tTWlqa1qxZozlz5igtLU1er1fNzc1qamqKeV4wGJTP50vk3AAAIEk5unJy/vnn67333ovZd+2116qgoEB33HGH8vLy1L17d9XU1Ki0tFSSVF9fr4aGBvn9/sRNDQAAkpajOMnMzNTJJ58cs++II45Qr169ovvHjx+v8vJyZWdny+12a+LEifL7/RoyZEjipgYAAEnLUZz8ELNmzVK3bt1UWlqqSCSikpISzZs3L9EvAwAAklSKMcZ09hDfFg6H5fF4FAqF5Ha7E37+vlNWJfycHe2TqpGdPQIAAN8pkd+/+WwdAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFiFOAEAAFYhTgAAgFWIEwAAYBXiBAAAWIU4AQAAVnEUJ/Pnz9egQYPkdrvldrvl9/v10ksvRR/fs2ePysrK1KtXL/Xs2VOlpaUKBoMJHxoAACQvR3FyzDHHqKqqSnV1ddqwYYOGDx+uiy66SO+//74kafLkyVq5cqWWLVumNWvWaMeOHRozZkyHDA4AAJJTijHGtOcE2dnZevjhh3XxxRfr6KOP1pIlS3TxxRdLkj788EMNGDBAtbW1GjJkSJvPj0QiikQi0a/D4bDy8vIUCoXkdrvbM1qb+k5ZlfBzdrRPqkZ29ggAAHyncDgsj8eTkO/fcd9zsm/fPi1dulS7d++W3+9XXV2dWlpaVFxcHD2moKBA+fn5qq2tPeh5Kisr5fF4olteXl68IwEAgCTgOE7ee+899ezZUy6XSzfeeKOWL1+uk046SYFAQOnp6crKyoo53uv1KhAIHPR8FRUVCoVC0a2xsdHxHwIAACSPNKdPOPHEE7Vp0yaFQiE9++yzGjdunNasWRP3AC6XSy6XK+7nAwCA5OI4TtLT03XcccdJkgoLC/XOO+/oD3/4gy677DI1Nzerqakp5upJMBiUz+dL2MAAACC5tfv3nLS2tioSiaiwsFDdu3dXTU1N9LH6+no1NDTI7/e392UAAMBhwtGVk4qKCo0YMUL5+fnatWuXlixZotdff10vv/yyPB6Pxo8fr/LycmVnZ8vtdmvixIny+/0HfacOAADA/hzFyeeff66rr75aO3fulMfj0aBBg/Tyyy/rZz/7mSRp1qxZ6tatm0pLSxWJRFRSUqJ58+Z1yOAAACA5tfv3nCRaIt8n3RZ+zwkAAIlnxe85AQAA6AjECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALCKoziprKzUmWeeqczMTPXu3VujR49WfX19zDF79uxRWVmZevXqpZ49e6q0tFTBYDChQwMAgOTlKE7WrFmjsrIyrVu3Tq+88opaWlr085//XLt3744eM3nyZK1cuVLLli3TmjVrtGPHDo0ZMybhgwMAgOSU5uTg1atXx3y9aNEi9e7dW3V1dfrJT36iUCikhQsXasmSJRo+fLgkqbq6WgMGDNC6des0ZMiQxE0OAACSUrvuOQmFQpKk7OxsSVJdXZ1aWlpUXFwcPaagoED5+fmqra1t8xyRSEThcDhmAwAAh6+446S1tVWTJk3S0KFDdfLJJ0uSAoGA0tPTlZWVFXOs1+tVIBBo8zyVlZXyeDzRLS8vL96RAABAEog7TsrKyvSvf/1LS5cubdcAFRUVCoVC0a2xsbFd5wMAAF2bo3tOvnHzzTfrhRde0BtvvKFjjjkmut/n86m5uVlNTU0xV0+CwaB8Pl+b53K5XHK5XPGMAQAAkpCjKyfGGN18881avny5XnvtNfXr1y/m8cLCQnXv3l01NTXRffX19WpoaJDf70/MxAAAIKk5unJSVlamJUuW6G9/+5syMzOj95F4PB716NFDHo9H48ePV3l5ubKzs+V2uzVx4kT5/X7eqQMAAH4QR3Eyf/58SdJPf/rTmP3V1dW65pprJEmzZs1St27dVFpaqkgkopKSEs2bNy8hwwIAgOTnKE6MMd97TEZGhubOnau5c+fGPRQAADh88dk6AADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwCnECAACsQpwAAACrECcAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArOI4Tt544w2NGjVKubm5SklJ0YoVK2IeN8bo7rvvVk5Ojnr06KHi4mJ99NFHiZoXAAAkOcdxsnv3bp166qmaO3dum4/PmDFDc+bM0YIFC7R+/XodccQRKikp0Z49e9o9LAAASH5pTp8wYsQIjRgxos3HjDGaPXu27rrrLl100UWSpCeffFJer1crVqzQ5Zdf3r5pAQBA0kvoPSfbt29XIBBQcXFxdJ/H41FRUZFqa2vbfE4kElE4HI7ZAADA4cvxlZPvEggEJElerzdmv9frjT62v8rKSt17772JHCPp9J2yqrNHcOyTqpGdPQIAoIvq9HfrVFRUKBQKRbfGxsbOHgkAAHSihMaJz+eTJAWDwZj9wWAw+tj+XC6X3G53zAYAAA5fCY2Tfv36yefzqaamJrovHA5r/fr18vv9iXwpAACQpBzfc/LVV19p69at0a+3b9+uTZs2KTs7W/n5+Zo0aZIeeOABHX/88erXr5+mTp2q3NxcjR49OpFzw3LcJwMAiJfjONmwYYPOO++86Nfl5eWSpHHjxmnRokW6/fbbtXv3bk2YMEFNTU0aNmyYVq9erYyMjMRNDQAAklaKMcZ09hDfFg6H5fF4FAqFOuT+k674f/Q4NLhyAgDxS+T3705/tw4AAMC3EScAAMAqxAkAALAKcQIAAKxCnAAAAKsQJwAAwCrECQAAsApxAgAArEKcAAAAqxAnAADAKsQJAACwiuMP/gOSVVf83CU+DwhAMuLKCQAAsApxAgAArEKcAAAAq3DPCdCFcZ8MgGTElRMAAGAV4gQAAFiFOAEAAFYhTgAAgFW4IRbAIdUVb+Ltqrj5GF0VV04AAIBViBMAAGAV4gQAAFiFOAEAAFbhhlgAgDW64g3T3HiceFw5AQAAViFOAACAVYgTAABgFe45AQCgHbhPJvG4cgIAAKxCnAAAAKsQJwAAwCrECQAAsAo3xAJAkuqKN2oCUgdeOZk7d6769u2rjIwMFRUV6e233+6olwIAAEmkQ+Lkr3/9q8rLyzVt2jS9++67OvXUU1VSUqLPP/+8I14OAAAkkQ75sc7MmTN1/fXX69prr5UkLViwQKtWrdITTzyhKVOmxBwbiUQUiUSiX4dCIUlSOBzuiNHUGvm6Q84LAEBX0RHfY785pzGm/SczCRaJRExqaqpZvnx5zP6rr77aXHjhhQccP23aNCOJjY2NjY2NLQm2xsbGdrdEwq+cfPHFF9q3b5+8Xm/Mfq/Xqw8//PCA4ysqKlReXh79urW1Vf/973/Vq1cvpaSkJHS2cDisvLw8NTY2yu12J/TcODjWvXOw7p2Dde8crHvn+Pa6Z2ZmateuXcrNzW33eTv93Toul0sulytmX1ZWVoe+ptvt5i9vJ2DdOwfr3jlY987BuneOb9bd4/Ek5HwJvyH2qKOOUmpqqoLBYMz+YDAon8+X6JcDAABJJuFxkp6ersLCQtXU1ET3tba2qqamRn6/P9EvBwAAkkyH/FinvLxc48aN0+DBg3XWWWdp9uzZ2r17d/TdO53F5XJp2rRpB/wYCR2Lde8crHvnYN07B+veOTpq3VOMScR7fg70xz/+UQ8//LACgYBOO+00zZkzR0VFRR3xUgAAIIl0WJwAAADEgw/+AwAAViFOAACAVYgTAABgFeIEAABYJeniZO7cuerbt68yMjJUVFSkt99++zuPX7ZsmQoKCpSRkaFTTjlFL7744iGaNLk4WffHH39c55xzjo488kgdeeSRKi4u/t5/T2ib07/v31i6dKlSUlI0evTojh0wSTld96amJpWVlSknJ0cul0snnHAC/62Jg9N1nz17tk488UT16NFDeXl5mjx5svbs2XOIpk0Ob7zxhkaNGqXc3FylpKRoxYoV3/uc119/XWeccYZcLpeOO+44LVq0yPkLt/vTeSyydOlSk56ebp544gnz/vvvm+uvv95kZWWZYDDY5vFvvvmmSU1NNTNmzDCbN282d911l+nevbt57733DvHkXZvTdb/yyivN3LlzzcaNG80HH3xgrrnmGuPxeMxnn312iCfv2pyu+ze2b99ufvzjH5tzzjnHXHTRRYdm2CTidN0jkYgZPHiwueCCC8zatWvN9u3bzeuvv242bdp0iCfv2pyu+9NPP21cLpd5+umnzfbt283LL79scnJyzOTJkw/x5F3biy++aO68807z3HPPGUkHfKjv/rZt22Z+9KMfmfLycrN582bz6KOPmtTUVLN69WpHr5tUcXLWWWeZsrKy6Nf79u0zubm5prKyss3jL730UjNy5MiYfUVFReaGG27o0DmTjdN139/evXtNZmamWbx4cUeNmJTiWfe9e/eas88+2/z5z38248aNI07i4HTd58+fb/r372+am5sP1YhJyem6l5WVmeHDh8fsKy8vN0OHDu3QOZPZD4mT22+/3QwcODBm32WXXWZKSkocvVbS/FinublZdXV1Ki4uju7r1q2biouLVVtb2+ZzamtrY46XpJKSkoMejwPFs+77+/rrr9XS0qLs7OyOGjPpxLvu9913n3r37q3x48cfijGTTjzr/vzzz8vv96usrExer1cnn3yypk+frn379h2qsbu8eNb97LPPVl1dXfRHP9u2bdOLL76oCy644JDMfLhK1PfVTv9U4kT54osvtG/fPnm93pj9Xq9XH374YZvPCQQCbR4fCAQ6bM5kE8+67++OO+5Qbm7uAX+hcXDxrPvatWu1cOFCbdq06RBMmJziWfdt27bptdde09ixY/Xiiy9q69atuummm9TS0qJp06YdirG7vHjW/corr9QXX3yhYcOGyRijvXv36sYbb9Tvfve7QzHyYetg31fD4bD+97//qUePHj/oPElz5QRdU1VVlZYuXarly5crIyOjs8dJWrt27dJVV12lxx9/XEcddVRnj3NYaW1tVe/evfXYY4+psLBQl112me68804tWLCgs0dLaq+//rqmT5+uefPm6d1339Vzzz2nVatW6f777+/s0fADJM2Vk6OOOkqpqakKBoMx+4PBoHw+X5vP8fl8jo7HgeJZ92888sgjqqqq0quvvqpBgwZ15JhJx+m6f/zxx/rkk080atSo6L7W1lZJUlpamurr63Xsscd27NBJIJ6/7zk5OerevbtSU1Oj+wYMGKBAIKDm5malp6d36MzJIJ51nzp1qq666ir96le/kiSdcsop2r17tyZMmKA777xT3brx/+Yd4WDfV91u9w++aiIl0ZWT9PR0FRYWqqamJrqvtbVVNTU18vv9bT7H7/fHHC9Jr7zyykGPx4HiWXdJmjFjhu6//36tXr1agwcPPhSjJhWn615QUKD33ntPmzZtim4XXnihzjvvPG3atEl5eXmHcvwuK56/70OHDtXWrVujMShJW7ZsUU5ODmHyA8Wz7l9//fUBAfJNIBo+Uq7DJOz7qrN7de22dOlS43K5zKJFi8zmzZvNhAkTTFZWlgkEAsYYY6666iozZcqU6PFvvvmmSUtLM4888oj54IMPzLRp03grcRycrntVVZVJT083zz77rNm5c2d027VrV2f9Ebokp+u+P96tEx+n697Q0GAyMzPNzTffbOrr680LL7xgevfubR544IHO+iN0SU7Xfdq0aSYzM9P85S9/Mdu2bTN///vfzbHHHmsuvfTSzvojdEm7du0yGzduNBs3bjSSzMyZM83GjRvNp59+aowxZsqUKeaqq66KHv/NW4lvu+0288EHH5i5c+fyVmJjjHn00UdNfn6+SU9PN2eddZZZt25d9LFzzz3XjBs3Lub4Z555xpxwwgkmPT3dDBw40KxateoQT5wcnKx7nz59jKQDtmnTph36wbs4p3/fv404iZ/TdX/rrbdMUVGRcblcpn///ubBBx80e/fuPcRTd31O1r2lpcXcc8895thjjzUZGRkmLy/P3HTTTebLL7889IN3Yf/4xz/a/O/1N2s9btw4c+655x7wnNNOO82kp6eb/v37m+rqasevm2IM17cAAIA9kuaeEwAAkByIEwAAYBXiBAAAWIU4AQAAViFOAACAVYgTAABgFeIEAABYhTgBAABWIU4AAIBViBMAAGAV4gQAAFjl/wAma14tFYj16wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "max_iteration = 120\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "print(f'iteration #{0}:')\n",
    "\n",
    "\n",
    "while len(list_p_value) <= max_iteration:\n",
    "    p_value = run_tpr()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "    print(f'TPR: {count / len(list_p_value)}')\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'iteration #{len(list_p_value)+1}:')\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
