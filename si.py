import numpy as np
from typing import List
import matplotlib.pyplot as plt
from models.train import WDGRL, run, get_next_index
from mpmath import mp
mp.dps = 500
import torch
import os
import scipy.stats as stats
from multiprocessing import Pool

def gen_data(n: int, d: int, mu: float, delta: List[int]):
    mu = np.full((n, d), mu, dtype=np.float64)
    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))
    X = mu + noise
    labels = np.zeros(n)
    if len(delta) == 1:
        # In this case, we generate data for target domain.
        # For simplicity in experiment with varying deltas, 
        # we assume that delta is the same for all anomalies.
        X = X + delta[0]
        if delta[0] != 0:
            labels = np.ones(n)
    else:
        # In this case, we generate data for source domain.
        # 5% of the data is abnormal.
        # Anomalies are generated by randomly adding deltas to the data.
        n_anomalies = int(n * 0.05)
        idx = np.random.choice(n, n_anomalies, replace=False)
        if 0 in delta: 
            delta.pop(delta.index(0))
        if len(delta) != 0:
            split_points = sorted(np.random.choice(range(1, len(idx)), len(delta) - 1, replace=False))
            segments = np.split(idx, split_points)
            for i, segment in enumerate(segments):
                X[segment] = X[segment] + delta[i]
            labels[idx] = 1
    return X, labels

def model_parameters_match(model, checkpoint): 
    try:
        # Extract model and checkpoint state dictionaries
        model_gen_state = model.generator.state_dict()
        model_crit_state = model.critic.state_dict()
        checkpoint_gen_state = checkpoint['generator_state_dict']
        checkpoint_crit_state = checkpoint['critic_state_dict']

        # Check if layer names match
        generator_match = model_gen_state.keys() == checkpoint_gen_state.keys()
        critic_match = model_crit_state.keys() == checkpoint_crit_state.keys()

        if not (generator_match and critic_match):
            print("Model layer names do not match.")
            return False

        # Check if layer shapes (node counts) match
        for key in model_gen_state:
            if model_gen_state[key].shape != checkpoint_gen_state[key].shape:
                print(f"Mismatch in generator layer {key}: {model_gen_state[key].shape} vs {checkpoint_gen_state[key].shape}")
                return False

        for key in model_crit_state:
            if model_crit_state[key].shape != checkpoint_crit_state[key].shape:
                print(f"Mismatch in critic layer {key}: {model_crit_state[key].shape} vs {checkpoint_crit_state[key].shape}")
                return False

        return True  # Both names and dimensions match

    except KeyError:
        print("KeyError: Model and checkpoint structure do not match.")
        return False

def basic_anomaly_detection(X):
    O = np.argmax(np.sum(X, axis=1))
    Y_hat = np.zeros(X.shape[0])
    Y_hat[O] = 1
    return O, Y_hat

def intersect(itv1, itv2):
    # print(itv1, itv2)
    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]
    if itv[0] > itv[1]:
        return None    
    return itv

def solve_linear_inequality(u, v): #u + vz < 0
    if (v > -1e-16 and v < 1e-16):
        v = 0
        if (u < 0):
            return [np.NINF, np.inf]
        else:
            print('error')
            return None
    if (v < 0):
        return [-u/v, np.inf]
    return [np.NINF, -u/v]

def get_dnn_interval(model, Xtj, a, b):
    layers = []

    for name, param in model.generator.named_children():
        temp = dict(param._modules)
        
        for layer_name in temp.values():
            if ('Linear' in str(layer_name)):
                layers.append('Linear')
            elif ('ReLU' in str(layer_name)):
                layers.append('ReLU')

    ptr = 0
    itv = [np.NINF, np.inf]
    u = a
    v = b
    temp = Xtj
    weight = None
    bias = None
    for name, param in model.generator.named_parameters():
        if (layers[ptr] == 'Linear'):
            if ('weight' in name):
                weight = param.data.cpu().detach().numpy()
            elif ('bias' in name):
                bias = param.data.cpu().detach().numpy().reshape(-1, 1)
                ptr += 1
                temp = weight.dot(temp) + bias
                u = weight.dot(u) + bias
                v = weight.dot(v)

        if (ptr < len(layers) and layers[ptr] == 'ReLU'):
            ptr += 1
            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))
            sub_itv = [np.NINF, np.inf]
            for i in range(temp.shape[0]):
                if temp[i] > 0:
                    Relu_matrix[i][i] = 1
                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i][0], -v[i][0]))
                else:
                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i][0], v[i][0]))
            itv = intersect(itv, sub_itv)
            temp = Relu_matrix.dot(temp)
            u = Relu_matrix.dot(u)
            v = Relu_matrix.dot(v)

    return itv, u, v

def truncated_cdf(etajTy, mu, sigma, left, right):
    numerator = mp.ncdf((etajTy - mu) / sigma) - mp.ncdf((left - mu) / sigma)
    denominator = mp.ncdf((right - mu) / sigma) - mp.ncdf((left - mu) / sigma)
    true_cdf = numerator / denominator 
    return true_cdf

def run_oc(model):
    ns, nt = 100, 100
    d = 1
    mu_s, mu_t = 0, 2
    delta_s = [0, 1, 2, 3, 4]
    delta_t = [0]
    Xs, _ = gen_data(ns, d, mu_s, delta_s)
    Xt, __ = gen_data(nt, d, mu_t, delta_t)

    Xs_hat = model.generator(torch.tensor(Xs, dtype=torch.float32)).detach().numpy()
    Xt_hat = model.generator(torch.tensor(Xt, dtype=torch.float32)).detach().numpy()
    X_hat = np.vstack((Xs_hat, Xt_hat))
    O, Y_hat = basic_anomaly_detection(X_hat)
    if O < ns:
        # print("Anomaly detected in source domain.")
        return None
    O = [O-ns]
    Oc = list(np.where(Y_hat[ns:ns+nt] == 0)[0])
    j = np.random.choice(O, 1, replace=False)[0]
    etj = np.zeros((nt, 1))
    etj[j][0] = 1
    etOc = np.zeros((nt, 1))
    etOc[Oc] = 1
    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))
    X = np.vstack((Xs, Xt))

    etajTX = etaj.T.dot(X)
    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))
    sigma = np.identity(ns+nt)
    etajTmu = etaj.T.dot(mu)
    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)
    
    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))
    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)

    itv = [np.NINF, np.inf]
    for i in range(X.shape[0]):
        itv = intersect(itv, get_dnn_interval(model, X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])

    sub_itv = [np.NINF, np.inf]
    _, uo, vo = get_dnn_interval(model, X[O[0]+100].reshape(-1, 1), a[O[0]+100].reshape(-1, 1), b[O[0]+100].reshape(-1, 1))
    I = np.ones((X_hat.shape[1],1))
    for i in range(X.shape[0]):
        if (i != O[0]+100):
            _, ui, vi = get_dnn_interval(model, X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))
            u = uo - ui
            v = vo - vi 
            u = I.T.dot(u)[0][0]
            v = I.T.dot(v)[0][0]
            sub__itv = solve_linear_inequality(-u, -v)
            sub_itv = intersect(sub_itv, sub__itv)
    itv = intersect(itv, sub_itv)

    cdf = truncated_cdf(etajTX[0][0], etajTmu[0][0], np.sqrt(etajTsigmaetaj[0][0]), itv[0], itv[1])
    p_value = float(2 * min(cdf, 1 - cdf))
    return p_value
    
def run_parametric(model):
    ns, nt = 100, 100
    d = 1
    mu_s, mu_t = 0, 2
    delta_s = [0, 1, 2, 3, 4]
    delta_t = [0]
    Xs, _ = gen_data(ns, d, mu_s, delta_s)
    Xt, __ = gen_data(nt, d, mu_t, delta_t)

    Xs_hat = model.generator(torch.tensor(Xs, dtype=torch.float32)).detach().numpy()
    Xt_hat = model.generator(torch.tensor(Xt, dtype=torch.float32)).detach().numpy()
    X_hat = np.vstack((Xs_hat, Xt_hat))
    O, Y_hat = basic_anomaly_detection(X_hat)
    if O < ns:
        # print("Anomaly detected in source domain.")
        return None
    O = [O-ns]
    Oc = list(np.where(Y_hat[ns:ns+nt] == 0)[0])
    j = np.random.choice(O, 1, replace=False)[0]
    etj = np.zeros((nt, 1))
    etj[j][0] = 1
    etOc = np.zeros((nt, 1))
    etOc[Oc] = 1
    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))
    X = np.vstack((Xs, Xt))

    etajTX = etaj.T.dot(X)
    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))
    sigma = np.identity(ns+nt)
    etajTmu = etaj.T.dot(mu)
    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)
    
    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))
    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)

    itv = [np.NINF, np.inf]
    for i in range(X.shape[0]):
        itv = intersect(itv, get_dnn_interval(model, X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])

    sub_itv = [np.NINF, np.inf]
    _, uo, vo = get_dnn_interval(model, X[O[0]+100].reshape(-1, 1), a[O[0]+100].reshape(-1, 1), b[O[0]+100].reshape(-1, 1))
    I = np.ones((X_hat.shape[1],1))
    for i in range(X.shape[0]):
        if (i != O[0]+100):
            _, ui, vi = get_dnn_interval(model, X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))
            u = uo - ui
            v = vo - vi 
            u = I.T.dot(u)[0][0]
            v = I.T.dot(v)[0][0]
            sub__itv = solve_linear_inequality(-u, -v)
            sub_itv = intersect(sub_itv, sub__itv)
    itv = intersect(itv, sub_itv)

    cdf = truncated_cdf(etajTX[0][0], etajTmu[0][0], np.sqrt(etajTsigmaetaj[0][0]), itv[0], itv[1])
    p_value = float(2 * min(cdf, 1 - cdf))
    return p_value

if __name__ == '__main__':
    os.environ["MKL_NUM_THREADS"] = "1"
    os.environ["NUMEXPR_NUM_THREADS"] = "1"
    os.environ["OMP_NUM_THREADS"] = "1"

    d = 1
    generator_hidden_dims = [10, 10, 10]
    critic_hidden_dims = [10]
    print("Loading model...")
    model = WDGRL(d, generator_hidden_dims=generator_hidden_dims, critic_hidden_dims=critic_hidden_dims)
    MODEL_DIR = "models"
    INDEX_FILE = os.path.join(MODEL_DIR, "index.txt")
    index = get_next_index(INDEX_FILE) 
    # Try to load a matching model
    matching_model_found = False
    for i in range(index):
        try:
            model_name = f'wdgrl_{i}'
            # Load the saved checkpoint
            checkpoint = torch.load(f"models/{model_name}.pth", map_location=model.device, weights_only=True)
            if model_parameters_match(model, checkpoint):
                # Restore the model weights
                model.generator.load_state_dict(checkpoint['generator_state_dict'])
                model.critic.load_state_dict(checkpoint['critic_state_dict'])
                print(f"Model loaded successfully from models/{model_name}.pth!")
                matching_model_found = True
                break
        except (FileNotFoundError, ValueError):
           continue
    # If no matching model was found, train a new one
    if not matching_model_found:
        print("No matching model found in models folder. Training a new model...")
        run(d, generator_hidden_dims=generator_hidden_dims, critic_hidden_dims=critic_hidden_dims)
        index = get_next_index(INDEX_FILE) - 1
        model_name = f'wdgrl_{index}'
        # Load the saved checkpoint
        checkpoint = torch.load(f"models/{model_name}.pth", map_location=model.device, weights_only=True)
        print(f"Model loaded successfully from models/{model_name}.pth!")

    max_iteration = 2000
    alpha = 0.05
    list_p_value = []
    count = 0
    detect = 0

    list_model = [model] * max_iteration
    pool = Pool(initializer=np.random.seed)
    list_result = pool.map(run_oc, list_model)

    for p_value in list_result:
        if p_value is None:
            continue
        detect += 1
        list_p_value.append(p_value)
        if p_value <= alpha:
            count += 1

    print(f'FPR: {count / detect}')
    plt.hist(list_p_value)
    plt.show()
    plt.close()
    print(f"ks-test result: {stats.kstest(list_p_value, 'uniform')[1]}")