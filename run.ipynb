{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gen_data(mu, delta, n, d: int = 2):\n",
    "    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))\n",
    "    mu = np.full((n, d), mu, dtype=np.float64)\n",
    "\n",
    "    if delta == 0.0:\n",
    "        return mu + noise, np.zeros(n)\n",
    "    \n",
    "    # 10% of the data are abnormal\n",
    "    abnormal_idx = np.random.choice(n, int(n/10), replace=False)\n",
    "\n",
    "    mu[abnormal_idx, :] += delta\n",
    "\n",
    "    X = mu + noise \n",
    "    Y = np.zeros(n)\n",
    "    Y[abnormal_idx] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Feature extractor network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Domain critic network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class WDGRL():\n",
    "    def __init__(self, input_dim: int=2, generator_hidden_dims: List[int]=[32, 16, 8, 4, 2], critic_hidden_dims: List[int]=[32, 16, 8, 4, 2],\n",
    "                 gamma: float = 0.1, _lr_generator: float = 1e-2, _lr_critic: float = 1e-2, \n",
    "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.generator = Generator(input_dim, generator_hidden_dims).to(self.device)\n",
    "        self.critic = Critic(generator_hidden_dims[-1], critic_hidden_dims).to(self.device)\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=_lr_generator)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=_lr_critic)\n",
    "    \n",
    "    def compute_gradient_penalty(self, source_data: torch.Tensor, target_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute gradient penalty.\"\"\"\n",
    "        if source_data.size(0) > target_data.size(0):\n",
    "            ms = source_data.size(0)\n",
    "            mt = target_data.size(0)\n",
    "            gradient_penalty = 0\n",
    "            for _ in range(0, ms, mt):\n",
    "                source_chunk = source_data[_:_+mt]\n",
    "                target_chunk = target_data\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            if ms % mt != 0:\n",
    "                source_chunk = source_data[ms-mt:]\n",
    "                perm = torch.randperm(mt)\n",
    "                idx = perm[:ms % mt]\n",
    "                target_chunk = target_data[idx]\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            return gradient_penalty / ((ms // mt) + (ms % mt != 0)) \n",
    "        \n",
    "        # For balanced batch\n",
    "        alpha = torch.rand(source_data.size(0), 1).to(self.device)\n",
    "        interpolates = (alpha * source_data + ((1 - alpha) * target_data)).requires_grad_(True)\n",
    "        \n",
    "        # Domain critic outputs\n",
    "        dc_output = self.critic(interpolates)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=dc_output,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        # Compute gradient penalty\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    def train(self, source_loader: DataLoader, target_loader: DataLoader, num_epochs: int = 100, dc_iter: int = 100) -> List[float]:\n",
    "        self.generator.train()\n",
    "        self.critic.train()\n",
    "        losses = []\n",
    "        source_critic_scores = []\n",
    "        target_critic_scores = []\n",
    "        for epoch in trange(num_epochs, desc='Epoch'):\n",
    "            loss = 0\n",
    "            for (source_data, _), (target_data, _) in zip(source_loader, target_loader):\n",
    "                source_data, target_data = source_data.to(self.device), target_data.to(self.device)\n",
    "\n",
    "                # Train domain critic\n",
    "                for _ in range(dc_iter):\n",
    "                    self.critic_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        source_features = self.generator(source_data)\n",
    "                        target_features = self.generator(target_data)\n",
    "                    \n",
    "                    # Compute empirical Wasserstein distance\n",
    "                    dc_source = self.critic(source_features)\n",
    "                    dc_target = self.critic(target_features)\n",
    "                    wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.compute_gradient_penalty(source_features, target_features)\n",
    "\n",
    "                    # Domain critic loss\n",
    "                    dc_loss = - wasserstein_distance + self.gamma * gradient_penalty\n",
    "                    dc_loss.backward()\n",
    "                    self.critic_optimizer.step()\n",
    "\n",
    "                # Train feature extractor\n",
    "                self.generator_optimizer.zero_grad()\n",
    "                source_features = self.generator(source_data)\n",
    "                target_features = self.generator(target_data)\n",
    "                dc_source = self.critic(source_features)\n",
    "                dc_target = self.critic(target_features)\n",
    "                wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "                wasserstein_distance.backward()\n",
    "                self.generator_optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    loss += wasserstein_distance.item()\n",
    "                    \n",
    "            source_critic_scores.append(self.criticize(source_loader.dataset.tensors[0].to(self.device)))\n",
    "            target_critic_scores.append(self.criticize(target_loader.dataset.tensors[0].to(self.device)))\n",
    "            losses.append(loss/len(source_loader))\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | Loss: {wasserstein_distance.item()}')\n",
    "        return losses, source_critic_scores, target_critic_scores\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_feature(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.generator.eval()\n",
    "        return self.generator(x)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def criticize(self, x: torch.Tensor) -> float:\n",
    "        self.generator.eval()\n",
    "        self.critic.eval()\n",
    "        return self.critic(self.generator(x)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the WDGRL model (same architecture as before)\n",
    "model = WDGRL(input_dim=1, generator_hidden_dims=[10, 10, 10], critic_hidden_dims=[10])\n",
    "\n",
    "# Load the saved checkpoint\n",
    "checkpoint = torch.load(\"wdgrl.pth\", map_location=model.device, weights_only=True)\n",
    "\n",
    "# Restore the model weights\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Create synthetic dataset and dataloaders for domain adaptation.\"\"\"\n",
    "# Create datasets\n",
    "ns, nt, d = 100, 10, 1\n",
    "mu_s, mu_t = 0, 20\n",
    "delta_s, delta_t = 4, 0\n",
    "xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "plt.scatter(xs[:, 0], np.zeros_like(xs[:, 0]), c=ys, cmap='viridis', s=2)\n",
    "plt.scatter(xt[:, 0], np.zeros_like(xt[:, 0]), c=yt, cmap='cool', s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4336, 0.0000, 0.0000, 0.0000, 0.0000, 0.3233, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4231, 0.0000, 0.0000, 0.0000, 0.0000, 0.3172, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4172, 0.0000, 0.0000, 0.0000, 0.0000, 0.3138, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4364, 0.0000, 0.0000, 0.0000, 0.0000, 0.3250, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4303, 0.0000, 0.0000, 0.0000, 0.0000, 0.3214, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4419, 0.0000, 0.0000, 0.0000, 0.0000, 0.3282, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4152, 0.0000, 0.0000, 0.0000, 0.0000, 0.3126, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4234, 0.0000, 0.0000, 0.0000, 0.0000, 0.3174, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4359, 0.0000, 0.0000, 0.0000, 0.0000, 0.3247, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4135, 0.0000, 0.0000, 0.0000, 0.0000, 0.3116, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "xs = torch.FloatTensor(xs)\n",
    "ys = torch.LongTensor(ys)\n",
    "xt = torch.FloatTensor(xt)\n",
    "yt = torch.LongTensor(yt)\n",
    "xs_hat = model.extract_feature(xs.cuda())\n",
    "xt_hat = model.extract_feature(xt.cuda())\n",
    "print(xt_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_sum(X):\n",
    "    return np.argmax(np.sum(X, axis=1))\n",
    "x_hat = torch.cat([xs_hat, xt_hat], dim=0).cpu().numpy()\n",
    "O = max_sum(x_hat)\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "# O = []\n",
    "# alpha = 0.5\n",
    "# for i in range(x_hat.shape[1]):\n",
    "#     x_hat_i = x_hat[:, i]\n",
    "#     median = x_hat_i.median().item()\n",
    "#     mad = torch.abs(x_hat_i - median).median().item()\n",
    "#     lower = median - alpha * mad\n",
    "#     upper = median + alpha * mad\n",
    "#     for j in range(nt):\n",
    "#         value = xt_hat[j, i].item()\n",
    "#         if (value < lower or value > upper) and j not in O:\n",
    "#             O.append(j)\n",
    "# O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "yt_hat = torch.zeros_like(yt)\n",
    "print(yt_hat)\n",
    "yt_hat[O-100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.50      0.45      0.47        10\n",
      "weighted avg       1.00      0.90      0.95        10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9000, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(yt, yt_hat)\n",
    "precision = precision_score(yt, yt_hat)\n",
    "recall = recall_score(yt, yt_hat)\n",
    "f1 = f1_score(yt, yt_hat)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(yt, yt_hat))\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(yt, yt_hat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5460882758701967"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mpmath import mp\n",
    "mp.dps = 500\n",
    "\n",
    "Oc = list(torch.where(yt == 0)[0])\n",
    "j = np.random.choice(O-100, 1, replace=False)[0]\n",
    "etj = np.zeros((nt, 1))\n",
    "etj[j][0] = 1\n",
    "etOc = np.zeros((nt, 1))\n",
    "etOc[Oc] = 1\n",
    "etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "\n",
    "etajTX = etaj.T.dot(X)\n",
    "mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "sigma = np.identity(ns+nt)\n",
    "etajTmu = etaj.T.dot(mu)\n",
    "etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "cdf = mp.ncdf((etajTX[0][0] - etajTmu[0][0]) / np.sqrt(etajTsigmaetaj[0][0]))\n",
    "p_value = float(2 * min(cdf, 1 - cdf))\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive $p$-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naive():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = 4, 0\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "    \n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = []\n",
    "    alpha = 0.5\n",
    "    for i in range(x_hat.shape[1]):\n",
    "        x_hat_i = x_hat[:, i]\n",
    "        median = x_hat_i.median().item()\n",
    "        mad = torch.abs(x_hat_i - median).median().item()\n",
    "        lower = median - alpha * mad\n",
    "        upper = median + alpha * mad\n",
    "        for j in range(nt):\n",
    "            value = xt_hat[j, i].item()\n",
    "            if (value < lower or value > upper) and j not in O:\n",
    "                O.append(j)\n",
    "    \n",
    "    if len(O) == 0:\n",
    "        return None\n",
    "    \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "\n",
    "    etajTX = etaj.T.dot(X)\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    cdf = mp.ncdf((etajTX[0][0] - etajTmu[0][0]) / np.sqrt(etajTsigmaetaj[0][0]))\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iteration = 1000\n",
    "# alpha = 0.05\n",
    "# list_p_value = []\n",
    "# count = 0\n",
    "\n",
    "# for i in range(max_iteration):\n",
    "#     p_value = run_naive()\n",
    "#     if p_value is None:\n",
    "#         continue\n",
    "#     list_p_value.append(p_value)\n",
    "#     if p_value <= alpha:\n",
    "#         count += 1\n",
    "# print(f'FPR: {count / max_iteration}')\n",
    "# plt.hist(list_p_value)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.24824876e-01]\n",
      " [ 1.47933769e+00]\n",
      " [-6.97039783e-01]\n",
      " [ 1.55214214e+00]\n",
      " [-3.66752952e-01]\n",
      " [ 1.40682435e+00]\n",
      " [ 6.22364646e-03]\n",
      " [ 8.01227927e-01]\n",
      " [ 9.21947539e-01]\n",
      " [ 1.00068748e+00]\n",
      " [ 4.16120708e-01]\n",
      " [ 2.26306930e-01]\n",
      " [-1.57185018e+00]\n",
      " [-2.47593284e-01]\n",
      " [-1.70653141e+00]\n",
      " [ 6.42575145e-01]\n",
      " [ 2.17651129e+00]\n",
      " [-4.42898482e-01]\n",
      " [-4.89341199e-01]\n",
      " [-1.06704438e+00]\n",
      " [-3.08048069e-01]\n",
      " [ 1.50255466e+00]\n",
      " [-4.82477784e-01]\n",
      " [ 1.20185328e+00]\n",
      " [ 1.35469973e-01]\n",
      " [ 4.22815943e+00]\n",
      " [ 4.47247386e-01]\n",
      " [-8.88022840e-01]\n",
      " [ 6.70722127e-01]\n",
      " [-5.83628416e-02]\n",
      " [ 8.66991341e-01]\n",
      " [-1.56511796e+00]\n",
      " [-1.27894926e+00]\n",
      " [-6.63939178e-01]\n",
      " [-8.57146829e-02]\n",
      " [-5.24681926e-01]\n",
      " [-1.21946406e+00]\n",
      " [ 1.35156882e+00]\n",
      " [-1.03164923e+00]\n",
      " [-1.09222877e+00]\n",
      " [ 8.08733046e-01]\n",
      " [ 2.84091264e-01]\n",
      " [-3.73895675e-01]\n",
      " [-2.09751892e+00]\n",
      " [ 5.14014959e+00]\n",
      " [ 6.36589050e-01]\n",
      " [ 3.40726346e-01]\n",
      " [-1.04375467e-01]\n",
      " [-4.65014726e-02]\n",
      " [ 8.69423866e-01]\n",
      " [-1.20482838e+00]\n",
      " [ 1.34428406e+00]\n",
      " [ 7.84123480e-01]\n",
      " [-4.37201440e-01]\n",
      " [-3.83742005e-02]\n",
      " [ 5.91516197e-02]\n",
      " [ 1.59728003e+00]\n",
      " [-1.79087669e-01]\n",
      " [-1.75569206e-01]\n",
      " [ 3.55911279e+00]\n",
      " [ 5.65541089e-01]\n",
      " [-1.34006095e+00]\n",
      " [ 4.32640696e+00]\n",
      " [-4.74974602e-01]\n",
      " [-6.96460009e-01]\n",
      " [ 3.51140070e+00]\n",
      " [ 1.03188169e+00]\n",
      " [ 1.07226825e+00]\n",
      " [ 2.84296966e+00]\n",
      " [ 2.90120810e-01]\n",
      " [ 1.68658507e+00]\n",
      " [-1.14796901e+00]\n",
      " [-1.17023957e+00]\n",
      " [ 3.20976764e-01]\n",
      " [ 3.08572936e+00]\n",
      " [ 4.54999161e+00]\n",
      " [-1.38443008e-01]\n",
      " [-1.81920195e+00]\n",
      " [ 1.66468784e-01]\n",
      " [-7.90570080e-01]\n",
      " [ 1.04227734e+00]\n",
      " [ 1.64527881e+00]\n",
      " [ 3.98060894e+00]\n",
      " [-9.64495182e-01]\n",
      " [-7.07440615e-01]\n",
      " [ 8.13520610e-01]\n",
      " [-8.01634490e-02]\n",
      " [ 1.60430300e+00]\n",
      " [-1.51022458e+00]\n",
      " [ 1.04352891e+00]\n",
      " [-1.93152022e+00]\n",
      " [-2.14814827e-01]\n",
      " [-1.24199784e+00]\n",
      " [-2.43120581e-01]\n",
      " [ 3.58715200e+00]\n",
      " [-8.56458306e-01]\n",
      " [ 1.39812124e+00]\n",
      " [-2.10541263e-01]\n",
      " [ 8.89091194e-01]\n",
      " [ 1.19054329e+00]\n",
      " [ 2.01497316e+01]\n",
      " [ 1.98663685e+01]\n",
      " [ 1.93556778e+01]\n",
      " [ 2.10283749e+01]\n",
      " [ 2.04953434e+01]\n",
      " [ 2.15034020e+01]\n",
      " [ 1.91821778e+01]\n",
      " [ 1.99000752e+01]\n",
      " [ 2.09814331e+01]\n",
      " [ 1.90347321e+01]]\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 1.        ]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]]\n"
     ]
    }
   ],
   "source": [
    "b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(itv1, itv2):\n",
    "    # print(itv1, itv2)\n",
    "    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]\n",
    "    if itv[0] > itv[1]:\n",
    "        return None    \n",
    "    return itv\n",
    "\n",
    "def solve_linear_inequality(u, v): #u + vz < 0\n",
    "    if (v > -1e-16 and v < 1e-16):\n",
    "        if (u < 0):\n",
    "            return [-np.Inf, np.Inf]\n",
    "        else:\n",
    "            print('error')\n",
    "            return None\n",
    "    if (v < 0):\n",
    "        return [-u/v, np.Inf]\n",
    "    return [np.NINF, -u/v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-inf, inf], array([[0.32881318],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.26970707],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]))\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def get_interval(Xtj, a, b):\n",
    "    layers = []\n",
    "\n",
    "    for name, param in model.generator.named_children():\n",
    "        temp = dict(param._modules)\n",
    "        \n",
    "        for layer_name in temp.values():\n",
    "            if ('Linear' in str(layer_name)):\n",
    "                layers.append('Linear')\n",
    "            elif ('ReLU' in str(layer_name)):\n",
    "                layers.append('ReLU')\n",
    "\n",
    "    ptr = 0\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    u = a\n",
    "    v = b\n",
    "    temp = Xtj\n",
    "    weight = None\n",
    "    bias = None\n",
    "    for name, param in model.generator.named_parameters():\n",
    "        if (layers[ptr] == 'Linear'):\n",
    "            if ('weight' in name):\n",
    "                weight = param.data.cpu().detach().numpy()\n",
    "            elif ('bias' in name):\n",
    "                bias = param.data.cpu().detach().numpy().reshape(-1, 1)\n",
    "                ptr += 1\n",
    "                temp = weight.dot(temp) + bias\n",
    "                u = weight.dot(u) + bias\n",
    "                v = weight.dot(v)\n",
    "\n",
    "        if (ptr < len(layers) and layers[ptr] == 'ReLU'):\n",
    "            ptr += 1\n",
    "            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))\n",
    "            sub_itv = [np.NINF, np.inf]\n",
    "            for i in range(temp.shape[0]):\n",
    "                if temp[i] > 0:\n",
    "                    Relu_matrix[i][i] = 1\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i], -v[i]))\n",
    "                else:\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i], v[i]))\n",
    "            itv = intersect(itv, sub_itv)\n",
    "            temp = Relu_matrix.dot(temp)\n",
    "            u = Relu_matrix.dot(u)\n",
    "            v = Relu_matrix.dot(v)\n",
    "\n",
    "    return itv, u, v\n",
    "\n",
    "\n",
    "print(get_interval(X[0].reshape(-1,1), a[0].reshape(-1, 1), b[0].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-13.64229481]), array([1.2183033])]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itv = [np.NINF, np.Inf]\n",
    "for i in range(X.shape[0]):\n",
    "    itv = intersect(itv, get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "_, uo, vo = get_interval(X[O].reshape(-1, 1), a[O].reshape(-1, 1), b[O].reshape(-1, 1))\n",
    "I = np.ones(x_hat.shape[1])\n",
    "for i in range(X.shape[0]):\n",
    "    if (i != O):\n",
    "        _, ui, vi = get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "        u = uo - ui\n",
    "        v = vo - vi \n",
    "        u = I.T.dot(u)\n",
    "        v = I.T.dot(v)\n",
    "        sub_itv = solve_linear_inequality(-u, -v)\n",
    "        itv = intersect(itv, sub_itv)\n",
    "itv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_cdf(etajTy, mu, sigma, left, right):\n",
    "    numerator = mp.ncdf((etajTy - mu) / sigma) - mp.ncdf((left - mu) / sigma)\n",
    "    denominator = mp.ncdf((right - mu) / sigma) - mp.ncdf((left - mu) / sigma)\n",
    "    if denominator <= 1e-16:\n",
    "        true_cdf = 1\n",
    "    else:\n",
    "        true_cdf = numerator / denominator \n",
    "    return true_cdf\n",
    "def run_si_oc():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = 4, 0\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "    \n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < 100):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - 100]   \n",
    "    \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "    \n",
    "    etajTX = etaj.T.dot(X)\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        itv = intersect(itv, get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "    print(itv)\n",
    "    _, uo, vo = get_interval(X[O].reshape(-1, 1), a[O].reshape(-1, 1), b[O].reshape(-1, 1))\n",
    "    print(uo, vo)\n",
    "    I = np.ones((x_hat.shape[1],1))\n",
    "    sub_itv = [np.NINF, np.inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        if (i not in O):\n",
    "            _, ui, vi = get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "            u = uo - ui\n",
    "            v = vo - vi \n",
    "            u = I.T.dot(u)\n",
    "            v = I.T.dot(v)\n",
    "            print(-u, -v)\n",
    "            sub_itv = intersect(sub_itv, solve_linear_inequality(-u, -v))\n",
    "    print(sub_itv)\n",
    "    itv = intersect(itv, sub_itv)\n",
    "    print(itv)\n",
    "    print('------------------------')\n",
    "    cdf = truncated_cdf(etajTX[0][0], etajTmu[0][0], np.sqrt(etajTsigmaetaj[0][0]), itv[0], itv[1])\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    return p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-2.14890955]), array([-2.06224687])]\n",
      "[[0.36749947]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.29020349]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[-0.18257239]] [[-0.]]\n",
      "[[-0.08489331]] [[-0.]]\n",
      "[[0.00120689]] [[-0.]]\n",
      "error\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iteration):\n\u001b[1;32m----> 7\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[43mrun_si_oc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[114], line 76\u001b[0m, in \u001b[0;36mrun_si_oc\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m         v \u001b[38;5;241m=\u001b[39m I\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(v)\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m-\u001b[39mu, \u001b[38;5;241m-\u001b[39mv)\n\u001b[1;32m---> 76\u001b[0m         sub_itv \u001b[38;5;241m=\u001b[39m \u001b[43mintersect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_itv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve_linear_inequality\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(sub_itv)\n\u001b[0;32m     78\u001b[0m itv \u001b[38;5;241m=\u001b[39m intersect(itv, sub_itv)\n",
      "Cell \u001b[1;32mIn[109], line 3\u001b[0m, in \u001b[0;36mintersect\u001b[1;34m(itv1, itv2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintersect\u001b[39m(itv1, itv2):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# print(itv1, itv2)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     itv \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(itv1[\u001b[38;5;241m0\u001b[39m], \u001b[43mitv2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m), \u001b[38;5;28mmin\u001b[39m(itv1[\u001b[38;5;241m1\u001b[39m], itv2[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m itv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m itv[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m    \n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "max_iteration = 1000\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "\n",
    "for i in range(max_iteration):\n",
    "    p_value = run_si_oc()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "print(f'FPR: {count / max_iteration}')\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
