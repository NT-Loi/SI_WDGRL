{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gen_data(mu, delta, n, d: int = 2):\n",
    "    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))\n",
    "    mu = np.full((n, d), mu, dtype=np.float64)\n",
    "\n",
    "    if delta == 0.0:\n",
    "        return mu + noise, np.zeros(n)\n",
    "    \n",
    "    # 10% of the data are abnormal\n",
    "    abnormal_idx = np.random.choice(n, int(n/10), replace=False)\n",
    "\n",
    "    mu[abnormal_idx, :] += delta\n",
    "\n",
    "    X = mu + noise \n",
    "    Y = np.zeros(n)\n",
    "    Y[abnormal_idx] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Feature extractor network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Domain critic network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class WDGRL():\n",
    "    def __init__(self, input_dim: int=2, generator_hidden_dims: List[int]=[32, 16, 8, 4, 2], critic_hidden_dims: List[int]=[32, 16, 8, 4, 2],\n",
    "                 gamma: float = 0.1, _lr_generator: float = 1e-2, _lr_critic: float = 1e-2, \n",
    "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.generator = Generator(input_dim, generator_hidden_dims).to(self.device)\n",
    "        self.critic = Critic(generator_hidden_dims[-1], critic_hidden_dims).to(self.device)\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=_lr_generator)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=_lr_critic)\n",
    "    \n",
    "    def compute_gradient_penalty(self, source_data: torch.Tensor, target_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute gradient penalty.\"\"\"\n",
    "        if source_data.size(0) > target_data.size(0):\n",
    "            ms = source_data.size(0)\n",
    "            mt = target_data.size(0)\n",
    "            gradient_penalty = 0\n",
    "            for _ in range(0, ms, mt):\n",
    "                source_chunk = source_data[_:_+mt]\n",
    "                target_chunk = target_data\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            if ms % mt != 0:\n",
    "                source_chunk = source_data[ms-mt:]\n",
    "                perm = torch.randperm(mt)\n",
    "                idx = perm[:ms % mt]\n",
    "                target_chunk = target_data[idx]\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            return gradient_penalty / ((ms // mt) + (ms % mt != 0)) \n",
    "        \n",
    "        # For balanced batch\n",
    "        alpha = torch.rand(source_data.size(0), 1).to(self.device)\n",
    "        interpolates = (alpha * source_data + ((1 - alpha) * target_data)).requires_grad_(True)\n",
    "        \n",
    "        # Domain critic outputs\n",
    "        dc_output = self.critic(interpolates)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=dc_output,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        # Compute gradient penalty\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    def train(self, source_loader: DataLoader, target_loader: DataLoader, num_epochs: int = 100, dc_iter: int = 100) -> List[float]:\n",
    "        self.generator.train()\n",
    "        self.critic.train()\n",
    "        losses = []\n",
    "        source_critic_scores = []\n",
    "        target_critic_scores = []\n",
    "        for epoch in trange(num_epochs, desc='Epoch'):\n",
    "            loss = 0\n",
    "            for (source_data, _), (target_data, _) in zip(source_loader, target_loader):\n",
    "                source_data, target_data = source_data.to(self.device), target_data.to(self.device)\n",
    "\n",
    "                # Train domain critic\n",
    "                for _ in range(dc_iter):\n",
    "                    self.critic_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        source_features = self.generator(source_data)\n",
    "                        target_features = self.generator(target_data)\n",
    "                    \n",
    "                    # Compute empirical Wasserstein distance\n",
    "                    dc_source = self.critic(source_features)\n",
    "                    dc_target = self.critic(target_features)\n",
    "                    wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.compute_gradient_penalty(source_features, target_features)\n",
    "\n",
    "                    # Domain critic loss\n",
    "                    dc_loss = - wasserstein_distance + self.gamma * gradient_penalty\n",
    "                    dc_loss.backward()\n",
    "                    self.critic_optimizer.step()\n",
    "\n",
    "                # Train feature extractor\n",
    "                self.generator_optimizer.zero_grad()\n",
    "                source_features = self.generator(source_data)\n",
    "                target_features = self.generator(target_data)\n",
    "                dc_source = self.critic(source_features)\n",
    "                dc_target = self.critic(target_features)\n",
    "                wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "                wasserstein_distance.backward()\n",
    "                self.generator_optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    loss += wasserstein_distance.item()\n",
    "                    \n",
    "            source_critic_scores.append(self.criticize(source_loader.dataset.tensors[0].to(self.device)))\n",
    "            target_critic_scores.append(self.criticize(target_loader.dataset.tensors[0].to(self.device)))\n",
    "            losses.append(loss/len(source_loader))\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | Loss: {wasserstein_distance.item()}')\n",
    "        return losses, source_critic_scores, target_critic_scores\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_feature(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.generator.eval()\n",
    "        return self.generator(x)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def criticize(self, x: torch.Tensor) -> float:\n",
    "        self.generator.eval()\n",
    "        self.critic.eval()\n",
    "        return self.critic(self.generator(x)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the WDGRL model (same architecture as before)\n",
    "model = WDGRL(input_dim=1, generator_hidden_dims=[10, 10, 10], critic_hidden_dims=[10])\n",
    "\n",
    "# Load the saved checkpoint\n",
    "checkpoint = torch.load(\"wdgrl.pth\", map_location=model.device, weights_only=True)\n",
    "\n",
    "# Restore the model weights\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Create synthetic dataset and dataloaders for domain adaptation.\"\"\"\n",
    "# Create datasets\n",
    "ns, nt, d = 100, 10, 1\n",
    "mu_s, mu_t = 0, 20\n",
    "delta_s, delta_t = 4, 0\n",
    "xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "plt.scatter(xs[:, 0], np.zeros_like(xs[:, 0]), c=ys, cmap='viridis', s=2)\n",
    "plt.scatter(xt[:, 0], np.zeros_like(xt[:, 0]), c=yt, cmap='cool', s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4282, 0.0000, 0.0000, 0.0000, 0.0000, 0.3202, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4243, 0.0000, 0.0000, 0.0000, 0.0000, 0.3179, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4276, 0.0000, 0.0000, 0.0000, 0.0000, 0.3198, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4182, 0.0000, 0.0000, 0.0000, 0.0000, 0.3144, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4343, 0.0000, 0.0000, 0.0000, 0.0000, 0.3238, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4230, 0.0000, 0.0000, 0.0000, 0.0000, 0.3172, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4214, 0.0000, 0.0000, 0.0000, 0.0000, 0.3162, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4336, 0.0000, 0.0000, 0.0000, 0.0000, 0.3233, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4170, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4229, 0.0000, 0.0000, 0.0000, 0.0000, 0.3171, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "xs = torch.FloatTensor(xs)\n",
    "ys = torch.LongTensor(ys)\n",
    "xt = torch.FloatTensor(xt)\n",
    "yt = torch.LongTensor(yt)\n",
    "xs_hat = model.extract_feature(xs.cuda())\n",
    "xt_hat = model.extract_feature(xt.cuda())\n",
    "print(xt_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_sum(X):\n",
    "    return np.argmax(np.sum(X, axis=1))\n",
    "x_hat = torch.cat([xs_hat, xt_hat], dim=0).cpu().numpy()\n",
    "O = max_sum(x_hat)\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "# O = []\n",
    "# alpha = 0.5\n",
    "# for i in range(x_hat.shape[1]):\n",
    "#     x_hat_i = x_hat[:, i]\n",
    "#     median = x_hat_i.median().item()\n",
    "#     mad = torch.abs(x_hat_i - median).median().item()\n",
    "#     lower = median - alpha * mad\n",
    "#     upper = median + alpha * mad\n",
    "#     for j in range(nt):\n",
    "#         value = xt_hat[j, i].item()\n",
    "#         if (value < lower or value > upper) and j not in O:\n",
    "#             O.append(j)\n",
    "# O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "yt_hat = torch.zeros_like(yt)\n",
    "print(yt_hat)\n",
    "yt_hat[O-100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.50      0.45      0.47        10\n",
      "weighted avg       1.00      0.90      0.95        10\n",
      "\n",
      "Accuracy: 0.9000, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(yt, yt_hat)\n",
    "precision = precision_score(yt, yt_hat)\n",
    "recall = recall_score(yt, yt_hat)\n",
    "f1 = f1_score(yt, yt_hat)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(yt, yt_hat))\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(yt, yt_hat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446609851531373"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mpmath import mp\n",
    "mp.dps = 500\n",
    "\n",
    "Oc = list(torch.where(yt == 0)[0])\n",
    "j = np.random.choice(O-100, 1, replace=False)[0]\n",
    "etj = np.zeros((nt, 1))\n",
    "etj[j][0] = 1\n",
    "etOc = np.zeros((nt, 1))\n",
    "etOc[Oc] = 1\n",
    "etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "\n",
    "etajTX = etaj.T.dot(X)\n",
    "mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "sigma = np.identity(ns+nt)\n",
    "etajTmu = etaj.T.dot(mu)\n",
    "etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "cdf = mp.ncdf((etajTX[0][0] - etajTmu[0][0]) / np.sqrt(etajTsigmaetaj[0][0]))\n",
    "p_value = float(2 * min(cdf, 1 - cdf))\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive $p$-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naive():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = 4, 0\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "    \n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = []\n",
    "    alpha = 0.5\n",
    "    for i in range(x_hat.shape[1]):\n",
    "        x_hat_i = x_hat[:, i]\n",
    "        median = x_hat_i.median().item()\n",
    "        mad = torch.abs(x_hat_i - median).median().item()\n",
    "        lower = median - alpha * mad\n",
    "        upper = median + alpha * mad\n",
    "        for j in range(nt):\n",
    "            value = xt_hat[j, i].item()\n",
    "            if (value < lower or value > upper) and j not in O:\n",
    "                O.append(j)\n",
    "    \n",
    "    if len(O) == 0:\n",
    "        return None\n",
    "    \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "\n",
    "    etajTX = etaj.T.dot(X)\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    cdf = mp.ncdf((etajTX[0][0] - etajTmu[0][0]) / np.sqrt(etajTsigmaetaj[0][0]))\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iteration = 1000\n",
    "# alpha = 0.05\n",
    "# list_p_value = []\n",
    "# count = 0\n",
    "\n",
    "# for i in range(max_iteration):\n",
    "#     p_value = run_naive()\n",
    "#     if p_value is None:\n",
    "#         continue\n",
    "#     list_p_value.append(p_value)\n",
    "#     if p_value <= alpha:\n",
    "#         count += 1\n",
    "# print(f'FPR: {count / max_iteration}')\n",
    "# plt.hist(list_p_value)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.70365393e-01]\n",
      " [ 3.99653196e+00]\n",
      " [-7.08473921e-02]\n",
      " [-1.21445882e+00]\n",
      " [ 4.58288574e+00]\n",
      " [-1.51459336e+00]\n",
      " [ 1.37680495e+00]\n",
      " [-8.16607118e-01]\n",
      " [-8.08007643e-02]\n",
      " [ 2.17468888e-01]\n",
      " [-2.48162508e-01]\n",
      " [ 3.59077835e+00]\n",
      " [ 1.41502094e+00]\n",
      " [-2.05231622e-01]\n",
      " [ 1.28936625e+00]\n",
      " [ 1.50800586e+00]\n",
      " [-1.81352258e-01]\n",
      " [-6.22878015e-01]\n",
      " [-1.89292181e+00]\n",
      " [ 1.27033567e+00]\n",
      " [ 1.47830978e-01]\n",
      " [ 3.51988077e+00]\n",
      " [ 1.16056606e-01]\n",
      " [-1.30086851e+00]\n",
      " [-6.70188814e-02]\n",
      " [ 1.03770709e+00]\n",
      " [ 1.14097230e-01]\n",
      " [ 2.08936524e+00]\n",
      " [ 2.71353245e+00]\n",
      " [ 1.47517633e+00]\n",
      " [ 1.06059873e+00]\n",
      " [ 4.07069802e-01]\n",
      " [ 5.86857414e+00]\n",
      " [ 4.42963696e+00]\n",
      " [ 6.24851108e-01]\n",
      " [ 5.07816017e-01]\n",
      " [-1.52954444e-01]\n",
      " [ 6.20771050e-01]\n",
      " [-1.86607814e+00]\n",
      " [ 6.96708262e-02]\n",
      " [-1.77123964e+00]\n",
      " [-7.24440575e-01]\n",
      " [-7.35010445e-01]\n",
      " [ 8.56888711e-01]\n",
      " [-3.13380837e-01]\n",
      " [ 1.34275448e+00]\n",
      " [ 1.18570638e+00]\n",
      " [-1.62808275e+00]\n",
      " [ 1.59525418e+00]\n",
      " [-7.36929059e-01]\n",
      " [ 3.33900738e+00]\n",
      " [-7.49024987e-01]\n",
      " [ 1.70924708e-01]\n",
      " [ 1.18235290e+00]\n",
      " [-1.76702511e+00]\n",
      " [-7.29169771e-02]\n",
      " [ 3.52892697e-01]\n",
      " [-8.45460057e-01]\n",
      " [-1.59857714e+00]\n",
      " [ 7.22133219e-01]\n",
      " [-2.90263295e-01]\n",
      " [-1.72365546e-01]\n",
      " [ 1.18535185e+00]\n",
      " [ 8.52431297e-01]\n",
      " [ 2.63620228e-01]\n",
      " [ 1.21867406e+00]\n",
      " [-7.24863946e-01]\n",
      " [ 4.42771006e+00]\n",
      " [ 3.26451004e-01]\n",
      " [-6.95110798e-01]\n",
      " [ 6.24734044e-01]\n",
      " [-1.38405800e+00]\n",
      " [ 1.46779573e+00]\n",
      " [ 6.60520077e-01]\n",
      " [ 7.38440752e-01]\n",
      " [ 4.27388906e-01]\n",
      " [ 1.44580090e+00]\n",
      " [ 8.50023150e-01]\n",
      " [ 3.03351432e-01]\n",
      " [-1.75282276e+00]\n",
      " [ 9.91206110e-01]\n",
      " [-4.01230156e-01]\n",
      " [-1.08261257e-01]\n",
      " [-1.60406256e+00]\n",
      " [ 2.72463799e-01]\n",
      " [ 4.09417331e-01]\n",
      " [-3.27565640e-01]\n",
      " [ 2.11288023e+00]\n",
      " [ 1.03954566e+00]\n",
      " [-1.77577343e-02]\n",
      " [-1.25232637e+00]\n",
      " [ 5.65664434e+00]\n",
      " [-1.07085533e-01]\n",
      " [ 1.60070324e+00]\n",
      " [ 5.02934837e+00]\n",
      " [ 6.33304775e-01]\n",
      " [-1.22479534e+00]\n",
      " [-1.17839837e+00]\n",
      " [ 3.55755925e-01]\n",
      " [ 9.29933548e-01]\n",
      " [ 2.02421931e+01]\n",
      " [ 1.99771667e+01]\n",
      " [ 2.01893156e+01]\n",
      " [ 1.93772600e+01]\n",
      " [ 2.07755011e+01]\n",
      " [ 1.97929934e+01]\n",
      " [ 1.96485937e+01]\n",
      " [ 2.07142256e+01]\n",
      " [ 1.92731779e+01]\n",
      " [ 1.97812403e+01]]\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.11111111]\n",
      " [ 1.        ]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]\n",
      " [-0.11111111]]\n"
     ]
    }
   ],
   "source": [
    "b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(itv1, itv2):\n",
    "    # print(itv1, itv2)\n",
    "    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]\n",
    "    if itv[0] > itv[1]:\n",
    "        return None    \n",
    "    return itv\n",
    "\n",
    "def solve_linear_inequality(u, v): #u + vz < 0\n",
    "    if (v > -1e-16 and v < 1e-16):\n",
    "        if (u < 0):\n",
    "            return [-np.Inf, np.Inf]\n",
    "        else:\n",
    "            print('error')\n",
    "            return None\n",
    "    if (v < 0):\n",
    "        return [-u/v, np.Inf]\n",
    "    return [np.NINF, -u/v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-inf, inf], array([[0.35257631],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.28628796],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ],\n",
      "       [0.        ]]), array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]))\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def get_interval(Xtj, a, b):\n",
    "    layers = []\n",
    "\n",
    "    for name, param in model.generator.named_children():\n",
    "        temp = dict(param._modules)\n",
    "        \n",
    "        for layer_name in temp.values():\n",
    "            if ('Linear' in str(layer_name)):\n",
    "                layers.append('Linear')\n",
    "            elif ('ReLU' in str(layer_name)):\n",
    "                layers.append('ReLU')\n",
    "\n",
    "    ptr = 0\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    u = a\n",
    "    v = b\n",
    "    temp = Xtj\n",
    "    weight = None\n",
    "    bias = None\n",
    "    for name, param in model.generator.named_parameters():\n",
    "        if (layers[ptr] == 'Linear'):\n",
    "            if ('weight' in name):\n",
    "                weight = param.data.cpu().detach().numpy()\n",
    "            elif ('bias' in name):\n",
    "                bias = param.data.cpu().detach().numpy().reshape(-1, 1)\n",
    "                ptr += 1\n",
    "                temp = weight.dot(temp) + bias\n",
    "                u = weight.dot(u) + bias\n",
    "                v = weight.dot(v)\n",
    "\n",
    "        if (ptr < len(layers) and layers[ptr] == 'ReLU'):\n",
    "            ptr += 1\n",
    "            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))\n",
    "            sub_itv = [np.NINF, np.inf]\n",
    "            for i in range(temp.shape[0]):\n",
    "                if temp[i] > 0:\n",
    "                    Relu_matrix[i][i] = 1\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i], -v[i]))\n",
    "                else:\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i], v[i]))\n",
    "            itv = intersect(itv, sub_itv)\n",
    "            temp = Relu_matrix.dot(temp)\n",
    "            u = Relu_matrix.dot(u)\n",
    "            v = Relu_matrix.dot(v)\n",
    "\n",
    "    return itv, u, v\n",
    "\n",
    "\n",
    "print(get_interval(X[0].reshape(-1,1), a[0].reshape(-1, 1), b[0].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-13.46972992]), array([0.7185009])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itv = [np.NINF, np.Inf]\n",
    "for i in range(X.shape[0]):\n",
    "    itv = intersect(itv, get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "_, uo, vo = get_interval(X[O].reshape(-1, 1), a[O].reshape(-1, 1), b[O].reshape(-1, 1))\n",
    "I = np.ones(x_hat.shape[1])\n",
    "for i in range(X.shape[0]):\n",
    "    if (i != O):\n",
    "        _, ui, vi = get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "        u = uo - ui\n",
    "        v = vo - vi \n",
    "        u = I.T.dot(u)\n",
    "        v = I.T.dot(v)\n",
    "        sub_itv = solve_linear_inequality(-u, -v)\n",
    "        itv = intersect(itv, sub_itv)\n",
    "itv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_cdf(etajTy, mu, sigma, left, right):\n",
    "    numerator = mp.ncdf((etajTy - mu) / sigma) - mp.ncdf((left - mu) / sigma)\n",
    "    denominator = mp.ncdf((right - mu) / sigma) - mp.ncdf((left - mu) / sigma)\n",
    "    if denominator <= 1e-16:\n",
    "        true_cdf = 1\n",
    "    else:\n",
    "        true_cdf = numerator / denominator \n",
    "    return true_cdf\n",
    "def run_basic_ad_da_si_oc():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = 4, 0\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "    \n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < 100):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - 100]   \n",
    "    \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "    \n",
    "    etajTX = etaj.T.dot(X)\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        itv = intersect(itv, get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "    print(itv)\n",
    "    _, uo, vo = get_interval(X[O].reshape(-1, 1), a[O].reshape(-1, 1), b[O].reshape(-1, 1))\n",
    "    print(uo, vo)\n",
    "    I = np.ones((x_hat.shape[1],1))\n",
    "    sub_itv = [np.NINF, np.inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        if (i not in O):\n",
    "            _, ui, vi = get_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "            u = uo - ui\n",
    "            v = vo - vi \n",
    "            u = I.T.dot(u)\n",
    "            v = I.T.dot(v)\n",
    "            print(-u, -v)\n",
    "            sub_itv = intersect(sub_itv, solve_linear_inequality(-u, -v))\n",
    "    print(sub_itv)\n",
    "    itv = intersect(itv, sub_itv)\n",
    "    print(itv)\n",
    "    print('------------------------')\n",
    "    cdf = truncated_cdf(etajTX[0][0], etajTmu[0][0], np.sqrt(etajTsigmaetaj[0][0]), itv[0], itv[1])\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    return p_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-2.51366302]), array([-2.11174328])]\n",
      "[[0.39046129]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.26866905]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[-0.08932274]] [[-0.]]\n",
      "[[-0.21351856]] [[-0.]]\n",
      "[[-0.10032238]] [[-0.]]\n",
      "[[-0.15470018]] [[-0.]]\n",
      "[[0.17210841]] [[-0.]]\n",
      "error\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iteration):\n\u001b[1;32m----> 7\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[43mrun_basic_ae_da_si_oc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[41], line 76\u001b[0m, in \u001b[0;36mrun_basic_ae_da_si_oc\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m         v \u001b[38;5;241m=\u001b[39m I\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(v)\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m-\u001b[39mu, \u001b[38;5;241m-\u001b[39mv)\n\u001b[1;32m---> 76\u001b[0m         sub_itv \u001b[38;5;241m=\u001b[39m \u001b[43mintersect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_itv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve_linear_inequality\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(sub_itv)\n\u001b[0;32m     78\u001b[0m itv \u001b[38;5;241m=\u001b[39m intersect(itv, sub_itv)\n",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m, in \u001b[0;36mintersect\u001b[1;34m(itv1, itv2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintersect\u001b[39m(itv1, itv2):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# print(itv1, itv2)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     itv \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(itv1[\u001b[38;5;241m0\u001b[39m], \u001b[43mitv2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m), \u001b[38;5;28mmin\u001b[39m(itv1[\u001b[38;5;241m1\u001b[39m], itv2[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m itv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m itv[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m    \n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "max_iteration = 1000\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "\n",
    "for i in range(max_iteration):\n",
    "    p_value = run_basic_ad_da_si_oc()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "print(f'FPR: {count / max_iteration}')\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_basic_ad_si_oc():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = 4, 0\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "    \n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = max_sum(torch.cat([xs_hat, xt_hat], dim=0).cpu().numpy())\n",
    "    if (O < 100):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - 100]   \n",
    "    \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "    \n",
    "    etajTX = etaj.T.dot(X)\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    uo = a[O].reshape(-1, 1)\n",
    "    vo = b[O].reshape(-1, 1)\n",
    "    print(uo, vo)\n",
    "    I = np.ones((X.shape[1],1))\n",
    "    sub_itv = [np.NINF, np.inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        if (i not in O):\n",
    "            ui = a[i].reshape(-1, 1)\n",
    "            vi = b[i].reshape(-1, 1)\n",
    "            u = uo - ui\n",
    "            v = vo - vi \n",
    "            u = I.T.dot(u)\n",
    "            v = I.T.dot(v)\n",
    "            print(-u, -v)\n",
    "            sub_itv = intersect(sub_itv, solve_linear_inequality(-u, -v))\n",
    "    print(sub_itv)\n",
    "    itv = intersect(itv, sub_itv)\n",
    "    print(itv)\n",
    "    print('------------------------')\n",
    "    cdf = truncated_cdf(etajTX[0][0], etajTmu[0][0], np.sqrt(etajTsigmaetaj[0][0]), itv[0], itv[1])\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.19335699]] [[0.]]\n",
      "[[2.78843105]] [[-0.]]\n",
      "error\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iteration):\n\u001b[1;32m----> 7\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[43mrun_basic_ad_si_oc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 60\u001b[0m, in \u001b[0;36mrun_basic_ad_si_oc\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m         v \u001b[38;5;241m=\u001b[39m I\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(v)\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m-\u001b[39mu, \u001b[38;5;241m-\u001b[39mv)\n\u001b[1;32m---> 60\u001b[0m         sub_itv \u001b[38;5;241m=\u001b[39m \u001b[43mintersect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_itv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve_linear_inequality\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(sub_itv)\n\u001b[0;32m     62\u001b[0m itv \u001b[38;5;241m=\u001b[39m intersect(itv, sub_itv)\n",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m, in \u001b[0;36mintersect\u001b[1;34m(itv1, itv2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintersect\u001b[39m(itv1, itv2):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# print(itv1, itv2)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     itv \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmax\u001b[39m(itv1[\u001b[38;5;241m0\u001b[39m], \u001b[43mitv2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m), \u001b[38;5;28mmin\u001b[39m(itv1[\u001b[38;5;241m1\u001b[39m], itv2[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m itv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m itv[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m    \n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "max_iteration = 1000\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "\n",
    "for i in range(max_iteration):\n",
    "    p_value = run_basic_ad_si_oc()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "print(f'FPR: {count / max_iteration}')\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
