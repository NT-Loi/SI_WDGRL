{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "def gen_data(mu, delta, n, d: int = 2):\n",
    "    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))\n",
    "    mu = np.full((n, d), mu, dtype=np.float64)\n",
    "\n",
    "    if delta == 0.0:\n",
    "        return mu + noise, np.zeros(n)\n",
    "    \n",
    "    # 10% of the data are abnormal\n",
    "    abnormal_idx = np.random.choice(n, int(n/10), replace=False)\n",
    "\n",
    "    mu[abnormal_idx, :] += delta\n",
    "\n",
    "    X = mu + noise \n",
    "    Y = np.zeros(n)\n",
    "    Y[abnormal_idx] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "torch.manual_seed(42)\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Feature extractor network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Domain critic network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class WDGRL():\n",
    "    def __init__(self, input_dim: int=2, generator_hidden_dims: List[int]=[32, 16, 8, 4, 2], critic_hidden_dims: List[int]=[32, 16, 8, 4, 2],\n",
    "                 gamma: float = 0.1, _lr_generator: float = 1e-2, _lr_critic: float = 1e-2, \n",
    "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu', random_seed: Optional[int] = 0):\n",
    "        if random_seed is not None:\n",
    "            torch.manual_seed(random_seed)\n",
    "            np.random.seed(random_seed)\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.generator = Generator(input_dim, generator_hidden_dims).to(self.device)\n",
    "        self.critic = Critic(generator_hidden_dims[-1], critic_hidden_dims).to(self.device)\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=_lr_generator)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=_lr_critic)\n",
    "    \n",
    "    def compute_gradient_penalty(self, source_data: torch.Tensor, target_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute gradient penalty.\"\"\"\n",
    "        if source_data.size(0) > target_data.size(0):\n",
    "            ms = source_data.size(0)\n",
    "            mt = target_data.size(0)\n",
    "            gradient_penalty = 0\n",
    "            for _ in range(0, ms, mt):\n",
    "                source_chunk = source_data[_:_+mt]\n",
    "                target_chunk = target_data\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            if ms % mt != 0:\n",
    "                source_chunk = source_data[ms-mt:]\n",
    "                perm = torch.randperm(mt)\n",
    "                idx = perm[:ms % mt]\n",
    "                target_chunk = target_data[idx]\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            return gradient_penalty / ((ms // mt) + (ms % mt != 0)) \n",
    "        \n",
    "        # For balanced batch\n",
    "        alpha = torch.rand(source_data.size(0), 1).to(self.device)\n",
    "        interpolates = (alpha * source_data + ((1 - alpha) * target_data)).requires_grad_(True)\n",
    "        \n",
    "        # Domain critic outputs\n",
    "        dc_output = self.critic(interpolates)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=dc_output,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        # Compute gradient penalty\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    def train(self, source_loader: DataLoader, target_loader: DataLoader, num_epochs: int = 100, dc_iter: int = 100) -> List[float]:\n",
    "        self.generator.train()\n",
    "        self.critic.train()\n",
    "        losses = []\n",
    "        source_critic_scores = []\n",
    "        target_critic_scores = []\n",
    "        for epoch in trange(num_epochs, desc='Epoch'):\n",
    "            loss = 0\n",
    "            for (source_data, _), (target_data, _) in zip(source_loader, target_loader):\n",
    "                source_data, target_data = source_data.to(self.device), target_data.to(self.device)\n",
    "\n",
    "                # Train domain critic\n",
    "                for _ in range(dc_iter):\n",
    "                    self.critic_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        source_features = self.generator(source_data)\n",
    "                        target_features = self.generator(target_data)\n",
    "                    \n",
    "                    # Compute empirical Wasserstein distance\n",
    "                    dc_source = self.critic(source_features)\n",
    "                    dc_target = self.critic(target_features)\n",
    "                    wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.compute_gradient_penalty(source_features, target_features)\n",
    "\n",
    "                    # Domain critic loss\n",
    "                    dc_loss = - wasserstein_distance + self.gamma * gradient_penalty\n",
    "                    dc_loss.backward()\n",
    "                    self.critic_optimizer.step()\n",
    "\n",
    "                # Train feature extractor\n",
    "                self.generator_optimizer.zero_grad()\n",
    "                source_features = self.generator(source_data)\n",
    "                target_features = self.generator(target_data)\n",
    "                dc_source = self.critic(source_features)\n",
    "                dc_target = self.critic(target_features)\n",
    "                wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "                wasserstein_distance.backward()\n",
    "                self.generator_optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    loss += wasserstein_distance.item()\n",
    "                    \n",
    "            source_critic_scores.append(self.criticize(source_loader.dataset.tensors[0].to(self.device)))\n",
    "            target_critic_scores.append(self.criticize(target_loader.dataset.tensors[0].to(self.device)))\n",
    "            losses.append(loss/len(source_loader))\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | Loss: {wasserstein_distance.item()}')\n",
    "        return losses, source_critic_scores, target_critic_scores\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_feature(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.generator.eval()\n",
    "        return self.generator(x)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def criticize(self, x: torch.Tensor) -> float:\n",
    "        self.generator.eval()\n",
    "        self.critic.eval()\n",
    "        return self.critic(self.generator(x)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the WDGRL model (same architecture as before)\n",
    "model = WDGRL(input_dim=1, generator_hidden_dims=[10, 10, 10], critic_hidden_dims=[10])\n",
    "\n",
    "# Load the saved checkpoint\n",
    "checkpoint = torch.load(\"wdgrl.pth\", map_location=model.device, weights_only=True)\n",
    "\n",
    "# Restore the model weights\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Create synthetic dataset and dataloaders for domain adaptation.\"\"\"\n",
    "# Create datasets\n",
    "ns, nt, d = 100, 10, 1\n",
    "mu_s, mu_t = 0, 20\n",
    "delta_s, delta_t = 4, 4\n",
    "xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "plt.scatter(xs[:, 0], np.zeros_like(xs[:, 0]), c=ys, cmap='viridis', s=2)\n",
    "plt.scatter(xt[:, 0], np.zeros_like(xt[:, 0]), c=yt, cmap='cool', s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4074, 0.0000, 0.0000, 0.0000, 0.0000, 0.3081, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4247, 0.0000, 0.0000, 0.0000, 0.0000, 0.3181, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4045, 0.0000, 0.0000, 0.0000, 0.0000, 0.3064, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4181, 0.0000, 0.0000, 0.0000, 0.0000, 0.3143, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4147, 0.0000, 0.0000, 0.0000, 0.0000, 0.3123, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4424, 0.0000, 0.0000, 0.0000, 0.0000, 0.3285, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4276, 0.0000, 0.0000, 0.0000, 0.0000, 0.3198, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4199, 0.0000, 0.0000, 0.0000, 0.0000, 0.3154, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4461, 0.0000, 0.0000, 0.0000, 0.0000, 0.3307, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.4449, 0.0000, 0.0000, 0.0000, 0.0000, 0.3299, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "xs = torch.FloatTensor(xs)\n",
    "ys = torch.LongTensor(ys)\n",
    "xt = torch.FloatTensor(xt)\n",
    "yt = torch.LongTensor(yt)\n",
    "xs_hat = model.extract_feature(xs.cuda())\n",
    "xt_hat = model.extract_feature(xt.cuda())\n",
    "print(xt_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "O = []\n",
    "alpha = 0.5\n",
    "for i in range(x_hat.shape[1]):\n",
    "    x_hat_i = x_hat[:, i]\n",
    "    median = x_hat_i.median().item()\n",
    "    mad = torch.abs(x_hat_i - median).median().item()\n",
    "    lower = median - alpha * mad\n",
    "    upper = median + alpha * mad\n",
    "    for j in range(nt):\n",
    "        value = xt_hat[j, i].item()\n",
    "        if (value < lower or value > upper) and j not in O:\n",
    "            O.append(j)\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "yt_hat = torch.zeros_like(yt)\n",
    "print(yt_hat)\n",
    "yt_hat[O] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.10      1.00      0.18         1\n",
      "\n",
      "    accuracy                           0.10        10\n",
      "   macro avg       0.05      0.50      0.09        10\n",
      "weighted avg       0.01      0.10      0.02        10\n",
      "\n",
      "Accuracy: 0.1000, Precision: 0.1000, Recall: 1.0000, F1-score: 0.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAG2CAYAAABbFn61AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAroklEQVR4nO3deXwUdZ7/8Xd1MJ1A0kGUKxACiATCqaAMXsCKYEYRxl1RJ64xCDvKDQMD/GYhIEJ0XBVRBhSVAILAqjCKBwsol3hwurhCNIgSkUsQcigJpOv3B6bHNijd6eqLej151GPsSn+/9XGG4cPn8/1WlWGapikAABBxHOEOAAAAnBtJGgCACEWSBgAgQpGkAQCIUCRpAAAiFEkaAIAIRZIGACBCkaQBAIhQJGkAACIUSRoAgAhFkgYAIEiKi4s1cuRIpaamKj4+Xtdcc422bNni83iSNAAAQTJw4ECtXr1aCxcu1K5du9SrVy/17NlTBw4c8Gm8wQs2AACw3o8//qjExET94x//0C233OI536lTJ2VkZOjhhx8+7xw1ghlgsLndbn377bdKTEyUYRjhDgcA4CfTNFVcXKzk5GQ5HMFr7p46dUrl5eUBz2OaZpV843Q65XQ6q3z3zJkzqqioUFxcnNf5+Ph4bdq0yecLRq3CwkJTEgcHBwdHlB+FhYVByxU//vijqRo1LYkzISGhyrmcnJxfvXbXrl3Nbt26mQcOHDDPnDljLly40HQ4HGbLli19ij2qK+nExERJUsG+QiW6XGGOBgiOJt3HhDsEIGjMinKVfzbf8+d5MJSXl0tnfpAzPUuKia3+RBXlKvlsvgoLC+X6Wc45VxVdaeHChRowYIAaNWqkmJgYXXnllbr77ru1bds2ny4Z1Um6suWQ6HJ5/RcGXEiMQP5QAaJESJYsa8QF9P8n0zjbjnf5kXMuu+wyrV+/XqWlpSoqKlLDhg115513qnnz5j6NZ3c3AMAeDEmGEcBR/UvXqlVLDRs21Pfff69Vq1apb9++Po2L6koaAACfGY6zRyDj/bRq1SqZpqm0tDQVFBRo7NixatWqlbKzs30aTyUNAECQnDx5UkOGDFGrVq1077336rrrrtOqVat00UUX+TSeShoAYA+VbetAxvupf//+6t+/f7UvSZIGANhDGNrdgaLdDQBAhKKSBgDYQxja3YEiSQMAbCLAdncYms+0uwEAiFBU0gAAe6DdDQBAhGJ3NwAAsAqVNADAHmh3AwAQoaKw3U2SBgDYQxRW0qxJAwAQoaikAQD2QLsbAIAIZRgBJmna3QAA4CdU0gAAe3AYZ49AxocYSRoAYA9RuCZNuxsAgAhFJQ0AsIcovE+aJA0AsAfa3QAAwCpU0gAAe6DdDQBAhIrCdjdJGgBgD1FYSbMmDQBAhKKSBgDYA+1uAAAiFO1uAABgFSppAIBNBNjuDkNdS5IGANgD7W4AACBJFRUVmjhxopo1a6b4+Hhddtllmjp1qkzT9HkOKmkAgD0YRoC7u/2rpB999FHNnj1b8+fPV5s2bbR161ZlZ2crKSlJw4cP92kOkjQAwB5CfAvW5s2b1bdvX91yyy2SpKZNm+rll1/Wxx9/7PMctLsBAPBDUVGR11FWVnbO711zzTVau3atPv/8c0nSJ598ok2bNikjI8Pna1FJAwDswaKNYykpKV6nc3JyNHny5CpfHz9+vIqKitSqVSvFxMSooqJC06ZNU2Zmps+XJEkDAOzBonZ3YWGhXC6X57TT6Tzn15ctW6ZFixZp8eLFatOmjXbu3KmRI0cqOTlZWVlZPl2SJA0AsAeLKmmXy+WVpH/N2LFjNX78eN11112SpHbt2unrr79Wbm6uz0maNWkAAILghx9+kMPhnWZjYmLkdrt9noNKGgBgDyHe3d2nTx9NmzZNTZo0UZs2bbRjxw498cQTGjBggM9zkKQBAPYQ4ieOPf3005o4caIGDx6sI0eOKDk5WX/60580adIkn+cgSQMAEASJiYmaMWOGZsyYUe05SNIAAFswDENGlD27myQNALCFaEzS7O4GACBCUUkDAOzB+OkIZHyIkaQBALZAuxsAAFiGShoAYAvRWEmTpAEAtkCSBgAgQkVjkmZNGgCACEUlDQCwB27BAgAgMtHuBgAAlqGSBgDYwtk3VQZSSVsXi69I0gAAWzAUYLs7DFmadjcAABGKShoAYAvRuHGMJA0AsIcovAWLdjcAABGKShoAYA8BtrtN2t0AAARHoGvSge0Mrx6SNADAFqIxSbMmDQBAhKKSBgDYQxTu7iZJAwBsgXY3AACwDJU0AMAWorGSJkkDAGwhGpM07W4AACIUlTQAwBaopAEAiFSGBYcfmjZt6vmLwc+PIUOG+DwHlTQAAEGwZcsWVVRUeD5/+umnuummm3THHXf4PAdJGgBgC6Fud9etW9fr8yOPPKLLLrtM3bp183kOkjQAwBasStJFRUVe551Op5xO52+OLS8v10svvaTRo0f7FQNr0gAAWzjX+rC/hySlpKQoKSnJc+Tm5p732itWrNCJEyd03333+RUzlTQAAH4oLCyUy+XyfD5fFS1JL7zwgjIyMpScnOzXtUjSAAB7sOgFGy6XyytJn8/XX3+tNWvW6LXXXvP7kiRpAIAthOs+6Xnz5qlevXq65ZZb/B7LmjQAAEHidrs1b948ZWVlqUYN/+tiKmn4bO6y9Xr6pbU6cqxIbS9vpEfH3qFObZqGOyzAEgk1nfp/D9yqW7t30KUXJ2jX599o/OOvaMdn+8MdGiwSjkp6zZo12r9/vwYMGFCta0ZEJT1r1iw1bdpUcXFx6tKliz7++ONwh4RfeO1/tuk/ZyzXuIEZWrdwnNpe3kj/OmyWjh4vDndogCWe+s8/qnuXVnogZ76uvXu63v1wj1bMGqaGdZPCHRosYijA3d3VWNDu1auXTNNUy5YtqxVz2JP00qVLNXr0aOXk5Gj79u3q0KGDevfurSNHjoQ7NPzM3xe/q3v7XaPM27qqVfOGemLCXaoZF6uXXv8g3KEBAYtzXqTbenTU5JkrtHnHXu375js9OvctfVl4VAP+9fpwhwcbC3uSfuKJJzRo0CBlZ2crPT1dc+bMUc2aNfXiiy+GOzT8pPz0Ge3cU6juV6d5zjkcDnW7Ok1bdu0LY2SANWrEOFSjRoxOlZ/2On+q7LR+1/GyMEUFq1l1n3QohTVJl5eXa9u2berZs6fnnMPhUM+ePfXBB1RokeLYiRJVVLhVt06i1/m6dVw6cqzoV0YB0aPkhzJ9/L9fauz9GWpwaZIcDkP9M67SVe2aqf6lvt9qgwgX4hdsWCGsSfq7775TRUWF6tev73W+fv36OnToUJXvl5WVqaioyOsAACv8adICGYa0++1pOvz+DP3Hnd306v9sldtthjs02FhU7e7Ozc3VlClTwh2G7VxSO0ExMY4qm8SOHi9SvUuoMnBh+OrAd7r1T0+pZlysEmvF6fCxIr0wPVtfH/gu3KHBIrxP2k+XXnqpYmJidPjwYa/zhw8fVoMGDap8f8KECTp58qTnKCwsDFWothZ7UQ11bJWi9VvyPefcbrc2bPlcV7VrFsbIAOv9cKpch48VKSkxXjf+rrXe2rAr3CHBItG4Jh3WSjo2NladOnXS2rVr1a9fP0ln//Bfu3athg4dWuX7vrxpBMEx+I//osFTFuqK1k10ZZummv3yeyr9sUyZfX4X7tAAS/zL71rLMKQvvj6i5o3r6qER/fT5V4e1iDsYLhiGcfYIZHyohb3dPXr0aGVlZalz5866+uqrNWPGDJWWlio7OzvcoeFnbu/VSd+dKNH0Z9/UkWPFateykV6ZOYR2Ny4YroQ4TRpym5Lr1db3RT/ojXd36uG/v6EzFe5whwYbC3uSvvPOO3X06FFNmjRJhw4dUseOHfXOO+9U2UyG8PuP/t30H/19f1k5EE1WrNmhFWt2hDsMBNHZSjqQNWkLg/FR2JO0JA0dOvSc7W0AACwTYLvbdrdgAQCAXxcRlTQAAMEWjbdgkaQBALYQjbu7aXcDABChqKQBALbgcBhyOKpfDpsBjK0ukjQAwBZodwMAAMtQSQMAbIHd3QAARKhobHeTpAEAthCNlTRr0gAARCgqaQCALURjJU2SBgDYQjSuSdPuBgAgQlFJAwBswVCA7e4wvKuSJA0AsAXa3QAAwDJU0gAAW2B3NwAAEYp2NwAAsAxJGgBgC5Xt7kAOfx04cED33HOPLrnkEsXHx6tdu3baunWrz+NpdwMAbCHU7e7vv/9e1157rXr06KG3335bdevW1RdffKGLL77Y5zlI0gAAWwj1xrFHH31UKSkpmjdvnudcs2bN/JqDdjcAAH4oKiryOsrKys75vddff12dO3fWHXfcoXr16umKK67Q3Llz/boWSRoAYA/GP1ve1TkqHziWkpKipKQkz5Gbm3vOy3355ZeaPXu2Lr/8cq1atUoPPvighg8frvnz5/scMu1uAIAtWNXuLiwslMvl8px3Op3n/L7b7Vbnzp01ffp0SdIVV1yhTz/9VHPmzFFWVpZP16SSBgDADy6Xy+v4tSTdsGFDpaene51r3bq19u/f7/O1qKQBALYQ6t3d1157rfLz873Off7550pNTfV5DpI0AMAWQr27e9SoUbrmmms0ffp09e/fXx9//LGee+45Pffccz7PQbsbAIAguOqqq7R8+XK9/PLLatu2raZOnaoZM2YoMzPT5zmopAEAthCOZ3ffeuutuvXWW6t9TZI0AMAWovEtWLS7AQCIUFTSAABbiMZKmiQNALCFaHyfNEkaAGAL0VhJsyYNAECEopIGANgC7W4AACIU7W4AAGAZKmkAgC0YCrDdbVkkviNJAwBswWEYcgSQpQMZW+1rhvyKAADAJ1TSAABbYHc3AAARKhp3d5OkAQC24DDOHoGMDzXWpAEAiFBU0gAAezACbFmzJg0AQHBE48Yx2t0AAEQoKmkAgC0YP/0KZHyokaQBALbA7m4AAGAZKmkAgC1csA8zef31132e8Lbbbqt2MAAABEs07u72KUn369fPp8kMw1BFRUUg8QAAgJ/4lKTdbnew4wAAIKii8VWVAa1Jnzp1SnFxcVbFAgBA0ERju9vv3d0VFRWaOnWqGjVqpISEBH355ZeSpIkTJ+qFF16wPEAAAKxQuXEskCPU/E7S06ZNU15env72t78pNjbWc75t27Z6/vnnLQ0OAAA78ztJL1iwQM8995wyMzMVExPjOd+hQwft2bPH0uAAALBKZbs7kCPU/E7SBw4cUIsWLaqcd7vdOn36tCVBAQBgtcqNY4Ec/pg8eXKVdnmrVq38msPvjWPp6enauHGjUlNTvc6/8soruuKKK/ydDgCAC1abNm20Zs0az+caNfxLu34n6UmTJikrK0sHDhyQ2+3Wa6+9pvz8fC1YsEArV670dzoAAELCUGCvhK7O2Bo1aqhBgwbVvqbf7e6+ffvqjTfe0Jo1a1SrVi1NmjRJu3fv1htvvKGbbrqp2oEAABBMVu3uLioq8jrKysp+9ZpffPGFkpOT1bx5c2VmZmr//v1+xVyt+6Svv/56rV69ujpDAQCIaikpKV6fc3JyNHny5Crf69Kli/Ly8pSWlqaDBw9qypQpuv766/Xpp58qMTHRp2tV+2EmW7du1e7duyWdXafu1KlTdacCACDorHpVZWFhoVwul+e80+k85/czMjI8/9y+fXt16dJFqampWrZsme6//36frul3kv7mm29099136/3331ft2rUlSSdOnNA111yjJUuWqHHjxv5OCQBA0Fn1FiyXy+WVpH1Vu3ZttWzZUgUFBT6P8XtNeuDAgTp9+rR2796t48eP6/jx49q9e7fcbrcGDhzo73QAANhCSUmJ9u7dq4YNG/o8xu9Kev369dq8ebPS0tI859LS0vT000/r+uuv93c6AABCJpQPJBkzZoz69Omj1NRUffvtt8rJyVFMTIzuvvtun+fwO0mnpKSc86ElFRUVSk5O9nc6AABCwqp2t68ql4ePHTumunXr6rrrrtOHH36ounXr+jyH30n6scce07BhwzRr1ix17txZ0tlNZCNGjNB//dd/+TsdAAAhYdXGMV8tWbKk+hf7iU9J+uKLL/b6G0Rpaam6dOnieXLKmTNnVKNGDQ0YMED9+vULOCgAAOBjkp4xY0aQwwAAILhC3e62gk9JOisrK9hxAAAQVOF4LGigqv0wE0k6deqUysvLvc5V594xAABQld9JurS0VOPGjdOyZct07NixKj+vqKiwJDAAAKxUnddN/nJ8qPn9MJO//OUvevfddzV79mw5nU49//zzmjJlipKTk7VgwYJgxAgAQMAMI/Aj1PyupN944w0tWLBA3bt3V3Z2tq6//nq1aNFCqampWrRokTIzM4MRJwAAtuN3JX38+HE1b95c0tn15+PHj0uSrrvuOm3YsMHa6AAAsIhVr6oMJb+TdPPmzbVv3z5JUqtWrbRs2TJJZyvsyhduAAAQaaKx3e13ks7OztYnn3wiSRo/frxmzZqluLg4jRo1SmPHjrU8QAAA7MrvNelRo0Z5/rlnz57as2ePtm3bphYtWqh9+/aWBgcAgFWicXd3QPdJS1JqaqpSU1OtiAUAgKAJtGUdsbu7Z86c6fOEw4cPr3YwAAAEywX7WNAnn3zSp8kMwyBJAwBgEZ+SdOVubgChl7+GV8DiwlVcXKS2zeaG5FoOVWO39C/Gh1rAa9IAAESDaGx3h+MvBgAAwAdU0gAAWzAMyXEh7u4GACDaOQJM0oGMrfY1Q39JAADgi2ol6Y0bN+qee+5R165ddeDAAUnSwoULtWnTJkuDAwDAKrZ4wcarr76q3r17Kz4+Xjt27FBZWZkk6eTJk5o+fbrlAQIAYIXKdncgR8hj9nfAww8/rDlz5mju3Lm66KKLPOevvfZabd++3dLgAACwM783juXn5+uGG26ocj4pKUknTpywIiYAACwXjc/u9ruSbtCggQoKCqqc37Rpk5o3b25JUAAAWK3yLViBHCGP2d8BgwYN0ogRI/TRRx/JMAx9++23WrRokcaMGaMHH3wwGDECABAwhwVHqPnd7h4/frzcbrduvPFG/fDDD7rhhhvkdDo1ZswYDRs2LBgxAgBgS34nacMw9Ne//lVjx45VQUGBSkpKlJ6eroSEhGDEBwCAJaJxTbraTxyLjY1Venq6lbEAABA0DgW2ruxQhL5P+ud69Ojxmzd0v/vuuwEFBAAAzvJ7Hbxjx47q0KGD50hPT1d5ebm2b9+udu3aBSNGAAACVtnuDuSorkceeUSGYWjkyJF+jfO7kn7yySfPeX7y5MkqKSnxdzoAAEIiXC/Y2LJli5599lm1b9/e/2tW75JV3XPPPXrxxRetmg4AgKhXUlKizMxMzZ07VxdffLHf4y1L0h988IHi4uKsmg4AAEudfZ909R9kUtnuLioq8joq32FxLkOGDNEtt9yinj17Vitmv9vdt99+u9dn0zR18OBBbd26VRMnTqxWEAAABJtVt2ClpKR4nc/JydHkyZOrfH/JkiXavn27tmzZUu1r+p2kk5KSvD47HA6lpaXpoYceUq9evaodCAAA0aCwsFAul8vz2el0nvM7I0aM0OrVqwPqMvuVpCsqKpSdna127dpVq7cOAEC4WLVxzOVyeSXpc9m2bZuOHDmiK6+80nOuoqJCGzZs0DPPPKOysjLFxMSc95p+JemYmBj16tVLu3fvJkkDAKKK8dOvQMb76sYbb9SuXbu8zmVnZ6tVq1YaN26cTwlaqka7u23btvryyy/VrFkzf4cCABA2obwFKzExUW3btvU6V6tWLV1yySVVzv/mNX2/5FkPP/ywxowZo5UrV+rgwYNVdrkBAABr+FxJP/TQQ/rzn/+s3//+95Kk2267zevxoKZpyjAMVVRUWB8lAAABCtfDTCqtW7fO7zE+J+kpU6bogQce0Hvvvef3RQAACDfDMH7z3RO+jA81n5O0aZqSpG7dugUtGAAA8E9+bRwLx98iAACwQrjb3dXhV5Ju2bLleRP18ePHAwoIAIBgsOqJY6HkV5KeMmVKlSeOAQCA4PArSd91112qV69esGIBACBoKl+UEcj4UPM5SbMeDQCIZtG4Ju3zw0wqd3cDAIDQ8LmSdrvdwYwDAIDgCnDjWACP/a42v5/dDQBANHLIkCOATBvI2OoiSQMAbCEab8Hy+wUbAAAgNKikAQC2EI27u0nSAABbiMb7pGl3AwAQoaikAQC2EI0bx0jSAABbcCjAdncYbsGi3Q0AQISikgYA2ALtbgAAIpRDgbWPw9F6pt0NAECEopIGANiCYRgBvXY5HK9sJkkDAGzBUGAvsgrDkjRJGgBgDzxxDAAAWIZKGgBgG+FoWQeCJA0AsIVovE+adjcAABGKShoAYAvcggUAQITiiWMAAECSNHv2bLVv314ul0sul0tdu3bV22+/7dccVNIAAFsIdbu7cePGeuSRR3T55ZfLNE3Nnz9fffv21Y4dO9SmTRuf5iBJAwBsIdRPHOvTp4/X52nTpmn27Nn68MMPSdIAAESKiooK/fd//7dKS0vVtWtXn8eRpAEAtmBVu7uoqMjrvNPplNPpPOeYXbt2qWvXrjp16pQSEhK0fPlypaen+3xNNo4BAGzBYcEhSSkpKUpKSvIcubm5v3rNtLQ07dy5Ux999JEefPBBZWVl6bPPPvM5ZippAIAtWFVJFxYWyuVyec7/WhUtSbGxsWrRooUkqVOnTtqyZYueeuopPfvssz5dkyQNAIAfKm+pqg63262ysjKfv0+SBgDYQqh3d0+YMEEZGRlq0qSJiouLtXjxYq1bt06rVq3yeQ6SNADAFkL9go0jR47o3nvv1cGDB5WUlKT27dtr1apVuummm3yegyQNAEAQvPDCCwHPQZIGANiCQ4YcATS8AxlbXSRpAIAt8D5pAABgGSppAIAtGD/9CmR8qJGkAQC2QLsbAABYhkoaAGALRoC7u2l3AwAQJNHY7iZJAwBsIRqTNGvSAABEKCppAIAtcAsWAAARymGcPQIZH2q0uwEAiFBU0gAAW6DdDQBAhGJ3NwAAsAyVNADAFgwF1rIOQyFNkgYA2AO7uwEAgGWopOGzucvW6+mX1urIsSK1vbyRHh17hzq1aRrusICAbfnfvXph2Tp9+sUBHT1WpFlT7lPPa9uGOyxYLBp3d4e1kt6wYYP69Omj5ORkGYahFStWhDMc/IbX/meb/nPGco0bmKF1C8ep7eWN9K/DZuno8eJwhwYE7IdT5UprnqycYX8IdygIosrd3YEcoRbWJF1aWqoOHTpo1qxZ4QwDPvj74nd1b79rlHlbV7Vq3lBPTLhLNeNi9dLrH4Q7NCBg3a5urVEDMnTTde3CHQqCyLDgCLWwtrszMjKUkZERzhDgg/LTZ7RzT6FG3dfLc87hcKjb1WnasmtfGCMDgAtbVK1Jl5WVqayszPO5qKgojNHYx7ETJaqocKtunUSv83XruPTFV4fDFBUA+MchQ44AetYOu61J+ys3N1dJSUmeIyUlJdwhAQCiRDS2u6MqSU+YMEEnT570HIWFheEOyRYuqZ2gmBhHlU1iR48Xqd4lrjBFBQAXvqhK0k6nUy6Xy+tA8MVeVEMdW6Vo/ZZ8zzm3260NWz7XVe2ahTEyAPBDFJbSUbUmjfAZ/Md/0eApC3VF6ya6sk1TzX75PZX+WKbMPr8Ld2hAwEp/LNP+A995Pn9z8Lh2FxxQUmJNJde/OIyRwUrReJ90WJN0SUmJCgoKPJ/37dunnTt3qk6dOmrSpEkYI8Mv3d6rk747UaLpz76pI8eK1a5lI70ycwjtblwQPs0v1L1j5ng+5855XZL0h16d9chf7gpXWIAM0zTNcF183bp16tGjR5XzWVlZysvLO+/4oqIiJSUl6fCxk7S+ccE6cvJUuEMAgqa4uEhtm9XXyZPB+3O8Mles3blfCYnVv0ZJcZFu7NgkqLH+UljXpLt37y7TNKscviRoAAD8Eeol6dzcXF111VVKTExUvXr11K9fP+Xn559/4M9E1cYxAACixfr16zVkyBB9+OGHWr16tU6fPq1evXqptLTU5znYOAYAsIdAd2j7Ofadd97x+pyXl6d69epp27ZtuuGGG3yagyQNALCFcO/uPnnypCSpTp06Po8hSQMAbCHQN1lVjv3lI6mdTqecTudvjnW73Ro5cqSuvfZatW3r+2tQWZMGAMAPKSkpXo+ozs3NPe+YIUOG6NNPP9WSJUv8uhaVNADAFqxaki4sLPS6Bet8VfTQoUO1cuVKbdiwQY0bN/brmiRpAIA9WJSlfX0stWmaGjZsmJYvX65169apWTP/H6NMkgYAIAiGDBmixYsX6x//+IcSExN16NAhSVJSUpLi4+N9moM1aQCALRgW/PLH7NmzdfLkSXXv3l0NGzb0HEuXLvV5DippAIAtWLW721dWPHWbShoAgAhFJQ0AsIUQP3DMEiRpAIA9RGGWpt0NAECEopIGANhCuJ/dXR0kaQCALYR6d7cVSNIAAFuIwiVp1qQBAIhUVNIAAHuIwlKaJA0AsIVo3DhGuxsAgAhFJQ0AsAV2dwMAEKGicEmadjcAAJGKShoAYA9RWEqTpAEAtsDubgAAYBkqaQCALbC7GwCACBWFS9IkaQCATURhlmZNGgCACEUlDQCwhWjc3U2SBgDYQ4Abx2h3AwAADyppAIAtROG+MZI0AMAmojBL0+4GACBCUUkDAGyB3d0AAESoaHwsKO1uAAAiFJU0AMAWonDfGJU0AMAmDAsOP2zYsEF9+vRRcnKyDMPQihUr/A6ZJA0AsAXDgl/+KC0tVYcOHTRr1qxqx0y7GwCAIMjIyFBGRkZAc5CkAQC2YCjA3d0//WdRUZHXeafTKafTWf2JfwPtbgCALVi1JJ2SkqKkpCTPkZubG7SYqaQBAPBDYWGhXC6X53OwqmiJJA0AsAmrHmbicrm8knQwkaQBADYRfXdKk6QBAAiCkpISFRQUeD7v27dPO3fuVJ06ddSkSROf5iBJAwBsIdTP7t66dat69Ojh+Tx69GhJUlZWlvLy8nyagyQNALCFUDe7u3fvLtM0A7git2ABABCxqKQBALYQja+qJEkDAGyhOs/f/uX4UCNJAwDsIfruwGJNGgCASEUlDQCwhSgspEnSAAB7iMaNY7S7AQCIUFTSAABbYHc3AACRKgoXpWl3AwAQoaikAQC2EIWFNEkaAGAP7O4GAACWoZIGANhEYLu7w9HwJkkDAGyBdjcAALAMSRoAgAhFuxsAYAvR2O4mSQMAbCEaHwtKuxsAgAhFJQ0AsAXa3QAARKhofCwo7W4AACIUlTQAwB6isJQmSQMAbIHd3QAAwDJU0gAAW2B3NwAAESoKl6RJ0gAAm4jCLM2aNAAAQTRr1iw1bdpUcXFx6tKliz7++GOfx5KkAQC2YFjwy19Lly7V6NGjlZOTo+3bt6tDhw7q3bu3jhw54tN4kjQAwBYqN44FcvjriSee0KBBg5Sdna309HTNmTNHNWvW1IsvvujT+KhekzZNU5JUXFQU5kiA4CkuPhXuEICgKSkulvTPP8+DqSjAXFE5/pfzOJ1OOZ3OKt8vLy/Xtm3bNGHCBM85h8Ohnj176oMPPvDpmlGdpIt/+h+3RbOUMEcCAAhEcXGxkpKSgjJ3bGysGjRooMstyBUJCQlKSfGeJycnR5MnT67y3e+++04VFRWqX7++1/n69etrz549Pl0vqpN0cnKyCgsLlZiYKCMcN7DZUFFRkVJSUlRYWCiXyxXucABL8fs79EzTVHFxsZKTk4N2jbi4OO3bt0/l5eUBz2WaZpV8c64q2ipRnaQdDocaN24c7jBsyeVy8YcYLlj8/g6tYFXQPxcXF6e4uLigX+fnLr30UsXExOjw4cNe5w8fPqwGDRr4NAcbxwAACILY2Fh16tRJa9eu9Zxzu91au3atunbt6tMcUV1JAwAQyUaPHq2srCx17txZV199tWbMmKHS0lJlZ2f7NJ4kDb84nU7l5OQEdQ0GCBd+f8Nqd955p44ePapJkybp0KFD6tixo955550qm8l+jWGGYt87AADwG2vSAABEKJI0AAARiiQNAECEIkkDABChSNLwWSCvWwMi2YYNG9SnTx8lJyfLMAytWLEi3CEBkkjS8FGgr1sDIllpaak6dOigWbNmhTsUwAu3YMEnXbp00VVXXaVnnnlG0tmn5qSkpGjYsGEaP358mKMDrGMYhpYvX65+/fqFOxSAShrnV/m6tZ49e3rO+fu6NQCA/0jSOK/fet3aoUOHwhQVAFz4SNIAAEQokjTOy4rXrQEA/EeSxnlZ8bo1AID/eAsWfBLo69aASFZSUqKCggLP53379mnnzp2qU6eOmjRpEsbIYHfcggWfPfPMM3rsscc8r1ubOXOmunTpEu6wgICtW7dOPXr0qHI+KytLeXl5oQ8I+AlJGgCACMWaNAAAEYokDQBAhCJJAwAQoUjSAABEKJI0AAARiiQNAECEIkkDABChSNJAgO677z6vdw93795dI0eODHkc69atk2EYOnHixK9+xzAMrVixwuc5J0+erI4dOwYU11dffSXDMLRz586A5gHsiCSNC9J9990nwzBkGIZiY2PVokULPfTQQzpz5kzQr/3aa69p6tSpPn3Xl8QKwL54djcuWDfffLPmzZunsrIyvfXWWxoyZIguuugiTZgwocp3y8vLFRsba8l169SpY8k8AEAljQuW0+lUgwYNlJqaqgcffFA9e/bU66+/LumfLepp06YpOTlZaWlpkqTCwkL1799ftWvXVp06ddS3b1999dVXnjkrKio0evRo1a5dW5dccon+8pe/6JdP1v1lu7usrEzjxo1TSkqKnE6nWrRooRdeeEFfffWV53nRF198sQzD0H333Sfp7FvGcnNz1axZM8XHx6tDhw565ZVXvK7z1ltvqWXLloqPj1ePHj284vTVuHHj1LJlS9WsWVPNmzfXxIkTdfr06Srfe/bZZ5WSkqKaNWuqf//+OnnypNfPn3/+ebVu3VpxcXFq1aqV/v73v/sdC4CqSNKwjfj4eJWXl3s+r127Vvn5+Vq9erVWrlyp06dPq3fv3kpMTNTGjRv1/vvvKyEhQTfffLNn3OOPP668vDy9+OKL2rRpk44fP67ly5f/5nXvvfdevfzyy5o5c6Z2796tZ599VgkJCUpJSdGrr74qScrPz9fBgwf11FNPSZJyc3O1YMECzZkzR//3f/+nUaNG6Z577tH69eslnf3LxO23364+ffpo586dGjhwoMaPH+/3fyeJiYnKy8vTZ599pqeeekpz587Vk08+6fWdgoICLVu2TG+88Ybeeecd7dixQ4MHD/b8fNGiRZo0aZKmTZum3bt3a/r06Zo4caLmz5/vdzwAfsEELkBZWVlm3759TdM0Tbfbba5evdp0Op3mmDFjPD+vX7++WVZW5hmzcOFCMy0tzXS73Z5zZWVlZnx8vLlq1SrTNE2zYcOG5t/+9jfPz0+fPm02btzYcy3TNM1u3bqZI0aMME3TNPPz801J5urVq88Z53vvvWdKMr///nvPuVOnTpk1a9Y0N2/e7PXd+++/37z77rtN0zTNCRMmmOnp6V4/HzduXJW5fkmSuXz58l/9+WOPPWZ26tTJ8zknJ8eMiYkxv/nmG8+5t99+23Q4HObBgwdN0zTNyy67zFy8eLHXPFOnTjW7du1qmqZp7tu3z5Rk7tix41evC+DcWJPGBWvlypVKSEjQ6dOn5Xa79cc//lGTJ0/2/Lxdu3Ze69CffPKJCgoKlJiY6DXPqVOntHfvXp08eVIHDx70ej1njRo11Llz5yot70o7d+5UTEyMunXr5nPcBQUF+uGHH3TTTTd5nS8vL9cVV1whSdq9e3eV14R27drV52tUWrp0qWbOnKm9e/eqpKREZ86ckcvl8vpOkyZN1KhRI6/ruN1u5efnKzExUXv37tX999+vQYMGeb5z5swZJSUl+R0PAG8kaVywevToodmzZys2NlbJycmqUcP7t3utWrW8PpeUlKhTp05atGhRlbnq1q1brRji4+P9HlNSUiJJevPNN72So3R2nd0qH3zwgTIzMzVlyhT17t1bSUlJWrJkiR5//HG/Y507d26VvzTExMRYFitgVyRpXLBq1aqlFi1a+Pz9K6+8UkuXLlW9evWqVJOVGjZsqI8++kg33HCDpLMV47Zt23TllVee8/vt2rWT2+3W+vXr1bNnzyo/r6zkKyoqPOfS09PldDq1f//+X63AW7du7dkEV+nDDz88/7/kz2zevFmpqan661//6jn39ddfV/ne/v379e233yo5OdlzHYfDobS0NNWvX1/Jycn68ssvlZmZ6df1AZwfG8eAn2RmZurSSy9V3759tXHjRu3bt0/r1q3T8OHD9c0330iSRowYoUceeUQrVqzQnj17NHjw4N+8x7lp06bKysrSgAEDtGLFCs+cy5YtkySlpqbKMAytXLlSR48eVUlJiRITEzVmzBiNGjVK8+fP1969e7V9+3Y9/fTTns1YDzzwgL744guNHTtW+fn5Wrx4sfLy8vz697388su1f/9+LVmyRHv37tXMmTPPuQkuLi5OWVlZ+uSTT7Rx40YNHz5c/fv3V4MGDSRJU6ZMUW5urmbOnKnPP/9cu3bt0rx58/TEE0/4FQ+AqkjSwE9q1qypDRs2qEmTJrr99tvVunVr3X///Tp16pSnsv7zn/+sf//3f1dWVpa6du2qxMRE/eEPf/jNeWfPnq1/+7d/0+DBg9WqVSsNGjRIpaWlkqRGjRppypQpGj9+vOrXr6+hQ4dKkqZOnaqJEycqNzdXrVu31s0336w333xTzZo1k3R2nfjVV1/VihUr1KFDB82ZM0fTp0/369/3tttu06hRozR06FB17NhRmzdv1sSJE6t8r0WLFrr99tv1+9//Xr169VL79u29brEaOHCgnn/+ec2bN0/t2rVTt27dlJeX54kVQPUZ5q/teAEAAGFFJQ0AQIQiSQMAEKFI0gAARCiSNAAAEYokDQBAhCJJAwAQoUjSAABEKJI0AAARiiQNAECEIkkDABChSNIAAEQokjQAABHq/wN1014MLmUs4AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(yt, yt_hat)\n",
    "precision = precision_score(yt, yt_hat)\n",
    "recall = recall_score(yt, yt_hat)\n",
    "f1 = f1_score(yt, yt_hat)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(yt, yt_hat))\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(yt, yt_hat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4507497955894369"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mpmath import mp\n",
    "mp.dps = 500\n",
    "\n",
    "Oc = list(torch.where(yt == 0)[0])\n",
    "j = np.random.choice(O, 1, replace=False)[0]\n",
    "etj = np.zeros((nt, 1))\n",
    "etj[j][0] = 1\n",
    "etOc = np.zeros((nt, 1))\n",
    "etOc[Oc] = 1\n",
    "etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "\n",
    "etajTX = etaj.T.dot(X)\n",
    "mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "sigma = np.identity(ns+nt)\n",
    "etajTmu = etaj.T.dot(mu)\n",
    "etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "cdf = mp.ncdf((etajTX[0][0] - etajTmu[0][0]) / np.sqrt(etajTsigmaetaj[0][0]))\n",
    "p_value = float(2 * min(cdf, 1 - cdf))\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive $p$-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naive():\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = 4, 0\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "    \n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "    \n",
    "    O = []\n",
    "    alpha = 0.5\n",
    "    for i in range(x_hat.shape[1]):\n",
    "        x_hat_i = x_hat[:, i]\n",
    "        median = x_hat_i.median().item()\n",
    "        mad = torch.abs(x_hat_i - median).median().item()\n",
    "        lower = median - alpha * mad\n",
    "        upper = median + alpha * mad\n",
    "        for j in range(nt):\n",
    "            value = xt_hat[j, i].item()\n",
    "            if (value < lower or value > upper) and j not in O:\n",
    "                O.append(j)\n",
    "    \n",
    "    if len(O) == 0:\n",
    "        return None\n",
    "    \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    j = np.random.choice(O, 1, replace=False)[0]\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "    X = np.vstack((xs.numpy(), xt.numpy()))\n",
    "\n",
    "    etajTX = etaj.T.dot(X)\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    cdf = mp.ncdf((etajTX[0][0] - etajTmu[0][0]) / np.sqrt(etajTsigmaetaj[0][0]))\n",
    "    p_value = float(2 * min(cdf, 1 - cdf))\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iteration = 4000\n",
    "# alpha = 0.05\n",
    "# list_p_value = []\n",
    "# count = 0\n",
    "\n",
    "# for i in range(max_iteration):\n",
    "#     p_value = run_naive()\n",
    "#     if p_value is None:\n",
    "#         continue\n",
    "#     list_p_value.append(p_value)\n",
    "#     if p_value <= alpha:\n",
    "#         count += 1\n",
    "# print(f'FPR: {count / max_iteration}')\n",
    "# plt.hist(list_p_value)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405239e+00]\n",
      " [ 4.00157213e-01]\n",
      " [ 9.78738010e-01]\n",
      " [ 2.24089313e+00]\n",
      " [ 1.86755800e+00]\n",
      " [-9.77277875e-01]\n",
      " [ 4.95008850e+00]\n",
      " [-1.51357204e-01]\n",
      " [-1.03218853e-01]\n",
      " [ 4.10598516e-01]\n",
      " [ 1.44043565e-01]\n",
      " [ 1.45427346e+00]\n",
      " [ 7.61037707e-01]\n",
      " [ 1.21675014e-01]\n",
      " [ 4.43863243e-01]\n",
      " [ 3.33674341e-01]\n",
      " [ 1.49407911e+00]\n",
      " [-2.05158263e-01]\n",
      " [ 3.13067704e-01]\n",
      " [ 3.14590430e+00]\n",
      " [-2.55298972e+00]\n",
      " [ 6.53618574e-01]\n",
      " [ 4.86443615e+00]\n",
      " [-7.42165029e-01]\n",
      " [ 2.26975465e+00]\n",
      " [ 2.54563427e+00]\n",
      " [ 4.57585156e-02]\n",
      " [-1.87183857e-01]\n",
      " [ 1.53277922e+00]\n",
      " [ 1.46935880e+00]\n",
      " [ 4.15494728e+00]\n",
      " [ 3.78162533e-01]\n",
      " [-8.87785733e-01]\n",
      " [-1.98079646e+00]\n",
      " [-3.47912163e-01]\n",
      " [ 1.56348974e-01]\n",
      " [ 1.23029065e+00]\n",
      " [ 1.20237982e+00]\n",
      " [-3.87326807e-01]\n",
      " [-3.02302748e-01]\n",
      " [-1.04855299e+00]\n",
      " [-1.42001796e+00]\n",
      " [-1.70627022e+00]\n",
      " [ 1.95077538e+00]\n",
      " [-5.09652197e-01]\n",
      " [ 3.56192565e+00]\n",
      " [-1.25279534e+00]\n",
      " [ 7.77490377e-01]\n",
      " [ 2.38610220e+00]\n",
      " [-2.12740287e-01]\n",
      " [-8.95466566e-01]\n",
      " [ 3.86902511e-01]\n",
      " [-5.10805130e-01]\n",
      " [-1.18063223e+00]\n",
      " [-2.81822290e-02]\n",
      " [ 4.28331882e-01]\n",
      " [ 6.65172189e-02]\n",
      " [ 4.30247211e+00]\n",
      " [-6.34322107e-01]\n",
      " [ 3.63725877e+00]\n",
      " [-6.72460437e-01]\n",
      " [-3.59553158e-01]\n",
      " [-8.13146293e-01]\n",
      " [-1.72628260e+00]\n",
      " [ 1.77426144e-01]\n",
      " [-4.01780933e-01]\n",
      " [-1.63019836e+00]\n",
      " [ 4.62782264e-01]\n",
      " [-9.07298386e-01]\n",
      " [ 5.19453958e-02]\n",
      " [ 7.29090571e-01]\n",
      " [ 1.28982916e-01]\n",
      " [ 1.13940072e+00]\n",
      " [ 2.76517415e+00]\n",
      " [ 4.02341634e-01]\n",
      " [-6.84810102e-01]\n",
      " [-8.70797157e-01]\n",
      " [-5.78849673e-01]\n",
      " [-3.11552525e-01]\n",
      " [ 5.61653413e-02]\n",
      " [-1.16514981e+00]\n",
      " [ 9.00826514e-01]\n",
      " [ 4.65662450e-01]\n",
      " [-1.53624368e+00]\n",
      " [ 1.48825216e+00]\n",
      " [ 1.89588916e+00]\n",
      " [ 1.17877960e+00]\n",
      " [-1.79924831e-01]\n",
      " [-1.07075262e+00]\n",
      " [ 1.05445170e+00]\n",
      " [-4.03176934e-01]\n",
      " [ 1.22244501e+00]\n",
      " [ 2.08274975e-01]\n",
      " [ 9.76639032e-01]\n",
      " [ 3.56366396e-01]\n",
      " [ 7.06573188e-01]\n",
      " [ 1.05000203e-02]\n",
      " [ 1.78587055e+00]\n",
      " [ 1.26912087e-01]\n",
      " [ 4.01989371e-01]\n",
      " [ 1.83550962e+01]\n",
      " [ 1.98566564e+01]\n",
      " [ 1.80998414e+01]\n",
      " [ 1.92799447e+01]\n",
      " [ 1.97828744e+01]\n",
      " [ 2.14018434e+01]\n",
      " [ 2.01066202e+01]\n",
      " [ 1.94395173e+01]\n",
      " [ 2.17234758e+01]\n",
      " [ 2.17058620e+01]]\n",
      "[[ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [-0.125]\n",
      " [-0.125]\n",
      " [-0.125]\n",
      " [-0.125]\n",
      " [ 1.   ]\n",
      " [-0.125]\n",
      " [-0.125]\n",
      " [-0.125]\n",
      " [-0.125]\n",
      " [ 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(itv1, itv2):\n",
    "    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]\n",
    "    if itv[0] > itv[1]:\n",
    "        return None    \n",
    "    return itv\n",
    "\n",
    "def solve_linear_inequality(u, v): #u + vz < 0\n",
    "    if (v == 0):\n",
    "        return None \n",
    "    if (v < 0):\n",
    "        return [-u/v, np.Inf]\n",
    "    return [np.NINF, -u/v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-inf, array([155.18176574])]\n",
      "[-inf, array([169.89659569])]\n",
      "[-inf, array([147.74989398])]\n",
      "[-inf, array([129.52692562])]\n",
      "[-inf, array([141.87503409])]\n",
      "[-inf, array([160.98072945])]\n",
      "[-inf, array([154.47534601])]\n",
      "[-inf, array([131.62256994])]\n",
      "[-inf, array([153.28632049])]\n",
      "[-inf, array([142.26424118])]\n",
      "[-inf, array([179.26675822])]\n",
      "[-inf, array([150.21505981])]\n",
      "[-inf, array([126.53529541])]\n",
      "[-inf, array([148.17195633])]\n",
      "[-inf, array([94.78127481])]\n",
      "[-inf, array([134.26444214])]\n",
      "[-inf, array([190.80069421])]\n",
      "[-inf, array([158.24484049])]\n",
      "[-inf, array([145.0214267])]\n",
      "[-inf, array([188.35640384])]\n",
      "[-inf, array([282.92799866])]\n",
      "[-inf, array([240.13060292])]\n",
      "[-inf, array([159.32448172])]\n",
      "[array([-4347.62801403]), inf]\n",
      "[-inf, array([229.44748718])]\n",
      "[-inf, array([367.18849609])]\n",
      "[-inf, array([225.9495387])]\n",
      "[-inf, array([133.07482738])]\n",
      "[-inf, array([150.91069523])]\n",
      "[-inf, array([368.17941314])]\n",
      "[array([-4347.62801403]), array([94.78127481])]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def get_interval(Xtj, a, b):\n",
    "    layers = []\n",
    "\n",
    "    for name, param in model.generator.named_children():\n",
    "        temp = dict(param._modules)\n",
    "        \n",
    "        for layer_name in temp.values():\n",
    "            if ('Linear' in str(layer_name)):\n",
    "                layers.append('Linear')\n",
    "            elif ('ReLU' in str(layer_name)):\n",
    "                layers.append('ReLU')\n",
    "\n",
    "    ptr = 0\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    u = a\n",
    "    v = b\n",
    "    temp = Xtj\n",
    "    weight = None\n",
    "    bias = None\n",
    "    for name, param in model.generator.named_parameters():\n",
    "        if (layers[ptr] == 'Linear'):\n",
    "            if ('weight' in name):\n",
    "                weight = param.data.cpu().detach().numpy()\n",
    "            elif ('bias' in name):\n",
    "                bias = param.data.cpu().detach().numpy().reshape(-1, 1)\n",
    "                ptr += 1\n",
    "                temp = weight.dot(temp) + bias\n",
    "                u = weight.dot(u) + bias\n",
    "                v = weight.dot(v)\n",
    "\n",
    "        if (ptr < len(layers) and layers[ptr] == 'ReLU'):\n",
    "            ptr += 1\n",
    "            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))\n",
    "            sub_itv = [np.NINF, np.inf]\n",
    "            for i in range(temp.shape[0]):\n",
    "                if temp[i] > 0:\n",
    "                    Relu_matrix[i][i] = 1\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i], -v[i]))\n",
    "                    print(solve_linear_inequality(-u[i], -v[i]))\n",
    "                else:\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i], v[i]))\n",
    "                    print(solve_linear_inequality(u[i], v[i]))\n",
    "            itv = intersect(itv, sub_itv)\n",
    "            temp = Relu_matrix.dot(temp)\n",
    "            u = Relu_matrix.dot(u)\n",
    "            v = Relu_matrix.dot(v)\n",
    "\n",
    "    if (ptr < len(layers)):\n",
    "        if (layers[ptr] == 'ReLU'):\n",
    "            ptr += 1\n",
    "            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))\n",
    "            sub_itv = [np.NINF, np.inf]\n",
    "            for i in range(temp.shape[0]):\n",
    "                if temp[i] > 0:\n",
    "                    Relu_matrix[i][i] = 1\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i], -v[i]))\n",
    "                    print(solve_linear_inequality(-u[i], -v[i]))\n",
    "                else:\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i], v[i]))\n",
    "                    print(solve_linear_inequality(u[i], v[i]))\n",
    "            itv = intersect(itv, sub_itv)\n",
    "            temp = Relu_matrix.dot(temp)\n",
    "            u = Relu_matrix.dot(u)\n",
    "            v = Relu_matrix.dot(v)\n",
    "\n",
    "    return itv\n",
    "\n",
    "\n",
    "print(get_interval(X[100].reshape(-1,1), a[100].reshape(-1, 1), b[100].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net Sequential(\n",
      "  (0): Linear(in_features=1, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (5): ReLU()\n",
      ")\n",
      "Linear(in_features=1, out_features=10, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=10, out_features=10, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=10, out_features=10, bias=True)\n",
      "ReLU()\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "layer_dict = {}\n",
    "\n",
    "cnt=0\n",
    "for name, layer in model.generator.named_children():\n",
    "    print(name, layer)\n",
    "    layer_info = {\"type\": layer.__class__.__name__}\n",
    "    cnt += 1\n",
    "    # Check if layer has parameters (weights and biases)\n",
    "    if isinstance(layer, nn.Sequential):\n",
    "        for sub_layer in layer:\n",
    "            print(sub_layer)\n",
    "            if hasattr(sub_layer, 'weight'):\n",
    "                layer_info[\"weight\"] = sub_layer.weight.detach().cpu().numpy()\n",
    "            if hasattr(sub_layer, 'bias'):\n",
    "                layer_info[\"bias\"] = sub_layer.bias.detach().cpu().numpy()\n",
    "\n",
    "print(layer_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
