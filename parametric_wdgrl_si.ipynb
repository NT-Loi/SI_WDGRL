{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gen_data(mu, delta, n, d: int = 2):\n",
    "    noise = np.random.normal(loc = 0, scale = 1, size=(n, d))\n",
    "    mu = np.full((n, d), mu, dtype=np.float64)\n",
    "\n",
    "    if len(delta) == 1 and delta[0] == 0:\n",
    "        return mu + noise, np.zeros(n)\n",
    "    \n",
    "    # 10% of the data are abnormal\n",
    "    m = len(delta)\n",
    "    abnormal_idx = np.random.choice(n, int(n/10), replace=False)\n",
    "\n",
    "    ptr = 0\n",
    "    for i in range(m):\n",
    "        for j in range(len(abnormal_idx)//m):\n",
    "            mu[abnormal_idx[ptr], :] += delta[i]\n",
    "            ptr += 1\n",
    "    \n",
    "    X = mu + noise \n",
    "    Y = np.zeros(n)\n",
    "    Y[abnormal_idx] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Feature extractor network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dims: List[int]):\n",
    "        \"\"\"Domain critic network.\"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class WDGRL():\n",
    "    def __init__(self, input_dim: int=2, generator_hidden_dims: List[int]=[32, 16, 8, 4, 2], critic_hidden_dims: List[int]=[32, 16, 8, 4, 2],\n",
    "                 gamma: float = 0.1, _lr_generator: float = 1e-2, _lr_critic: float = 1e-2, \n",
    "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.gamma = gamma\n",
    "        self.device = device\n",
    "        self.generator = Generator(input_dim, generator_hidden_dims).to(self.device)\n",
    "        self.critic = Critic(generator_hidden_dims[-1], critic_hidden_dims).to(self.device)\n",
    "        self.generator_optimizer = torch.optim.Adam(self.generator.parameters(), lr=_lr_generator)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=_lr_critic)\n",
    "    \n",
    "    def compute_gradient_penalty(self, source_data: torch.Tensor, target_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute gradient penalty.\"\"\"\n",
    "        if source_data.size(0) > target_data.size(0):\n",
    "            ms = source_data.size(0)\n",
    "            mt = target_data.size(0)\n",
    "            gradient_penalty = 0\n",
    "            for _ in range(0, ms, mt):\n",
    "                source_chunk = source_data[_:_+mt]\n",
    "                target_chunk = target_data\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            if ms % mt != 0:\n",
    "                source_chunk = source_data[ms-mt:]\n",
    "                perm = torch.randperm(mt)\n",
    "                idx = perm[:ms % mt]\n",
    "                target_chunk = target_data[idx]\n",
    "                alpha = torch.rand(target_chunk.size(0), 1).to(self.device)\n",
    "                interpolates = (alpha * source_chunk + ((1 - alpha) * target_chunk)).requires_grad_(True)\n",
    "                \n",
    "                # Domain critic outputs\n",
    "                dc_output = self.critic(interpolates)\n",
    "                \n",
    "                # Compute gradients\n",
    "                gradients = torch.autograd.grad(\n",
    "                    outputs=dc_output,\n",
    "                    inputs=interpolates,\n",
    "                    grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True,\n",
    "                    only_inputs=True,\n",
    "                )\n",
    "                gradients = gradients[0]\n",
    "                gradient_penalty += ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "            return gradient_penalty / ((ms // mt) + (ms % mt != 0)) \n",
    "        \n",
    "        # For balanced batch\n",
    "        alpha = torch.rand(source_data.size(0), 1).to(self.device)\n",
    "        interpolates = (alpha * source_data + ((1 - alpha) * target_data)).requires_grad_(True)\n",
    "        \n",
    "        # Domain critic outputs\n",
    "        dc_output = self.critic(interpolates)\n",
    "        \n",
    "        # Compute gradients\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=dc_output,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones_like(dc_output).to(self.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        # Compute gradient penalty\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    def train(self, source_loader: DataLoader, target_loader: DataLoader, num_epochs: int = 100, dc_iter: int = 100) -> List[float]:\n",
    "        self.generator.train()\n",
    "        self.critic.train()\n",
    "        losses = []\n",
    "        source_critic_scores = []\n",
    "        target_critic_scores = []\n",
    "        for epoch in trange(num_epochs, desc='Epoch'):\n",
    "            loss = 0\n",
    "            for (source_data, _), (target_data, _) in zip(source_loader, target_loader):\n",
    "                source_data, target_data = source_data.to(self.device), target_data.to(self.device)\n",
    "\n",
    "                # Train domain critic\n",
    "                for _ in range(dc_iter):\n",
    "                    self.critic_optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        source_features = self.generator(source_data)\n",
    "                        target_features = self.generator(target_data)\n",
    "                    \n",
    "                    # Compute empirical Wasserstein distance\n",
    "                    dc_source = self.critic(source_features)\n",
    "                    dc_target = self.critic(target_features)\n",
    "                    wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "\n",
    "                    # Gradient penalty\n",
    "                    gradient_penalty = self.compute_gradient_penalty(source_features, target_features)\n",
    "\n",
    "                    # Domain critic loss\n",
    "                    dc_loss = - wasserstein_distance + self.gamma * gradient_penalty\n",
    "                    dc_loss.backward()\n",
    "                    self.critic_optimizer.step()\n",
    "\n",
    "                # Train feature extractor\n",
    "                self.generator_optimizer.zero_grad()\n",
    "                source_features = self.generator(source_data)\n",
    "                target_features = self.generator(target_data)\n",
    "                dc_source = self.critic(source_features)\n",
    "                dc_target = self.critic(target_features)\n",
    "                wasserstein_distance = dc_source.mean() - dc_target.mean()\n",
    "                wasserstein_distance.backward()\n",
    "                self.generator_optimizer.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    loss += wasserstein_distance.item()\n",
    "                    \n",
    "            source_critic_scores.append(self.criticize(source_loader.dataset.tensors[0].to(self.device)))\n",
    "            target_critic_scores.append(self.criticize(target_loader.dataset.tensors[0].to(self.device)))\n",
    "            losses.append(loss/len(source_loader))\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs} | Loss: {wasserstein_distance.item()}')\n",
    "        return losses, source_critic_scores, target_critic_scores\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_feature(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        self.generator.eval()\n",
    "        return self.generator(x)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def criticize(self, x: torch.Tensor) -> float:\n",
    "        self.generator.eval()\n",
    "        self.critic.eval()\n",
    "        return self.critic(self.generator(x)).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new instance of the WDGRL model (same architecture as before)\n",
    "model = WDGRL(input_dim=1,generator_hidden_dims=[10, 10, 10], critic_hidden_dims=[10])\n",
    "\n",
    "# Load the saved checkpoint\n",
    "checkpoint = torch.load(\"wdgrl.pth\", map_location=model.device, weights_only=True)\n",
    "\n",
    "# Restore the model weights\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Create synthetic dataset and dataloaders for domain adaptation.\"\"\"\n",
    "# Create datasets\n",
    "ns, nt, d = 100, 10, 1\n",
    "mu_s, mu_t = 0, 20\n",
    "delta_s, delta_t = [4], [4]\n",
    "xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "plt.scatter(xs[:, 0], np.zeros_like(xs[:, 0]), c=ys, cmap='viridis', s=2)\n",
    "plt.scatter(xt[:, 0], np.zeros_like(xt[:, 0]), c=yt, cmap='cool', s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.FloatTensor(xs)\n",
    "ys = torch.LongTensor(ys)\n",
    "xt = torch.FloatTensor(xt)\n",
    "yt = torch.LongTensor(yt)\n",
    "xs_hat = model.extract_feature(xs.cuda())\n",
    "xt_hat = model.extract_feature(xt.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_sum(X):\n",
    "    return np.argmax(np.sum(X, axis=1))\n",
    "x_hat = torch.cat([xs_hat, xt_hat], dim=0).cpu().numpy()\n",
    "print(x_hat)\n",
    "O = max_sum(x_hat)\n",
    "O = [O-ns]\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_hat = torch.zeros_like(yt)\n",
    "yt_hat[O[0]] = 1\n",
    "print(yt)\n",
    "yt_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(yt, yt_hat)\n",
    "precision = precision_score(yt, yt_hat)\n",
    "recall = recall_score(yt, yt_hat)\n",
    "f1 = f1_score(yt, yt_hat)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(yt, yt_hat))\n",
    "\n",
    "# Print the scores\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(yt, yt_hat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpmath import mp\n",
    "\n",
    "mp.dps = 500\n",
    "def intersect(itv1, itv2):\n",
    "    # print(itv1, itv2)\n",
    "    itv = [max(itv1[0], itv2[0]), min(itv1[1], itv2[1])]\n",
    "    if itv[0] > itv[1]:\n",
    "        return None    \n",
    "    return itv\n",
    "\n",
    "def solve_linear_inequality(u, v): #u + vz < 0\n",
    "    u = float(u)\n",
    "    v = float(v)\n",
    "    if (v > -1e-16 and v < 1e-16):\n",
    "        if (u < 0):\n",
    "            return [-np.Inf, np.Inf]\n",
    "        else:\n",
    "            print('error')\n",
    "            return None\n",
    "    if (v < 0):\n",
    "        return [-u/v, np.Inf]\n",
    "    return [np.NINF, -u/v]\n",
    "\n",
    "def get_dnn_interval(Xtj, a, b):\n",
    "    layers = []\n",
    "\n",
    "    for name, param in model.generator.named_children():\n",
    "        temp = dict(param._modules)\n",
    "        \n",
    "        for layer_name in temp.values():\n",
    "            if ('Linear' in str(layer_name)):\n",
    "                layers.append('Linear')\n",
    "            elif ('ReLU' in str(layer_name)):\n",
    "                layers.append('ReLU')\n",
    "\n",
    "    ptr = 0\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    u = a\n",
    "    v = b\n",
    "    temp = Xtj\n",
    "    weight = None\n",
    "    bias = None\n",
    "    for name, param in model.generator.named_parameters():\n",
    "        if (layers[ptr] == 'Linear'):\n",
    "            if ('weight' in name):\n",
    "                weight = param.data.cpu().detach().numpy()\n",
    "            elif ('bias' in name):\n",
    "                bias = param.data.cpu().detach().numpy().reshape(-1, 1)\n",
    "                ptr += 1\n",
    "                temp = weight.dot(temp) + bias\n",
    "                u = weight.dot(u) + bias\n",
    "                v = weight.dot(v)\n",
    "\n",
    "        if (ptr < len(layers) and layers[ptr] == 'ReLU'):\n",
    "            ptr += 1\n",
    "            Relu_matrix = np.zeros((temp.shape[0], temp.shape[0]))\n",
    "            sub_itv = [np.NINF, np.inf]\n",
    "            for i in range(temp.shape[0]):\n",
    "                if temp[i] > 0:\n",
    "                    Relu_matrix[i][i] = 1\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(-u[i], -v[i]))\n",
    "                else:\n",
    "                    sub_itv = intersect(sub_itv, solve_linear_inequality(u[i], v[i]))\n",
    "            itv = intersect(itv, sub_itv)\n",
    "            temp = Relu_matrix.dot(temp)\n",
    "            u = Relu_matrix.dot(u)\n",
    "            v = Relu_matrix.dot(v)\n",
    "\n",
    "    return itv, u, v\n",
    "\n",
    "def get_ad_interval(X, X_hat, O, a, b):\n",
    "    itv = [np.NINF, np.Inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        itv = intersect(itv, get_dnn_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))[0])\n",
    "    _, uo, vo = get_dnn_interval(X[O].reshape(-1, 1), a[O].reshape(-1, 1), b[O].reshape(-1, 1))\n",
    "    I = np.ones((X_hat.shape[1],1))\n",
    "    sub_itv = [np.NINF, np.inf]\n",
    "    for i in range(X.shape[0]):\n",
    "        if (i != O):\n",
    "            _, ui, vi = get_dnn_interval(X[i].reshape(-1, 1), a[i].reshape(-1, 1), b[i].reshape(-1, 1))\n",
    "            u = uo - ui\n",
    "            v = vo - vi \n",
    "            u = I.T.dot(u)\n",
    "            v = I.T.dot(v)\n",
    "            sub_itv = intersect(sub_itv, solve_linear_inequality(-u, -v))\n",
    "    itv = intersect(itv, sub_itv)\n",
    "    return itv\n",
    "\n",
    "def compute_yz(X, etaj, zk, n):\n",
    "    sq_norm = (np.linalg.norm(etaj))**2\n",
    "\n",
    "    e1 = np.identity(n) - (np.dot(etaj, etaj.T))/sq_norm\n",
    "    a = np.dot(e1, X)\n",
    "\n",
    "    b = etaj/sq_norm\n",
    "\n",
    "    Xz = a + b*zk\n",
    "\n",
    "    return Xz, a, b\n",
    "\n",
    "def parametric_wdgrl(Xz, a, b, n, zk):\n",
    "    Xz = torch.FloatTensor(Xz)\n",
    "    Xz_hat = model.extract_feature(Xz.cuda())\n",
    "    Oz = [max_sum(Xz_hat.cpu().numpy())]\n",
    "    itv = get_ad_interval(Xz, Xz_hat, Oz[0], a, b)\n",
    "    return itv[1] - min(zk, itv[1]), Oz\n",
    "\n",
    "\n",
    "def run_parametric_wdgrl(X, etaj, n, threshold):\n",
    "    zk = -threshold\n",
    "\n",
    "    list_zk = [zk]\n",
    "    list_Oz = []\n",
    "\n",
    "    while zk < threshold:\n",
    "        Xz, a, b = compute_yz(X, etaj, zk, n)\n",
    "        skz, Oz = parametric_wdgrl(Xz, a, b, n, zk)\n",
    "\n",
    "        zk = zk + skz + 1e-3 \n",
    "        zk = min(zk, threshold)\n",
    "        if zk < threshold:\n",
    "            list_zk.append(zk)\n",
    "        else:\n",
    "            list_zk.append(threshold)\n",
    "        list_Oz.append(Oz)\n",
    "        # print(f'intervals: {zk-skz-1e-3} - {zk -1e-3}')\n",
    "        # print(f'Anomaly index: {Oz}')\n",
    "    return list_zk, list_Oz\n",
    "        \n",
    "def cdf(mu, sigma, list_zk, list_Oz, etajTX, O):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for each_interval in range(len(list_zk) - 1):\n",
    "        al = list_zk[each_interval]\n",
    "        ar = list_zk[each_interval + 1] - 1e-3\n",
    "\n",
    "        if (np.array_equal(O, list_Oz[each_interval]) == False):\n",
    "            continue\n",
    "\n",
    "        denominator = denominator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)\n",
    "        if etajTX >= ar:\n",
    "            numerator = numerator + mp.ncdf((ar - mu)/sigma) - mp.ncdf((al - mu)/sigma)\n",
    "        elif (etajTX >= al) and (etajTX< ar):\n",
    "            numerator = numerator + mp.ncdf((etajTX - mu)/sigma) - mp.ncdf((al - mu)/sigma)\n",
    "\n",
    "    if denominator != 0:\n",
    "        return float(numerator/denominator)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fpr():\n",
    "    # np.random.seed(42)\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = [4], [0]\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_s, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "\n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "\n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < 100):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - 100]   \n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    X = np.vstack((xs, xt))\n",
    "    X = torch.FloatTensor(X)\n",
    "    j = np.random.choice(O)\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "\n",
    "    etajTx = etaj.T.dot(X)\n",
    "    \n",
    "    print(f'Anomaly index: {O[0] + 100}')\n",
    "    print(f'etajTX: {etajTx}')\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    threshold = 20\n",
    "    list_zk, list_Oz = run_parametric_wdgrl(X, etaj, ns+nt, threshold)\n",
    "    CDF = cdf(etajTmu[0][0], etajTsigmaetaj[0][0], list_zk, list_Oz, etajTx[0][0], [O[0] + 100])\n",
    "    p_value = 2 * min(CDF, 1 - CDF)\n",
    "    print(f'p-value: {p_value}')\n",
    "    return p_value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #0:\n",
      "Anomaly index: 102\n",
      "etajTX: [[-2.42122948]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9804\\3172295839.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  u = float(u)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9804\\3172295839.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  v = float(v)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(list_p_value) \u001b[38;5;241m<\u001b[39m max_iteration:\n\u001b[1;32m---> 10\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 57\u001b[0m, in \u001b[0;36mrun_fpr\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m a \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39midentity(ns\u001b[38;5;241m+\u001b[39mnt) \u001b[38;5;241m-\u001b[39m b\u001b[38;5;241m.\u001b[39mdot(etaj\u001b[38;5;241m.\u001b[39mT))\u001b[38;5;241m.\u001b[39mdot(X)\n\u001b[0;32m     56\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m---> 57\u001b[0m list_zk, list_Oz \u001b[38;5;241m=\u001b[39m \u001b[43mrun_parametric_wdgrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metaj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mnt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m CDF \u001b[38;5;241m=\u001b[39m cdf(etajTmu[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], etajTsigmaetaj[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], list_zk, list_Oz, etajTx[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], [O[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m     59\u001b[0m p_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmin\u001b[39m(CDF, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m CDF)\n",
      "Cell \u001b[1;32mIn[20], line 117\u001b[0m, in \u001b[0;36mrun_parametric_wdgrl\u001b[1;34m(X, etaj, n, threshold)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m zk \u001b[38;5;241m<\u001b[39m threshold:\n\u001b[0;32m    116\u001b[0m     Xz, a, b \u001b[38;5;241m=\u001b[39m compute_yz(X, etaj, zk, n)\n\u001b[1;32m--> 117\u001b[0m     skz, Oz \u001b[38;5;241m=\u001b[39m \u001b[43mparametric_wdgrl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     zk \u001b[38;5;241m=\u001b[39m zk \u001b[38;5;241m+\u001b[39m skz \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-3\u001b[39m \n\u001b[0;32m    120\u001b[0m     zk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(zk, threshold)\n",
      "Cell \u001b[1;32mIn[20], line 105\u001b[0m, in \u001b[0;36mparametric_wdgrl\u001b[1;34m(Xz, a, b, n, zk)\u001b[0m\n\u001b[0;32m    103\u001b[0m Xz_hat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mextract_feature(Xz\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[0;32m    104\u001b[0m Oz \u001b[38;5;241m=\u001b[39m [max_sum(Xz_hat\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())]\n\u001b[1;32m--> 105\u001b[0m itv \u001b[38;5;241m=\u001b[39m \u001b[43mget_ad_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXz_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m itv[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m(zk, itv[\u001b[38;5;241m1\u001b[39m]), Oz\n",
      "Cell \u001b[1;32mIn[20], line 74\u001b[0m, in \u001b[0;36mget_ad_interval\u001b[1;34m(X, X_hat, O, a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m itv \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mNINF, np\u001b[38;5;241m.\u001b[39mInf]\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 74\u001b[0m     itv \u001b[38;5;241m=\u001b[39m intersect(itv, \u001b[43mget_dnn_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     75\u001b[0m _, uo, vo \u001b[38;5;241m=\u001b[39m get_dnn_interval(X[O]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), a[O]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), b[O]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     76\u001b[0m I \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((X_hat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[20], line 46\u001b[0m, in \u001b[0;36mget_dnn_interval\u001b[1;34m(Xtj, a, b)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (layers[ptr] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name):\n\u001b[1;32m---> 46\u001b[0m         weight \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name):\n\u001b[0;32m     48\u001b[0m         bias \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "max_iteration = 1000\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "print(f'iteration #{0}:')\n",
    "\n",
    "\n",
    "while len(list_p_value) < max_iteration:\n",
    "    p_value = run_fpr()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "    print(f'FPR: {count / len(list_p_value)}')\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'iteration #{len(list_p_value)+1}:')\n",
    "print(f'KS-test p-value: {stats.kstest(list_p_value, 'uniform')[1]}')\n",
    "\n",
    "\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tpr():\n",
    "    # np.random.seed(42)\n",
    "    # Create datasets\n",
    "    ns, nt, d = 100, 10, 1\n",
    "    mu_s, mu_t = 0, 20\n",
    "    delta_s, delta_t = [1], [1]\n",
    "    xs, ys = gen_data(mu_s, delta_s, ns, d)\n",
    "    xt, yt = gen_data(mu_t, delta_t, nt, d)\n",
    "\n",
    "    xs = torch.FloatTensor(xs)\n",
    "    ys = torch.LongTensor(ys)\n",
    "    xt = torch.FloatTensor(xt)\n",
    "    yt = torch.LongTensor(yt)\n",
    "\n",
    "    xs = xs.cuda()\n",
    "    xt = xt.cuda()\n",
    "    ys = ys.cuda()\n",
    "    yt = yt.cuda()\n",
    "\n",
    "    xs_hat = model.extract_feature(xs)\n",
    "    xt_hat = model.extract_feature(xt)\n",
    "    x_hat = torch.cat([xs_hat, xt_hat], dim=0)\n",
    "\n",
    "    xs_hat = xs_hat.cpu()\n",
    "    xt_hat = xt_hat.cpu()\n",
    "    x_hat = x_hat.cpu()\n",
    "    xs = xs.cpu()\n",
    "    xt = xt.cpu()\n",
    "    ys = ys.cpu()\n",
    "    yt = yt.cpu()\n",
    "\n",
    "    O = max_sum(x_hat.numpy())\n",
    "    if (O < ns):\n",
    "        return None\n",
    "    else:\n",
    "        O = [O - ns]   \n",
    "    if yt[O[0]] == 0:\n",
    "        return None\n",
    "    Oc = list(torch.where(yt == 0)[0])\n",
    "    X = np.vstack((xs, xt))\n",
    "    X = torch.FloatTensor(X)\n",
    "    j = np.random.choice(O)\n",
    "    etj = np.zeros((nt, 1))\n",
    "    etj[j][0] = 1\n",
    "    etOc = np.zeros((nt, 1))\n",
    "    etOc[Oc] = 1\n",
    "    etaj = np.vstack((np.zeros((ns, 1)), etj-(1/len(Oc))*etOc))\n",
    "\n",
    "    etajTx = etaj.T.dot(X)\n",
    "    \n",
    "    print(f'Anomaly index: {O[0] + ns}')\n",
    "    print(f'etajTX: {etajTx}')\n",
    "    mu = np.vstack((np.full((ns,1), mu_s), np.full((nt,1), mu_t)))\n",
    "    sigma = np.identity(ns+nt)\n",
    "    etajTmu = etaj.T.dot(mu)\n",
    "    etajTsigmaetaj = etaj.T.dot(sigma).dot(etaj)\n",
    "    b = sigma.dot(etaj).dot(np.linalg.inv(etajTsigmaetaj))\n",
    "    a = (np.identity(ns+nt) - b.dot(etaj.T)).dot(X)\n",
    "    threshold = 20\n",
    "    list_zk, list_Oz = run_parametric_wdgrl(X, etaj, ns+nt, threshold)\n",
    "    CDF = cdf(etajTmu[0][0], etajTsigmaetaj[0][0], list_zk, list_Oz, etajTx[0][0], [O[0] + ns])\n",
    "    p_value = 2 * min(CDF, 1 - CDF)\n",
    "    print(f'p-value: {p_value}')\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #0:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.54033873]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13780\\3172295839.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  u = float(u)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13780\\3172295839.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  v = float(v)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.9806659552385734\n",
      "TPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #2:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.46685537]]\n",
      "p-value: 0.2549723621164468\n",
      "TPR: 0.0\n",
      "-------------------------------------------------\n",
      "iteration #3:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.29031478]]\n",
      "p-value: 0.025334851214287024\n",
      "TPR: 0.3333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #4:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.38114887]]\n",
      "p-value: 0.4925323675135334\n",
      "TPR: 0.25\n",
      "-------------------------------------------------\n",
      "iteration #5:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.82932621]]\n",
      "p-value: 0.4011186404915952\n",
      "TPR: 0.2\n",
      "-------------------------------------------------\n",
      "iteration #6:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.79586601]]\n",
      "p-value: 0.8696409691756184\n",
      "TPR: 0.16666666666666666\n",
      "-------------------------------------------------\n",
      "iteration #7:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.52181753]]\n",
      "p-value: 0.21766068313151984\n",
      "TPR: 0.14285714285714285\n",
      "-------------------------------------------------\n",
      "iteration #8:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.52178637]]\n",
      "p-value: 0.1853150213962529\n",
      "TPR: 0.125\n",
      "-------------------------------------------------\n",
      "iteration #9:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.56168365]]\n",
      "p-value: 0.07462189374181949\n",
      "TPR: 0.1111111111111111\n",
      "-------------------------------------------------\n",
      "iteration #10:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.24298731]]\n",
      "p-value: 0.3993218029374811\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #11:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.48972532]]\n",
      "p-value: 0.1129146362031812\n",
      "TPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #12:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.78676838]]\n",
      "p-value: 0.0029723751622805494\n",
      "TPR: 0.16666666666666666\n",
      "-------------------------------------------------\n",
      "iteration #13:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.31799592]]\n",
      "p-value: 0.8658295399726856\n",
      "TPR: 0.15384615384615385\n",
      "-------------------------------------------------\n",
      "iteration #14:\n",
      "Anomaly index: 102\n",
      "etajTX: [[3.91138268]]\n",
      "p-value: 0.0037105080407537905\n",
      "TPR: 0.21428571428571427\n",
      "-------------------------------------------------\n",
      "iteration #15:\n",
      "Anomaly index: 104\n",
      "etajTX: [[1.55486552]]\n",
      "p-value: 0.8785706101405129\n",
      "TPR: 0.2\n",
      "-------------------------------------------------\n",
      "iteration #16:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.60764143]]\n",
      "p-value: 0.45306601666176816\n",
      "TPR: 0.1875\n",
      "-------------------------------------------------\n",
      "iteration #17:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.97535472]]\n",
      "p-value: 0.452554762757285\n",
      "TPR: 0.17647058823529413\n",
      "-------------------------------------------------\n",
      "iteration #18:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.47824605]]\n",
      "p-value: 0.6973901089507915\n",
      "TPR: 0.16666666666666666\n",
      "-------------------------------------------------\n",
      "iteration #19:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.04657258]]\n",
      "p-value: 0.9159792184621982\n",
      "TPR: 0.15789473684210525\n",
      "-------------------------------------------------\n",
      "iteration #20:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.94157939]]\n",
      "p-value: 0.6521765598725396\n",
      "TPR: 0.15\n",
      "-------------------------------------------------\n",
      "iteration #21:\n",
      "Anomaly index: 107\n",
      "etajTX: [[2.33750958]]\n",
      "p-value: 0.3275954345946668\n",
      "TPR: 0.14285714285714285\n",
      "-------------------------------------------------\n",
      "iteration #22:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.10186153]]\n",
      "p-value: 0.9079867518785242\n",
      "TPR: 0.13636363636363635\n",
      "-------------------------------------------------\n",
      "iteration #23:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.48498705]]\n",
      "p-value: 0.7363139628333679\n",
      "TPR: 0.13043478260869565\n",
      "-------------------------------------------------\n",
      "iteration #24:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.32460721]]\n",
      "p-value: 0.9059429569472104\n",
      "TPR: 0.125\n",
      "-------------------------------------------------\n",
      "iteration #25:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.40855111]]\n",
      "p-value: 0.6947336063859264\n",
      "TPR: 0.12\n",
      "-------------------------------------------------\n",
      "iteration #26:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.14421823]]\n",
      "p-value: 0.3510606233780414\n",
      "TPR: 0.11538461538461539\n",
      "-------------------------------------------------\n",
      "iteration #27:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.5461252]]\n",
      "p-value: 0.7223192588067145\n",
      "TPR: 0.1111111111111111\n",
      "-------------------------------------------------\n",
      "iteration #28:\n",
      "Anomaly index: 100\n",
      "etajTX: [[0.75884734]]\n",
      "p-value: 0.05379500801504722\n",
      "TPR: 0.10714285714285714\n",
      "-------------------------------------------------\n",
      "iteration #29:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.00718668]]\n",
      "p-value: 0.24021067035803098\n",
      "TPR: 0.10344827586206896\n",
      "-------------------------------------------------\n",
      "iteration #30:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.50905503]]\n",
      "p-value: 0.7534583057269066\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #31:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.01583947]]\n",
      "p-value: 0.9007179825892706\n",
      "TPR: 0.0967741935483871\n",
      "-------------------------------------------------\n",
      "iteration #32:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.01346885]]\n",
      "p-value: 0.312295445183268\n",
      "TPR: 0.09375\n",
      "-------------------------------------------------\n",
      "iteration #33:\n",
      "Anomaly index: 107\n",
      "etajTX: [[2.05622821]]\n",
      "p-value: 0.9309449929947768\n",
      "TPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #34:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.00285636]]\n",
      "p-value: 0.32022153432680117\n",
      "TPR: 0.08823529411764706\n",
      "-------------------------------------------------\n",
      "iteration #35:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.38956345]]\n",
      "p-value: 0.19395117023207953\n",
      "TPR: 0.08571428571428572\n",
      "-------------------------------------------------\n",
      "iteration #36:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.59909651]]\n",
      "p-value: 0.03383490143404805\n",
      "TPR: 0.1111111111111111\n",
      "-------------------------------------------------\n",
      "iteration #37:\n",
      "Anomaly index: 105\n",
      "etajTX: [[0.99206225]]\n",
      "p-value: 0.3438170839255692\n",
      "TPR: 0.10810810810810811\n",
      "-------------------------------------------------\n",
      "iteration #38:\n",
      "Anomaly index: 105\n",
      "etajTX: [[0.91027302]]\n",
      "p-value: 0.5466415753348667\n",
      "TPR: 0.10526315789473684\n",
      "-------------------------------------------------\n",
      "iteration #39:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.60105557]]\n",
      "p-value: 0.4830627477967459\n",
      "TPR: 0.10256410256410256\n",
      "-------------------------------------------------\n",
      "iteration #40:\n",
      "Anomaly index: 107\n",
      "etajTX: [[2.36716949]]\n",
      "p-value: 0.22456941750309412\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #41:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.58957354]]\n",
      "p-value: 0.8901909929026621\n",
      "TPR: 0.0975609756097561\n",
      "-------------------------------------------------\n",
      "iteration #42:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.93140941]]\n",
      "p-value: 0.3280698801390003\n",
      "TPR: 0.09523809523809523\n",
      "-------------------------------------------------\n",
      "iteration #43:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.74435785]]\n",
      "p-value: 0.8483282471750508\n",
      "TPR: 0.09302325581395349\n",
      "-------------------------------------------------\n",
      "iteration #44:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.87233501]]\n",
      "p-value: 0.7251399528722791\n",
      "TPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #45:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.65292655]]\n",
      "p-value: 0.38170859553350156\n",
      "TPR: 0.08888888888888889\n",
      "-------------------------------------------------\n",
      "iteration #46:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.04278713]]\n",
      "p-value: 0.3277526082538358\n",
      "TPR: 0.08695652173913043\n",
      "-------------------------------------------------\n",
      "iteration #47:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.64516068]]\n",
      "p-value: 0.6381535874629938\n",
      "TPR: 0.0851063829787234\n",
      "-------------------------------------------------\n",
      "iteration #48:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.54427253]]\n",
      "p-value: 0.09145793971632821\n",
      "TPR: 0.08333333333333333\n",
      "-------------------------------------------------\n",
      "iteration #49:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.71281009]]\n",
      "p-value: 0.8785052017713835\n",
      "TPR: 0.08163265306122448\n",
      "-------------------------------------------------\n",
      "iteration #50:\n",
      "Anomaly index: 105\n",
      "etajTX: [[3.40600162]]\n",
      "p-value: 0.027670670228115535\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #51:\n",
      "Anomaly index: 100\n",
      "etajTX: [[3.64724837]]\n",
      "p-value: 0.028170727107397875\n",
      "TPR: 0.11764705882352941\n",
      "-------------------------------------------------\n",
      "iteration #52:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.60972955]]\n",
      "p-value: 0.27438802649907346\n",
      "TPR: 0.11538461538461539\n",
      "-------------------------------------------------\n",
      "iteration #53:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.01053174]]\n",
      "p-value: 0.40276641869069535\n",
      "TPR: 0.11320754716981132\n",
      "-------------------------------------------------\n",
      "iteration #54:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.44263204]]\n",
      "p-value: 0.5371343812491363\n",
      "TPR: 0.1111111111111111\n",
      "-------------------------------------------------\n",
      "iteration #55:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.63027763]]\n",
      "p-value: 0.9373326834174684\n",
      "TPR: 0.10909090909090909\n",
      "-------------------------------------------------\n",
      "iteration #56:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.59631602]]\n",
      "p-value: 0.8067651302696348\n",
      "TPR: 0.10714285714285714\n",
      "-------------------------------------------------\n",
      "iteration #57:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.04056803]]\n",
      "p-value: 0.2930736134794547\n",
      "TPR: 0.10526315789473684\n",
      "-------------------------------------------------\n",
      "iteration #58:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.24061627]]\n",
      "p-value: 0.44031127848697155\n",
      "TPR: 0.10344827586206896\n",
      "-------------------------------------------------\n",
      "iteration #59:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.13809564]]\n",
      "p-value: 0.2343961200308644\n",
      "TPR: 0.1016949152542373\n",
      "-------------------------------------------------\n",
      "iteration #60:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.44170613]]\n",
      "p-value: 0.531455293166005\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #61:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.75205506]]\n",
      "p-value: 0.08539785459929387\n",
      "TPR: 0.09836065573770492\n",
      "-------------------------------------------------\n",
      "iteration #62:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.55982738]]\n",
      "p-value: 0.2199262205241701\n",
      "TPR: 0.0967741935483871\n",
      "-------------------------------------------------\n",
      "iteration #63:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.8984979]]\n",
      "p-value: 0.10891026121201985\n",
      "TPR: 0.09523809523809523\n",
      "-------------------------------------------------\n",
      "iteration #64:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.08394814]]\n",
      "p-value: 0.6538384101032639\n",
      "TPR: 0.09375\n",
      "-------------------------------------------------\n",
      "iteration #65:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.23553975]]\n",
      "p-value: 0.5232997117436176\n",
      "TPR: 0.09230769230769231\n",
      "-------------------------------------------------\n",
      "iteration #66:\n",
      "Anomaly index: 100\n",
      "etajTX: [[0.93393347]]\n",
      "p-value: 0.6644089238150288\n",
      "TPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #67:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.87303734]]\n",
      "p-value: 0.857058492635822\n",
      "TPR: 0.08955223880597014\n",
      "-------------------------------------------------\n",
      "iteration #68:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.40904681]]\n",
      "p-value: 0.5000516610424399\n",
      "TPR: 0.08823529411764706\n",
      "-------------------------------------------------\n",
      "iteration #69:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.69567532]]\n",
      "p-value: 0.8347874038268357\n",
      "TPR: 0.08695652173913043\n",
      "-------------------------------------------------\n",
      "iteration #70:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.17650901]]\n",
      "p-value: 0.2188721657881323\n",
      "TPR: 0.08571428571428572\n",
      "-------------------------------------------------\n",
      "iteration #71:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.47420862]]\n",
      "p-value: 0.027990549441633927\n",
      "TPR: 0.09859154929577464\n",
      "-------------------------------------------------\n",
      "iteration #72:\n",
      "Anomaly index: 106\n",
      "etajTX: [[3.72764715]]\n",
      "p-value: 0.005608078299901065\n",
      "TPR: 0.1111111111111111\n",
      "-------------------------------------------------\n",
      "iteration #73:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.78422885]]\n",
      "p-value: 0.07828007725870342\n",
      "TPR: 0.1095890410958904\n",
      "-------------------------------------------------\n",
      "iteration #74:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.34302923]]\n",
      "p-value: 0.2860853355989976\n",
      "TPR: 0.10810810810810811\n",
      "-------------------------------------------------\n",
      "iteration #75:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.72482618]]\n",
      "p-value: 0.737091895732157\n",
      "TPR: 0.10666666666666667\n",
      "-------------------------------------------------\n",
      "iteration #76:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.37098206]]\n",
      "p-value: 0.9610445787241229\n",
      "TPR: 0.10526315789473684\n",
      "-------------------------------------------------\n",
      "iteration #77:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.10481517]]\n",
      "p-value: 0.6248093457574817\n",
      "TPR: 0.1038961038961039\n",
      "-------------------------------------------------\n",
      "iteration #78:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.45578406]]\n",
      "p-value: 0.15316738175087452\n",
      "TPR: 0.10256410256410256\n",
      "-------------------------------------------------\n",
      "iteration #79:\n",
      "Anomaly index: 109\n",
      "etajTX: [[2.0569405]]\n",
      "p-value: 0.3696083980637066\n",
      "TPR: 0.10126582278481013\n",
      "-------------------------------------------------\n",
      "iteration #80:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.29029867]]\n",
      "p-value: 0.398904868820821\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #81:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.36927668]]\n",
      "p-value: 0.3249053773435062\n",
      "TPR: 0.09876543209876543\n",
      "-------------------------------------------------\n",
      "iteration #82:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.46369531]]\n",
      "p-value: 0.20187776576384941\n",
      "TPR: 0.0975609756097561\n",
      "-------------------------------------------------\n",
      "iteration #83:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.71029896]]\n",
      "p-value: 0.891712583062972\n",
      "TPR: 0.0963855421686747\n",
      "-------------------------------------------------\n",
      "iteration #84:\n",
      "Anomaly index: 104\n",
      "etajTX: [[1.32149929]]\n",
      "p-value: 0.9602292608060312\n",
      "TPR: 0.09523809523809523\n",
      "-------------------------------------------------\n",
      "iteration #85:\n",
      "Anomaly index: 105\n",
      "etajTX: [[2.01041243]]\n",
      "p-value: 0.8267768535284056\n",
      "TPR: 0.09411764705882353\n",
      "-------------------------------------------------\n",
      "iteration #86:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.47485563]]\n",
      "p-value: 0.9432147897757832\n",
      "TPR: 0.09302325581395349\n",
      "-------------------------------------------------\n",
      "iteration #87:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.98264694]]\n",
      "p-value: 0.6596592557146728\n",
      "TPR: 0.09195402298850575\n",
      "-------------------------------------------------\n",
      "iteration #88:\n",
      "Anomaly index: 107\n",
      "etajTX: [[1.97052595]]\n",
      "p-value: 0.7868317387488601\n",
      "TPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #89:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.52494197]]\n",
      "p-value: 0.34058849546424463\n",
      "TPR: 0.0898876404494382\n",
      "-------------------------------------------------\n",
      "iteration #90:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.69344627]]\n",
      "p-value: 0.5776618913003544\n",
      "TPR: 0.08888888888888889\n",
      "-------------------------------------------------\n",
      "iteration #91:\n",
      "Anomaly index: 108\n",
      "etajTX: [[1.84627046]]\n",
      "p-value: 0.46585366506012704\n",
      "TPR: 0.08791208791208792\n",
      "-------------------------------------------------\n",
      "iteration #92:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.19995795]]\n",
      "p-value: 0.02327859468376363\n",
      "TPR: 0.09782608695652174\n",
      "-------------------------------------------------\n",
      "iteration #93:\n",
      "Anomaly index: 104\n",
      "etajTX: [[1.70444743]]\n",
      "p-value: 0.6387377219588095\n",
      "TPR: 0.0967741935483871\n",
      "-------------------------------------------------\n",
      "iteration #94:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.91365412]]\n",
      "p-value: 0.805538258354796\n",
      "TPR: 0.09574468085106383\n",
      "-------------------------------------------------\n",
      "iteration #95:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.75699721]]\n",
      "p-value: 0.10667750201140058\n",
      "TPR: 0.09473684210526316\n",
      "-------------------------------------------------\n",
      "iteration #96:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.69789653]]\n",
      "p-value: 0.5870593676427387\n",
      "TPR: 0.09375\n",
      "-------------------------------------------------\n",
      "iteration #97:\n",
      "Anomaly index: 104\n",
      "etajTX: [[2.30484729]]\n",
      "p-value: 0.21191961146594385\n",
      "TPR: 0.09278350515463918\n",
      "-------------------------------------------------\n",
      "iteration #98:\n",
      "Anomaly index: 103\n",
      "etajTX: [[1.55419371]]\n",
      "p-value: 0.6305095884620525\n",
      "TPR: 0.09183673469387756\n",
      "-------------------------------------------------\n",
      "iteration #99:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.38832325]]\n",
      "p-value: 0.01766428457955715\n",
      "TPR: 0.10101010101010101\n",
      "-------------------------------------------------\n",
      "iteration #100:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.79959234]]\n",
      "p-value: 0.3539244174518849\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #101:\n",
      "Anomaly index: 101\n",
      "etajTX: [[3.16398536]]\n",
      "p-value: 0.2768081272066325\n",
      "TPR: 0.09900990099009901\n",
      "-------------------------------------------------\n",
      "iteration #102:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.8398766]]\n",
      "p-value: 0.15560921523935112\n",
      "TPR: 0.09803921568627451\n",
      "-------------------------------------------------\n",
      "iteration #103:\n",
      "Anomaly index: 107\n",
      "etajTX: [[4.47425546]]\n",
      "p-value: 0.000547985752129998\n",
      "TPR: 0.10679611650485436\n",
      "-------------------------------------------------\n",
      "iteration #104:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.7437049]]\n",
      "p-value: 0.09134954331076961\n",
      "TPR: 0.10576923076923077\n",
      "-------------------------------------------------\n",
      "iteration #105:\n",
      "Anomaly index: 100\n",
      "etajTX: [[2.66520712]]\n",
      "p-value: 0.10257369183360221\n",
      "TPR: 0.10476190476190476\n",
      "-------------------------------------------------\n",
      "iteration #106:\n",
      "Anomaly index: 102\n",
      "etajTX: [[3.06626723]]\n",
      "p-value: 0.05829715911543998\n",
      "TPR: 0.10377358490566038\n",
      "-------------------------------------------------\n",
      "iteration #107:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.43730948]]\n",
      "p-value: 0.16443072192397312\n",
      "TPR: 0.102803738317757\n",
      "-------------------------------------------------\n",
      "iteration #108:\n",
      "Anomaly index: 102\n",
      "etajTX: [[2.13254886]]\n",
      "p-value: 0.4393460264553197\n",
      "TPR: 0.10185185185185185\n",
      "-------------------------------------------------\n",
      "iteration #109:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.94206026]]\n",
      "p-value: 0.3661504342308479\n",
      "TPR: 0.10091743119266056\n",
      "-------------------------------------------------\n",
      "iteration #110:\n",
      "Anomaly index: 106\n",
      "etajTX: [[2.29826207]]\n",
      "p-value: 0.6395451851317699\n",
      "TPR: 0.1\n",
      "-------------------------------------------------\n",
      "iteration #111:\n",
      "Anomaly index: 108\n",
      "etajTX: [[2.74612533]]\n",
      "p-value: 0.10422994394150087\n",
      "TPR: 0.0990990990990991\n",
      "-------------------------------------------------\n",
      "iteration #112:\n",
      "Anomaly index: 109\n",
      "etajTX: [[1.90681775]]\n",
      "p-value: 0.760578247054361\n",
      "TPR: 0.09821428571428571\n",
      "-------------------------------------------------\n",
      "iteration #113:\n",
      "Anomaly index: 103\n",
      "etajTX: [[2.10437499]]\n",
      "p-value: 0.3601000861970245\n",
      "TPR: 0.09734513274336283\n",
      "-------------------------------------------------\n",
      "iteration #114:\n",
      "Anomaly index: 104\n",
      "etajTX: [[1.46240722]]\n",
      "p-value: 0.43458316918274004\n",
      "TPR: 0.09649122807017543\n",
      "-------------------------------------------------\n",
      "iteration #115:\n",
      "Anomaly index: 105\n",
      "etajTX: [[1.91455015]]\n",
      "p-value: 0.8174640899185048\n",
      "TPR: 0.09565217391304348\n",
      "-------------------------------------------------\n",
      "iteration #116:\n",
      "Anomaly index: 100\n",
      "etajTX: [[1.61016549]]\n",
      "p-value: 0.5092804617667022\n",
      "TPR: 0.09482758620689655\n",
      "-------------------------------------------------\n",
      "iteration #117:\n",
      "Anomaly index: 103\n",
      "etajTX: [[0.95664999]]\n",
      "p-value: 0.17225427324604772\n",
      "TPR: 0.09401709401709402\n",
      "-------------------------------------------------\n",
      "iteration #118:\n",
      "Anomaly index: 101\n",
      "etajTX: [[2.03739696]]\n",
      "p-value: 0.3711961983245573\n",
      "TPR: 0.09322033898305085\n",
      "-------------------------------------------------\n",
      "iteration #119:\n",
      "Anomaly index: 101\n",
      "etajTX: [[1.31689305]]\n",
      "p-value: 0.21689805416583205\n",
      "TPR: 0.09243697478991597\n",
      "-------------------------------------------------\n",
      "iteration #120:\n",
      "Anomaly index: 102\n",
      "etajTX: [[1.4783552]]\n",
      "p-value: 0.7210965589266732\n",
      "TPR: 0.09166666666666666\n",
      "-------------------------------------------------\n",
      "iteration #121:\n",
      "Anomaly index: 106\n",
      "etajTX: [[1.80515586]]\n",
      "p-value: 0.7522793847820601\n",
      "TPR: 0.09090909090909091\n",
      "-------------------------------------------------\n",
      "iteration #122:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "max_iteration = 120\n",
    "alpha = 0.05\n",
    "list_p_value = []\n",
    "count = 0\n",
    "print(f'iteration #{0}:')\n",
    "\n",
    "\n",
    "while len(list_p_value) <= max_iteration:\n",
    "    p_value = run_tpr()\n",
    "    if p_value is None:\n",
    "        continue\n",
    "    list_p_value.append(p_value)\n",
    "    if p_value <= alpha:\n",
    "        count += 1\n",
    "    print(f'TPR: {count / len(list_p_value)}')\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'iteration #{len(list_p_value)+1}:')\n",
    "plt.hist(list_p_value)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
